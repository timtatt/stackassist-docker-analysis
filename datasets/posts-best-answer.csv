Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense,Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
"16047306","1","16048358","","2013-04-16 21:19:47","","3982","799487","<p>I keep rereading <a href=""https://docs.docker.com/"" rel=""noreferrer"">the Docker documentation</a> to try to understand the difference between Docker and a full VM. How does it manage to provide a full filesystem, isolated networking environment, etc. without being as heavy?</p>

<p>Why is deploying software to a Docker image (if that's the right term) easier than simply deploying to a consistent production environment?</p>
","109549","","63550","","2018-08-28 20:04:57","2020-11-26 15:53:35","How is Docker different from a virtual machine?","<docker><containers><virtual-machine><virtualization>","21","9","1879","","","CC BY-SA 4.0","16048358","2","","16047306","2013-04-16 22:35:27","","3657","","<p>Docker originally used <a href=""https://linuxcontainers.org/lxc/"" rel=""noreferrer"">LinuX Containers</a> (LXC), but later switched to <a href=""https://github.com/opencontainers/runc"" rel=""noreferrer"">runC</a> (formerly known as <strong>libcontainer</strong>), which runs in the same operating system as its host. This allows it to share a lot of the host operating system resources. Also, it uses a layered filesystem (<a href=""http://aufs.sourceforge.net/"" rel=""noreferrer"">AuFS</a>) and manages networking.</p>

<p>AuFS is a layered file system, so you can have a read only part and a write part which are merged together. One could have the common parts of the operating system as read only (and shared amongst all of your containers) and then give each container its own mount for writing.</p>

<p>So, let's say you have a 1&nbsp;GB container image; if you wanted to use a full VM, you would need to have 1&nbsp;GB x number of VMs you want. With Docker and AuFS you can share the bulk of the 1&nbsp;GB between all the containers and if you have 1000 containers you still might only have a little over 1&nbsp;GB of space for the containers OS (assuming they are all running the same OS image).</p>

<p>A full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible.</p>

<p>A full virtualized system usually takes minutes to start, whereas Docker/LXC/runC containers take seconds, and often even less than a second.</p>

<p>There are pros and cons for each type of virtualized system. If you want full isolation with guaranteed resources, a full VM is the way to go. If you just want to isolate processes from each other and want to run a ton of them on a reasonably sized host, then Docker/LXC/runC seems to be the way to go.</p>

<p>For more information, check out <a href=""http://web.archive.org/web/20150326185901/http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part"" rel=""noreferrer"">this set of blog posts</a> which do a good job of explaining how LXC works.</p>

<blockquote>
  <p>Why is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?</p>
</blockquote>

<p>Deploying a consistent production environment is easier said than done. Even if you use tools like <a href=""https://en.wikipedia.org/wiki/Chef_%28software%29"" rel=""noreferrer"">Chef</a> and <a href=""https://en.wikipedia.org/wiki/Puppet_%28software%29"" rel=""noreferrer"">Puppet</a>, there are always OS updates and other things that change between hosts and environments.</p>

<p>Docker gives you the ability to snapshot the OS into a shared image, and makes it easy to deploy on other Docker hosts. Locally, dev, qa, prod, etc.: all the same image. Sure you can do this with other tools, but not nearly as easily or fast.</p>

<p>This is great for testing; let's say you have thousands of tests that need to connect to a database, and each test needs a pristine copy of the database and will make changes to the data. The classic approach to this is to reset the database after every test either with custom code or with tools like <a href=""https://flywaydb.org/"" rel=""noreferrer"">Flyway</a> - this can be very time-consuming and means that tests must be run serially. However, with Docker you could create an image of your database and run up one instance per test, and then run all the tests in parallel since you know they will all be running against the same snapshot of the database. Since the tests are running in parallel and in Docker containers they could run all on the same box at the same time and should finish much faster. Try doing that with a full VM.</p>

<p>From comments...</p>

<blockquote>
  <p>Interesting! I suppose I'm still confused by the notion of ""snapshot[ting] the OS"". How does one do that without, well, making an image of the OS?</p>
</blockquote>

<p>Well, let's see if I can explain. You start with a base image, and then make your changes, and commit those changes using docker, and it creates an image. This image contains only the differences from the base. When you want to run your image, you also need the base, and it layers your image on top of the base using a layered file system: as mentioned above, Docker uses AuFS. AuFS merges the different layers together and you get what you want; you just need to run it. You can keep adding more and more images (layers) and it will continue to only save the diffs. Since Docker typically builds on top of ready-made images from a <a href=""https://registry.hub.docker.com/"" rel=""noreferrer"">registry</a>, you rarely have to ""snapshot"" the whole OS yourself.</p>
","356788","","4217352","","2019-11-19 19:29:30","2019-11-19 19:29:30","","","","0","","","","CC BY-SA 4.0"
"22049212","1","22050116","","2014-02-26 17:46:52","","2132","1146262","<p>I'm thinking of using Docker to build my dependencies on a Continuous Integration (CI) server, so that I don't have to install all the runtimes and libraries on the agents themselves. </p>

<p>To achieve this I would need to copy the build artifacts that are built inside the container back into the host. Is that possible?</p>
","2668128","","10907864","","2020-12-02 22:30:14","2021-04-21 09:10:05","Docker: Copying files from Docker container to host","<docker><docker-container><file-copying>","21","4","487","","","CC BY-SA 4.0","22050116","2","","22049212","2014-02-26 18:31:40","","3644","","<p>In order to copy a file from a container to the host, you can use the command</p>

<pre><code>docker cp &lt;containerId&gt;:/file/path/within/container /host/path/target
</code></pre>

<p>Here's an example:</p>

<pre><code>$ sudo docker cp goofy_roentgen:/out_read.jpg .
</code></pre>

<p>Here <strong>goofy_roentgen</strong> is the container name I got from the following command:</p>

<pre><code>$ sudo docker ps

CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                            NAMES
1b4ad9311e93        bamos/openface      ""/bin/bash""         33 minutes ago      Up 33 minutes       0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp   goofy_roentgen
</code></pre>

<p>You can also use (part of) the <strong>Container ID</strong>. The following command is equivalent to the first</p>

<pre><code>$ sudo docker cp 1b4a:/out_read.jpg .
</code></pre>
","884978","","9468261","","2019-11-07 15:25:50","2019-11-07 15:25:50","","","","13","","","","CC BY-SA 4.0"
"22907231","1","31971697","","2014-04-07 08:28:55","","1894","1508990","<p>I am trying to build a backup and restore solution for the Docker containers that we work with.</p>

<p>I have Docker base image that I have created, <code>ubuntu:base</code>, and do not want have to rebuild it each time with a Docker file to add files to it.</p>

<p>I want to create a script that runs from the host machine and creates a new container using the <code>ubuntu:base</code> Docker image and then copies files into that container.</p>

<p>How can I copy files from the host to the container?</p>
","3001829","","3257186","","2020-10-14 12:57:06","2021-05-26 21:56:17","How to copy files from host to Docker container?","<docker><docker-container>","45","4","555","","","CC BY-SA 4.0","31971697","2","","22907231","2015-08-12 17:25:00","","3215","","<p>The <code>cp</code> command can be used to copy files. </p>

<p>One specific file can be copied TO the container like:</p>

<pre><code>docker cp foo.txt mycontainer:/foo.txt
</code></pre>

<p>One specific file can be copied FROM the container like:</p>

<pre><code>docker cp mycontainer:/foo.txt foo.txt
</code></pre>

<p>For emphasis, <code>mycontainer</code> is a <em>container</em> ID, <strong>not</strong> an <em>image</em> ID.</p>

<p>Multiple files contained by the folder <code>src</code> can be copied into the <code>target</code> folder using:</p>

<pre><code>docker cp src/. mycontainer:/target
docker cp mycontainer:/src/. target
</code></pre>

<p>Reference: <a href=""https://docs.docker.com/engine/reference/commandline/cp/"" rel=""noreferrer"">Docker CLI docs for <code>cp</code></a> </p>

<p>In Docker versions prior to 1.8 it was only possible to copy files from a container to the host. Not from the host to a container.</p>
","2706422","","1137669","","2019-08-19 08:25:29","2019-08-19 08:25:29","","","","10","","","","CC BY-SA 4.0"
"23935141","1","23938978","","2014-05-29 13:57:18","","1700","790303","<p>How do I transfer a Docker image from one machine to another one without using a repository, no matter private or public?</p>

<p>I create my own image in VirtualBox, and when it is finished I try to deploy to other machines to have real usage.</p>

<p>Since it is based on my own based image (like Red Hat Linux), it cannot be recreated from a Dockerfile. My dockerfile isn't easily portable.</p>

<p>Are there simple commands I can use? Or another solution?</p>
","308174","","2051454","","2020-03-13 11:03:13","2021-05-25 07:04:20","How to copy Docker images from one host to another without using a repository","<docker>","15","1","684","","","CC BY-SA 4.0","23938978","2","","23935141","2014-05-29 17:09:52","","2856","","<p>You will need to save the Docker image as a tar file:</p>

<pre><code>docker save -o &lt;path for generated tar file&gt; &lt;image name&gt;
</code></pre>

<p>Then copy your image to a new system with regular file transfer tools such as <code>cp</code>, <code>scp</code> or <code>rsync</code>(preferred for big files). After that you will have to load the image into Docker:</p>

<pre><code>docker load -i &lt;path to image tar file&gt;
</code></pre>

<p>PS: You may need to <code>sudo</code> all commands.</p>

<p>EDIT: 
You should add filename (not just directory) with -o, for example:</p>

<pre><code>docker save -o c:/myfile.tar centos:16
</code></pre>
","1544590","","4214976","","2019-08-20 10:33:43","2019-08-20 10:33:43","","","","13","","","","CC BY-SA 4.0"
"24319662","1","24326540","","2014-06-20 03:54:16","","2075","1224162","<p>So I have a Nginx running inside a docker container, I have a mysql running on localhost, I want to connect to the MySql from within my Nginx. The MySql is running on localhost and not exposing a port to the outside world, so its bound on localhost, not bound on the ip address of the machine.</p>

<p>Is there any way to connect to this MySql or any other program on localhost from within this docker container?</p>

<p>This question is different from ""How to get the IP address of the docker host from inside a docker container"" due to the fact that the IP address of the docker host could be the public IP or the private IP in the network which may or may not be reachable from within the docker container (I mean public IP if hosted at AWS or something). Even if you have the IP address of the docker host it does not mean you can connect to docker host from within the container given that IP address as your Docker network may be overlay, host, bridge, macvlan, none etc which restricts the reachability of that IP address.</p>
","78000","","78000","","2019-11-09 12:21:57","2021-05-26 03:12:41","From inside of a Docker container, how do I connect to the localhost of the machine?","<nginx><docker><reverse-proxy><docker-networking>","34","5","858","","","CC BY-SA 4.0","24326540","2","","24319662","2014-06-20 11:46:51","","2811","","<p><strong>Edit:</strong></p>
<p>If you are using <a href=""https://docs.docker.com/docker-for-mac/networking/#there-is-no-docker0-bridge-on-macos#i-want-to-connect-from-a-container-to-a-service-on-the-host"" rel=""noreferrer"">Docker-for-mac</a> or <a href=""https://docs.docker.com/docker-for-windows/networking/#there-is-no-docker0-bridge-on-windows#i-want-to-connect-from-a-container-to-a-service-on-the-host"" rel=""noreferrer"">Docker-for-Windows</a> 18.03+, just connect to your mysql service using the host <code>host.docker.internal</code> (instead of the <code>127.0.0.1</code> in your connection string).</p>
<p>If you are using Docker-for-Linux 20.10.0+, you can also use the host <code>host.docker.internal</code> <strong>if</strong> you started your Docker container with the <code>--add-host host.docker.internal:host-gateway</code> option.</p>
<p>Otherwise, read below</p>
<hr />
<h2>TLDR</h2>
<p>Use <code>--network=&quot;host&quot;</code> in your <code>docker run</code> command, then <code>127.0.0.1</code> in your docker container will point to your docker host.</p>
<p>Note: This mode only works on Docker for Linux, <a href=""https://docs.docker.com/network/host/"" rel=""noreferrer"">per the documentation</a>.</p>
<hr />
<h1>Note on docker container networking modes</h1>
<p>Docker offers <a href=""https://docs.docker.com/engine/reference/run/#network-settings"" rel=""noreferrer"">different networking modes</a> when running containers. Depending on the mode you choose you would connect to your MySQL database running on the docker host differently.</p>
<h2>docker run --network=&quot;bridge&quot; (default)</h2>
<p>Docker creates a bridge named <code>docker0</code> by default. Both the docker host and the docker containers have an IP address on that bridge.</p>
<p>on the Docker host, type <code>sudo ip addr show docker0</code> you will have an output looking like:</p>
<pre><code>[vagrant@docker:~] $ sudo ip addr show docker0
4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff
    inet 172.17.42.1/16 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::5484:7aff:fefe:9799/64 scope link
       valid_lft forever preferred_lft forever
</code></pre>
<p>So here my docker host has the IP address <code>172.17.42.1</code> on the <code>docker0</code> network interface.</p>
<p>Now start a new container and get a shell on it: <code>docker run --rm -it ubuntu:trusty bash</code> and within the container type <code>ip addr show eth0</code> to discover how its main network interface is set up:</p>
<pre><code>root@e77f6a1b3740:/# ip addr show eth0
863: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 66:32:13:f0:f1:e3 brd ff:ff:ff:ff:ff:ff
    inet 172.17.1.192/16 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::6432:13ff:fef0:f1e3/64 scope link
       valid_lft forever preferred_lft forever
</code></pre>
<p>Here my container has the IP address <code>172.17.1.192</code>. Now look at the routing table:</p>
<pre><code>root@e77f6a1b3740:/# route
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
default         172.17.42.1     0.0.0.0         UG    0      0        0 eth0
172.17.0.0      *               255.255.0.0     U     0      0        0 eth0
</code></pre>
<p>So the IP Address of the docker host <code>172.17.42.1</code> is set as the default route and is accessible from your container.</p>
<pre><code>root@e77f6a1b3740:/# ping 172.17.42.1
PING 172.17.42.1 (172.17.42.1) 56(84) bytes of data.
64 bytes from 172.17.42.1: icmp_seq=1 ttl=64 time=0.070 ms
64 bytes from 172.17.42.1: icmp_seq=2 ttl=64 time=0.201 ms
64 bytes from 172.17.42.1: icmp_seq=3 ttl=64 time=0.116 ms
</code></pre>
<h2>docker run --network=&quot;host&quot;</h2>
<p>Alternatively you can run a docker container with <a href=""http://docs.docker.com/engine/reference/run/#network-host"" rel=""noreferrer"">network settings set to <code>host</code></a>. Such a container will share the network stack with the docker host and from the container point of view, <code>localhost</code> (or <code>127.0.0.1</code>) will refer to the docker host.</p>
<p>Be aware that any port opened in your docker container would be opened on the docker host. And this without requiring the <a href=""https://docs.docker.com/engine/reference/run/#expose-incoming-ports"" rel=""noreferrer""><code>-p</code> or <code>-P</code> <code>docker run</code> option</a>.</p>
<p>IP config on my docker host:</p>
<pre><code>[vagrant@docker:~] $ ip addr show eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link
       valid_lft forever preferred_lft forever
</code></pre>
<p>and from a docker container in <strong>host</strong> mode:</p>
<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host ubuntu:trusty ip addr show eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link
       valid_lft forever preferred_lft forever
</code></pre>
<p>As you can see both the docker host and docker container share the exact same network interface and as such have the same IP address.</p>
<hr />
<h1>Connecting to MySQL from containers</h1>
<h2>bridge mode</h2>
<p>To access MySQL running on the docker host from containers in <em>bridge mode</em>, you need to make sure the MySQL service is listening for connections on the <code>172.17.42.1</code> IP address.</p>
<p>To do so, make sure you have either <code>bind-address = 172.17.42.1</code> or <code>bind-address = 0.0.0.0</code> in your MySQL config file (my.cnf).</p>
<p>If you need to set an environment variable with the IP address of the gateway, you can run the following code in a container :</p>
<pre><code>export DOCKER_HOST_IP=$(route -n | awk '/UG[ \t]/{print $2}')
</code></pre>
<p>then in your application, use the <code>DOCKER_HOST_IP</code> environment variable to open the connection to MySQL.</p>
<p><strong>Note:</strong> if you use <code>bind-address = 0.0.0.0</code> your MySQL server will listen for connections on all network interfaces. That means your MySQL server could be reached from the Internet ; make sure to setup firewall rules accordingly.</p>
<p><strong>Note 2:</strong> if you use <code>bind-address = 172.17.42.1</code> your MySQL server won't listen for connections made to <code>127.0.0.1</code>. Processes running on the docker host that would want to connect to MySQL would have to use the <code>172.17.42.1</code> IP address.</p>
<h2>host mode</h2>
<p>To access MySQL running on the docker host from containers in <em>host mode</em>, you can keep <code>bind-address = 127.0.0.1</code> in your MySQL configuration and all you need to do is to connect to <code>127.0.0.1</code> from your containers:</p>
<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host mysql mysql -h 127.0.0.1 -uroot -p
Enter password:
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 36
Server version: 5.5.41-0ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt;
</code></pre>
<p><strong>note:</strong> Do use <code>mysql -h 127.0.0.1</code> and not <code>mysql -h localhost</code>; otherwise the MySQL client would try to connect using a unix socket.</p>
","107049","","107049","","2021-03-16 10:59:27","2021-03-16 10:59:27","","","","23","","","","CC BY-SA 4.0"
"17157721","1","20686101","","2013-06-17 22:10:22","","1673","1624299","<p>Is there a command I can run to get the container's IP address right from the host after a new container is created?</p>

<p>Basically, once Docker creates the container, I want to roll my own code deployment and container configuration scripts.</p>
","1131518","","1746118","","2021-04-08 13:32:36","2021-04-08 13:32:36","How to get a Docker container's IP address from the host","<docker><ip-address>","52","1","490","","","CC BY-SA 4.0","20686101","2","","17157721","2013-12-19 15:56:21","","2811","","<p>The <code>--format</code> option of <code>inspect</code> comes to the rescue.</p>
<p>Modern Docker client syntax is:</p>
<pre><code>docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container_name_or_id
</code></pre>
<p>Old Docker client syntax is:</p>
<pre><code>docker inspect --format '{{ .NetworkSettings.IPAddress }}' container_name_or_id
</code></pre>
<p>These commands will return the Docker container's IP address.</p>
<p>As mentioned in the comments: if you are on Windows, use double quotes <code>&quot;</code> instead of single quotes <code>'</code> around the curly braces.</p>
","3119830","","1714171","","2020-10-13 11:52:18","2020-10-13 11:52:18","","","","22","","","","CC BY-SA 4.0"
"24958140","1","24958548","","2014-07-25 14:31:20","","2506","808905","<p>What is the difference between the <code>COPY</code> and <code>ADD</code> commands in a Dockerfile, and when would I use one over the other?</p>

<pre><code>COPY &lt;src&gt; &lt;dest&gt;
</code></pre>

<blockquote>
  <p>The COPY instruction will copy new files from <code>&lt;src&gt;</code> and add them to the container's filesystem at path <code>&lt;dest&gt;</code></p>
</blockquote>

<pre><code>ADD &lt;src&gt; &lt;dest&gt;
</code></pre>

<blockquote>
  <p>The ADD instruction will copy new files from <code>&lt;src&gt;</code> and add them to the container's filesystem at path <code>&lt;dest&gt;</code>.</p>
</blockquote>
","131640","","7911776","","2019-09-16 05:12:49","2021-04-29 07:32:05","What is the difference between the 'COPY' and 'ADD' commands in a Dockerfile?","<docker><dockerfile>","16","5","358","","","CC BY-SA 4.0","24958548","2","","24958140","2014-07-25 14:52:38","","2468","","<p>You should check the <a href=""https://docs.docker.com/engine/reference/builder/#add"" rel=""noreferrer""><code>ADD</code></a> and <a href=""https://docs.docker.com/engine/reference/builder/#copy"" rel=""noreferrer""><code>COPY</code></a> documentation for a more detailed description of their behaviors, but in a nutshell, the major difference is that <code>ADD</code> can do more than <code>COPY</code>:</p>
<ul>
<li><code>ADD</code> allows <code>&lt;src&gt;</code> to be a URL</li>
<li>Referring to comments below, the <code>ADD</code> <a href=""https://docs.docker.com/engine/reference/builder/#add"" rel=""noreferrer"">documentation</a> states that:</li>
</ul>
<blockquote>
<p>If  is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from remote URLs are not decompressed.</p>
</blockquote>
<p>Note that the <a href=""https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#add-or-copy"" rel=""noreferrer"">Best practices for writing Dockerfiles</a> suggests using <code>COPY</code> where the magic of <code>ADD</code> is not required. Otherwise, you (<em>since you had to look up this answer</em>) are likely to get surprised someday when you mean to copy <code>keep_this_archive_intact.tar.gz</code> into your container, but instead, you spray the contents onto your filesystem.</p>
","451980","","7329832","","2020-10-06 07:07:11","2020-10-06 07:07:11","","","","7","","","","CC BY-SA 4.0"
"30172605","1","30173220","","2015-05-11 16:12:30","","1447","1339373","<p>I'm getting started working with Docker. I'm using the WordPress base image and docker-compose.</p>

<p>I'm trying to ssh into one of the containers to inspect the files/directories that were created during the initial build. I tried to run <code>docker-compose run containername ls -la</code>, but that didn't do anything. Even if it did, I'd rather have a console where I can traverse the directory structure, rather than run a single command. What is the right way to do this with Docker?</p>
","48523","","1663462","","2019-02-03 16:25:40","2021-06-19 15:46:41","How do I get into a Docker container's shell?","<docker><docker-container>","26","5","421","","","CC BY-SA 4.0","30173220","2","","30172605","2015-05-11 16:44:52","","2127","","<p><code>docker attach</code> will let you connect to your Docker container, but this isn't really the same thing as <code>ssh</code>.  If your container is running a webserver, for example, <code>docker attach</code> will probably connect you to the <em>stdout</em> of the web server process.  It won't necessarily give you a shell.</p>

<p>The <code>docker exec</code> command is probably what you are looking for; this will let you run arbitrary commands inside an existing container.  For example:</p>

<pre><code>docker exec -it &lt;mycontainer&gt; bash
</code></pre>

<p>Of course, whatever command you are running must exist in the container filesystem.</p>

<p>In the above command <code>&lt;mycontainer&gt;</code> is the name or ID of the target container.  It doesn't matter whether or not you're using <code>docker compose</code>; just run <code>docker ps</code> and use either the ID (a hexadecimal string displayed in the first column) or the name (displayed in the final column).  E.g., given:</p>

<pre><code>$ docker ps
d2d4a89aaee9        larsks/mini-httpd   ""mini_httpd -d /cont   7 days ago          Up 7 days                               web                 
</code></pre>

<p>I can run:</p>

<pre><code>$ docker exec -it web ip addr
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
18: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP 
    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.3/16 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:acff:fe11:3/64 scope link 
       valid_lft forever preferred_lft forever
</code></pre>

<p>I could accomplish the same thing by running:</p>

<pre><code>$ docker exec -it d2d4a89aaee9 ip addr
</code></pre>

<p>Similarly, I could start a shell in the container;</p>

<pre><code>$ docker exec -it web sh
/ # echo This is inside the container.
This is inside the container.
/ # exit
$
</code></pre>
","147356","","147356","","2020-04-12 12:17:24","2020-04-12 12:17:24","","","","10","","","","CC BY-SA 3.0"
"21553353","1","21564990","","2014-02-04 13:04:23","","2062","618197","<p>In Dockerfiles there are two commands that look similar to me: <code>CMD</code> and <code>ENTRYPOINT</code>. But I guess that there is a (subtle?) difference between them - otherwise it would not make any sense to have two commands for the very same thing.</p>

<p>The documentation states for <code>CMD</code></p>

<blockquote>
  <p>The main purpose of a CMD is to provide defaults for an executing container.</p>
</blockquote>

<p>and for <code>ENTRYPOINT</code>:</p>

<blockquote>
  <p>An ENTRYPOINT helps you to configure a container that you can run as an executable.</p>
</blockquote>

<p>So, what's the difference between those two commands?</p>
","1333873","","39726","","2014-02-04 17:13:41","2021-05-28 13:51:58","What is the difference between CMD and ENTRYPOINT in a Dockerfile?","<docker>","17","6","600","","","CC BY-SA 3.0","21564990","2","","21553353","2014-02-04 22:34:33","","2051","","<p>Docker has a default entrypoint which is <code>/bin/sh -c</code> but does not have a default command.</p>

<p>When you run docker like this:
<code>docker run -i -t ubuntu bash</code>
the entrypoint is the default <code>/bin/sh -c</code>, the image is <code>ubuntu</code> and the command is <code>bash</code>.  </p>

<p>The command is run via the entrypoint. i.e., the actual thing that gets executed is <code>/bin/sh -c bash</code>. This allowed Docker to implement <code>RUN</code> quickly by relying on the shell's parser.</p>

<p>Later on, people asked to be able to customize this, so <code>ENTRYPOINT</code> and <code>--entrypoint</code> were introduced.</p>

<p>Everything after <code>ubuntu</code> in the example above is the command and is passed to the entrypoint. When using the <code>CMD</code> instruction, it is exactly as if you were doing <code>docker run -i -t ubuntu &lt;cmd&gt;</code>. <code>&lt;cmd&gt;</code> will be the parameter of the entrypoint.</p>

<p>You will also get the same result if you instead type this command <code>docker run -i -t ubuntu</code>. You will still start a bash shell in the container because of the <a href=""https://github.com/dockerfile/ubuntu/blob/master/Dockerfile"" rel=""noreferrer"">ubuntu Dockerfile</a> specified a default CMD: <code>CMD [""bash""]</code></p>

<p>As everything is passed to the entrypoint, you can have a very nice behavior from your images. @Jiri example is good, it shows how to use an image as a ""binary"". When using <code>[""/bin/cat""]</code> as entrypoint and then doing <code>docker run img /etc/passwd</code>, you get it, <code>/etc/passwd</code> is the command and is passed to the entrypoint so the end result execution is simply <code>/bin/cat /etc/passwd</code>.</p>

<p>Another example would be to have any cli as entrypoint. For instance, if you have a redis image, instead of running <code>docker run redisimg redis -H something -u toto get key</code>, you can simply have <code>ENTRYPOINT [""redis"", ""-H"", ""something"", ""-u"", ""toto""]</code> and then run like this for the same result: <code>docker run redisimg get key</code>.</p>
","884978","","2051454","","2018-05-09 20:46:49","2018-05-09 20:46:49","","","","13","","","","CC BY-SA 4.0"
"35594987","1","35595021","","2016-02-24 06:37:48","","1088","769691","<p>I have build a Docker image from a Docker file using the below command.</p>

<pre><code>$ docker build -t u12_core -f u12_core .
</code></pre>

<p>When I am trying to rebuild it with the same command, it's using the build cache like:</p>

<pre><code>Step 1 : FROM ubuntu:12.04
 ---&gt; eb965dfb09d2
Step 2 : MAINTAINER Pavan Gupta &lt;pavan.gupta@gmail.com&gt;
 ---&gt; Using cache
 ---&gt; 4354ccf9dcd8
Step 3 : RUN apt-get update
 ---&gt; Using cache
 ---&gt; bcbca2fcf204
Step 4 : RUN apt-get install -y openjdk-7-jdk
 ---&gt; Using cache
 ---&gt; 103f1a261d44
Step 5 : RUN apt-get install -y openssh-server
 ---&gt; Using cache
 ---&gt; dde41f8d0904
Step 6 : RUN apt-get install -y git-core
 ---&gt; Using cache
 ---&gt; 9be002f08b6a
Step 7 : RUN apt-get install -y build-essential
 ---&gt; Using cache
 ---&gt; a752fd73a698
Step 8 : RUN apt-get install -y logrotate
 ---&gt; Using cache
 ---&gt; 93bca09b509d
Step 9 : RUN apt-get install -y lsb-release
 ---&gt; Using cache
 ---&gt; fd4d10cf18bc
Step 10 : RUN mkdir /var/run/sshd
 ---&gt; Using cache
 ---&gt; 63b4ecc39ff0
Step 11 : RUN echo 'root:root' | chpasswd
 ---&gt; Using cache
 ---&gt; 9532e31518a6
Step 12 : RUN sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config
 ---&gt; Using cache
 ---&gt; 47d1660bd544
Step 13 : RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
 ---&gt; Using cache
 ---&gt; d1f97f1c52f7
Step 14 : RUN wget -O aerospike.tgz 'http://aerospike.com/download/server/latest/artifact/ubuntu12'
 ---&gt; Using cache
 ---&gt; bd7dde7a98b9
Step 15 : RUN tar -xvf aerospike.tgz
 ---&gt; Using cache
 ---&gt; 54adaa09921f
Step 16 : RUN dpkg -i aerospike-server-community-*/*.deb
 ---&gt; Using cache
 ---&gt; 11aba013eea5
Step 17 : EXPOSE 22 3000 3001 3002 3003
 ---&gt; Using cache
 ---&gt; e33aaa78a931
Step 18 : CMD /usr/sbin/sshd -D
 ---&gt; Using cache
 ---&gt; 25f5fe70fa84
Successfully built 25f5fe70fa84
</code></pre>

<p>The cache shows that aerospike is installed. However, I don't find it inside containers spawn from this image, so I want to rebuild this image without using the cache. How can I force Docker to rebuild a clean image without the cache?</p>
","2710873","","582436","","2019-01-14 00:53:06","2020-10-31 18:18:39","How to force Docker for a clean build of an image","<docker><aerospike>","9","6","152","","","CC BY-SA 4.0","35595021","2","","35594987","2016-02-24 06:40:31","","1880","","<p>There's a <code>--no-cache</code> option:</p>

<pre><code>docker build --no-cache -t u12_core -f u12_core .
</code></pre>

<p>In older versions of Docker you needed to pass <code>--no-cache=true</code>, but this is no longer the case.</p>
","11208","","63550","","2018-07-24 15:38:00","2018-07-24 15:38:00","","","","6","","","","CC BY-SA 4.0"
"16840409","1","16842203","","2013-05-30 15:41:46","","965","838219","<p>There's a command to list images, <code>docker images</code>, but there doesn't seem to be a corresponding <code>docker containers</code>.</p>

<p>Other than becoming root and looking into <code>/var/lib/docker</code> there doesn't seem a way to do that. Am I missing something? Is that something one isn't supposed to do?</p>
","124416","","63550","","2018-06-21 19:58:23","2020-04-08 12:02:45","How to list containers in Docker","<docker>","14","1","211","","","CC BY-SA 4.0","16842203","2","","16840409","2013-05-30 17:15:11","","1738","","<p>To show only <strong>running containers</strong> use the given command:</p>

<pre><code>docker ps
</code></pre>

<p>To show <strong>all containers</strong> use the given command:</p>

<pre><code>docker ps -a
</code></pre>

<p>To show the <strong>latest created container</strong> (includes all states) use the given command:</p>

<pre><code>docker ps -l
</code></pre>

<p>To show <strong>n last created containers</strong> (includes all states) use the given command:</p>

<pre><code>docker ps -n=-1
</code></pre>

<p>To display <strong>total file sizes</strong> use the given command:</p>

<pre><code>docker ps -s
</code></pre>

<p>The content presented above is from <a href=""https://docs.docker.com/v1.11/engine/reference/commandline/ps/"" rel=""noreferrer"">docker.com</a>.</p>

<p>In the new version of Docker, commands are updated, and some management commands are added:</p>

<pre><code>docker container ls
</code></pre>

<p>It is used to list all the running containers.</p>

<pre><code>docker container ls -a
</code></pre>

<p>And then, if you want to clean them all,</p>

<pre><code>docker rm $(docker ps -aq)
</code></pre>

<p>It is used to list all the containers created irrespective of its state.</p>

<p>And to stop all the Docker containers (force)</p>

<pre><code>docker rm -f $(docker ps -a -q)  
</code></pre>

<p>Here the container is the management command.</p>
","404289","","942317","","2019-11-28 08:51:19","2019-11-28 08:51:19","","","","5","","","","CC BY-SA 4.0"
"17236796","1","17237701","","2013-06-21 13:41:42","","1313","757030","<p>This question is related to <em><a href=""https://stackoverflow.com/questions/17014263/should-i-be-concerned-about-excess-non-running-docker-containers"">Should I be concerned about excess, non-running, Docker containers?</a></em>.</p>

<p>I'm wondering how to remove old containers. The <code>docker rm 3e552code34a</code> lets you remove a single one, but I have lots already. <code>docker rm --help</code> doesn't give a selection option (like all, or by image name).</p>

<p>Maybe there is a directory in which these containers are stored where I can delete them easily manually?</p>
","1449361","","-1","","2017-05-23 11:55:19","2021-02-22 16:16:57","How to remove old Docker containers","<docker>","62","7","498","","","CC BY-SA 3.0","17237701","2","","17236796","2013-06-21 14:25:51","","1590","","<p>Since <a href=""https://github.com/moby/moby/blob/master/CHANGELOG.md#1130-2017-01-18"" rel=""noreferrer"">Docker 1.13.x</a> you can use <a href=""https://docs.docker.com/engine/reference/commandline/container_prune/"" rel=""noreferrer"">Docker container prune</a>:</p>

<pre><code>docker container prune
</code></pre>

<p>This will remove all stopped containers and should work on all platforms the same way.</p>

<p>There is also a <a href=""https://docs.docker.com/engine/reference/commandline/system_prune/"" rel=""noreferrer"">Docker system prune</a>:</p>

<pre><code>docker system prune
</code></pre>

<p>which will clean up all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes, in one command.</p>

<hr>

<p>For older Docker versions, you can string Docker commands together with other Unix commands to get what you need. Here is an example on how to clean up old containers that are weeks old:</p>

<pre><code>$ docker ps --filter ""status=exited"" | grep 'weeks ago' | awk '{print $1}' | xargs --no-run-if-empty docker rm
</code></pre>

<p>To give credit, where it is due, this example is from <a href=""https://twitter.com/jpetazzo/status/347431091415703552"" rel=""noreferrer"">https://twitter.com/jpetazzo/status/347431091415703552</a>.</p>
","356788","","435093","","2019-07-09 07:23:49","2019-07-09 07:23:49","","","","22","","","","CC BY-SA 4.0"
"32723111","1","32723127","","2015-09-22 17:23:37","","863","452054","<p>When running Docker for a long time, there are a lot of images in system. How can I remove all unused Docker images at once safety to free up the storage?</p>

<p>In addition, I also want to remove images pulled months ago, which have the correct <code>TAG</code>.</p>

<p>So, I'm not asking for removing untagged images only. I'm searching for a way to remove general unused images, which includes both untagged and other images such as pulled months ago with correct <code>TAG</code>.</p>
","622662","","4671027","","2019-08-02 08:28:34","2021-06-14 18:53:04","How to remove old and unused Docker images","<docker><docker-image>","27","0","333","","","CC BY-SA 4.0","32723127","2","","32723111","2015-09-22 17:24:26","","1571","","<p>Update Sept. 2016: Docker 1.13: <a href=""https://github.com/docker/docker/pull/26108"" rel=""noreferrer"">PR 26108</a> and <a href=""https://github.com/docker/docker/commit/86de7c000f5d854051369754ad1769194e8dd5e1"" rel=""noreferrer"">commit 86de7c0</a> introduce a few new commands to help facilitate visualizing how much space the docker daemon data is taking on disk and allowing for easily cleaning up ""unneeded"" excess.</p>

<p><a href=""https://docs.docker.com/engine/reference/commandline/system_prune/"" rel=""noreferrer""><strong><code>docker system prune</code></strong></a> will delete ALL dangling data (i.e. In order: containers stopped, volumes without containers and images with no containers). Even unused data, with <code>-a</code> option.</p>

<p>You also have:</p>

<ul>
<li><a href=""https://docs.docker.com/engine/reference/commandline/container_prune/"" rel=""noreferrer""><code>docker container prune</code></a></li>
<li><a href=""https://docs.docker.com/engine/reference/commandline/image_prune/"" rel=""noreferrer""><code>docker image prune</code></a></li>
<li><a href=""https://docs.docker.com/engine/reference/commandline/network_prune/"" rel=""noreferrer""><code>docker network prune</code></a></li>
<li><a href=""https://docs.docker.com/engine/reference/commandline/volume_prune/"" rel=""noreferrer""><code>docker volume prune</code></a></li>
</ul>

<p>For <em>unused</em> images, use <code>docker image prune -a</code> (for removing dangling <em>and</em> ununsed images).<br>
Warning: '<em>unused</em>' means ""images not referenced by any container"": be careful before using <code>-a</code>.</p>

<p>As illustrated in <a href=""https://stackoverflow.com/users/1207596/a-l"">A L</a>'s <a href=""https://stackoverflow.com/a/50405599/6309"">answer</a>, <code>docker system prune --all</code> will remove all <em>unused</em> images not just dangling ones... which can be a bit too much.</p>

<p>Combining <code>docker xxx prune</code> with the <a href=""https://docs.docker.com/engine/reference/commandline/system_prune/#filtering"" rel=""noreferrer""><code>--filter</code> option</a> can be a great way to limit the pruning (<a href=""https://docs.docker.com/develop/sdk/#api-version-matrix"" rel=""noreferrer"">docker SDK API 1.28 minimum, so docker 17.04+</a>)</p>

<blockquote>
  <p>The currently supported filters are:</p>
</blockquote>

<ul>
<li><code>until (&lt;timestamp&gt;)</code> - only remove containers, images, and networks created before given timestamp</li>
<li><code>label</code> (<code>label=&lt;key&gt;</code>, <code>label=&lt;key&gt;=&lt;value&gt;</code>, <code>label!=&lt;key&gt;</code>, or <code>label!=&lt;key&gt;=&lt;value&gt;</code>) - only remove containers, images, networks, and volumes with (or <em>without</em>, in case <code>label!=...</code> is used) the specified labels.</li>
</ul>

<p>See ""<a href=""https://docs.docker.com/config/pruning/#prune-images"" rel=""noreferrer"">Prune images</a>"" for an example.</p>

<hr>

<p>Original answer (Sep. 2016)</p>

<p>I usually do:</p>

<pre><code>docker rmi $(docker images --filter ""dangling=true"" -q --no-trunc)
</code></pre>

<p>I have an <a href=""https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options"" rel=""noreferrer"">alias for removing those [dangling images]<a href=""https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options"" rel=""noreferrer"">13</a>: <code>drmi</code></a></p>

<blockquote>
  <p>The <code>dangling=true</code> filter finds unused images</p>
</blockquote>

<p>That way, any intermediate image no longer referenced by a labelled image is removed.</p>

<p>I do the same <strong>first</strong> for <a href=""https://github.com/VonC/b2d/blob/b010ab51974ac7de6162cdcbff795d7b9e84fd67/.bash_aliases#L21"" rel=""noreferrer"">exited processes (containers)</a></p>

<pre><code>alias drmae='docker rm $(docker ps -qa --no-trunc --filter ""status=exited"")'
</code></pre>

<p>As <a href=""https://stackoverflow.com/users/95750/haridsv"">haridsv</a> points out <a href=""https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images/32723127#comment63457575_32723127"">in the comments</a>:</p>

<blockquote>
  <p>Technically, <strong>you should first clean up containers before cleaning up images, as this will catch more dangling images and less errors</strong>.</p>
</blockquote>

<hr>

<p><a href=""https://github.com/jfrazelle"" rel=""noreferrer"">Jess Frazelle (jfrazelle)</a> has the <a href=""https://github.com/jfrazelle/dotfiles/blob/a7fd3df6ab423e6dd04f27727f653753453db837/.dockerfunc#L8-L11"" rel=""noreferrer"">bashrc function</a>:</p>

<pre><code>dcleanup(){
    docker rm -v $(docker ps --filter status=exited -q 2&gt;/dev/null) 2&gt;/dev/null
    docker rmi $(docker images --filter dangling=true -q 2&gt;/dev/null) 2&gt;/dev/null
}
</code></pre>

<hr>

<p>To remove old images, and not just ""unreferenced-dangling"" images, you can consider <a href=""https://github.com/spotify/docker-gc"" rel=""noreferrer""><strong><code>docker-gc</code></strong></a>:</p>

<hr>

<blockquote>
  <p>A simple Docker container and image garbage collection script.</p>
  
  <ul>
  <li>Containers that exited more than an hour ago are removed.</li>
  <li>Images that don't belong to any remaining container after that are removed.</li>
  </ul>
</blockquote>
","6309","","6309","","2018-05-18 08:13:28","2018-05-18 08:13:28","","","","32","","","","CC BY-SA 4.0"
"30494050","1","30494145","","2015-05-27 22:17:09","","964","1033237","<p>I'm new to Docker, and it's unclear how to access an external database from a container. Is the best way to hard-code in the connection string?</p>

<pre><code># Dockerfile
ENV DATABASE_URL amazon:rds/connection?string
</code></pre>
","824377","","4574309","","2019-06-13 09:59:17","2021-06-18 01:44:16","How do I pass environment variables to Docker containers?","<docker><environment-variables><dockerfile>","14","0","174","","","CC BY-SA 3.0","30494145","2","","30494050","2015-05-27 22:25:07","","1487","","<p>You can pass environment variables to your containers with the <code>-e</code> flag.</p>

<p>An example from a startup script:</p>

<pre><code>sudo docker run -d -t -i -e REDIS_NAMESPACE='staging' \ 
-e POSTGRES_ENV_POSTGRES_PASSWORD='foo' \
-e POSTGRES_ENV_POSTGRES_USER='bar' \
-e POSTGRES_ENV_DB_NAME='mysite_staging' \
-e POSTGRES_PORT_5432_TCP_ADDR='docker-db-1.hidden.us-east-1.rds.amazonaws.com' \
-e SITE_URL='staging.mysite.com' \
-p 80:80 \
--link redis:redis \  
--name container_name dockerhub_id/image_name
</code></pre>

<p>Or, if you don't want to have the value on the command-line where it will be displayed by <code>ps</code>, etc., <code>-e</code> can pull in the value from the current environment if you just give it without the <code>=</code>:</p>

<pre><code>sudo PASSWORD='foo' docker run  [...] -e PASSWORD [...]
</code></pre>

<p>If you have many environment variables and especially if they're meant to be secret, you can <a href=""https://docs.docker.com/engine/reference/commandline/run/#set-environment-variables--e---env---env-file"">use an env-file</a>:</p>

<pre><code>$ docker run --env-file ./env.list ubuntu bash
</code></pre>

<blockquote>
  <p>The --env-file flag takes a filename as an argument and expects each line to be in the VAR=VAL format, mimicking the argument passed to --env. Comment lines need only be prefixed with #</p>
</blockquote>
","2155313","","498730","","2016-11-29 00:43:16","2016-11-29 00:43:16","","","","9","","","","CC BY-SA 3.0"
"23735149","1","23736802","","2014-05-19 10:15:27","","1066","365069","<p>When using Docker, we start with a base image. We boot it up, create changes and those changes are saved in layers forming another image.</p>

<p>So eventually I have an image for my PostgreSQL instance and an image for my web application, changes to which keep on being persisted.</p>

<p>What is a container?</p>
","84143","","63550","","2019-11-11 14:17:24","2021-04-06 19:52:16","What is the difference between a Docker image and a container?","<docker><docker-container><docker-image>","28","0","353","","","CC BY-SA 4.0","23736802","2","","23735149","2014-05-19 11:40:01","","1415","","<p>An instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.</p>

<p>You can see all your images with <code>docker images</code> whereas you can see your running containers with <code>docker ps</code> (and you can see all containers with <code>docker ps -a</code>).</p>

<p>So a running instance of an image is a container.</p>
","847064","","1723886","","2017-10-20 17:41:57","2017-10-20 17:41:57","","","","13","","","","CC BY-SA 3.0"
"25211198","1","25214186","","2014-08-08 19:48:36","","691","433317","<p>I'm trying to change repository name of the image:</p>

<pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
server              latest              d583c3ac45fd        26 minutes ago      685.5 MB
</code></pre>

<p>Hence I want to change the name <code>server</code> to something like <code>myname/server</code>:</p>

<pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
myname/server       latest              d583c3ac45fd        26 minutes ago      685.5 MB
</code></pre>

<p>How can I do this?</p>
","1349754","","1349754","","2015-01-04 09:56:01","2021-06-28 07:00:57","Docker how to change repository name or rename image?","<docker><linux-containers>","11","4","144","","","CC BY-SA 3.0","25214186","2","","25211198","2014-08-09 00:50:30","","1233","","<pre><code>docker image tag server:latest myname/server:latest
</code></pre>

<p>or</p>

<pre><code>docker image tag d583c3ac45fd myname/server:latest
</code></pre>

<p>Tags are just human-readable aliases for the full image name (<code>d583c3ac45fd...</code>). </p>

<p>So you can have as many of them associated with the same image as you like. If you don't like the old name you can remove it after you've retagged it:</p>

<pre><code>docker rmi server
</code></pre>

<p>That will just remove the <code>alias/tag</code>. Since <code>d583c3ac45fd</code> has other names, the actual image won't be deleted.</p>
","1452016","","746777","","2019-12-21 06:26:30","2019-12-21 06:26:30","","","","5","","","","CC BY-SA 4.0"
"16647069","1","16761439","","2013-05-20 10:05:25","","2140","407093","<p>I use Ubuntu for development and deployment and have a need for creating an isolated environment. </p>

<p>I am considering either Vagrant or Docker for this purpose. What are the pros and cons, or how do these solutions compare?</p>
","780799","","63550","","2016-12-24 22:57:52","2018-11-08 20:22:37","Should I use Vagrant or Docker for creating an isolated environment?","<vagrant><docker>","10","4","1345","2017-05-11 07:20:10","","CC BY-SA 3.0","16761439","2","","16647069","2013-05-26 16:46:10","","1177","","<p>If your purpose is the isolation, I think Docker is what you want.</p>

<p>Vagrant is a virtual machine manager. It allows you to script the virtual machine configuration as well as the provisioning. However, it is still a virtual machine depending on <a href=""http://en.wikipedia.org/wiki/VirtualBox"">VirtualBox</a> (or others) with a huge overhead. It requires you to have a hard drive file that can be huge, it takes a lot of ram, and performance may be not very good.</p>

<p>Docker on the other hand uses kernel cgroup and namespacing via <a href=""https://en.wikipedia.org/wiki/LXC"">LXC</a>. It means that you are using the same kernel as the host and the same file system.
You can use Dockerfile with the <code>docker build</code> command in order to handle the provisioning and configuration of your container. You have an example at <a href=""https://docs.docker.com/"">docs.docker.com</a> on how to make your Dockerfile; it is very intuitive.</p>

<p>The only reason you could want to use Vagrant is if you need to do BSD, Windows or other non-Linux development on your Ubuntu box. Otherwise, go for Docker.</p>
","884978","","63550","","2016-12-24 23:08:09","2016-12-24 23:08:09","","","","10","","","","CC BY-SA 3.0"
"20932357","1","26496854","","2014-01-05 10:13:41","","595","454304","<p>I have a container that is running the Apache service in the foreground. I would like to be able to access the container from another shell in order to ""poke around"" inside it and examine the files. At the moment, if I attach to the container, I am left looking at the Apache daemon and cannot run any commands.</p>

<p>Is it possible to attach another tty to a running container? Possibly, I can take advantage of the fact that Docker is actually just wrapping around LXC containers? I have tried <code>sudo lxc-console -n [container-id] -t [1-4]</code> but it appears that only one tty is made available and that is the one running the apache daemon. Perhaps there is a way to enable multiple lxc consoles during the build?</p>

<p>I would rather <strong>not</strong> configure and build the container with an openssh service if possible.</p>
","1385833","","4802075","","2018-04-20 01:42:17","2021-03-09 22:33:19","How to enter in a Docker container already running with a new TTY","<docker><tty>","11","3","170","","","CC BY-SA 3.0","26496854","2","","20932357","2014-10-21 21:40:50","","1170","","<p>With docker 1.3, there is a new command <a href=""https://docs.docker.com/engine/reference/commandline/exec/"" rel=""noreferrer""><code>docker exec</code></a>. This allows you to enter a running container:</p>
<pre><code>docker exec -it [container-id] bash
</code></pre>
<p><strong>Note:</strong> this assumes <code>bash</code> is installed on your container. You may run <code>sh</code> or whatever interactive shell is installed on the container.</p>
","2297345","","2297345","","2021-03-09 22:33:19","2021-03-09 22:33:19","","","","11","","","","CC BY-SA 4.0"
"30063907","1","30064175","","2015-05-05 21:53:37","","656","577927","<p>I want to do something like this where I can run multiple commands in order.</p>
<pre class=""lang-yaml prettyprint-override""><code>db:
  image: postgres
web:
  build: .
  command: python manage.py migrate
  command: python manage.py runserver 0.0.0.0:8000
  volumes:
    - .:/code
  ports:
    - &quot;8000:8000&quot;
  links:
    - db
</code></pre>
","2587797","","1402846","","2020-09-08 06:36:26","2021-01-29 22:51:34","Using Docker-Compose, how to execute multiple commands","<docker><yaml><docker-compose>","16","0","163","","","CC BY-SA 4.0","30064175","2","","30063907","2015-05-05 22:16:53","","1084","","<p>Figured it out, use <strong><code>bash -c</code></strong>.</p>

<p>Example:</p>

<pre><code>command: bash -c ""python manage.py migrate &amp;&amp; python manage.py runserver 0.0.0.0:8000""
</code></pre>

<p>Same example in multilines:</p>

<pre><code>command: &gt;
    bash -c ""python manage.py migrate
    &amp;&amp; python manage.py runserver 0.0.0.0:8000""
</code></pre>

<p>Or:</p>

<pre><code>command: bash -c ""
    python manage.py migrate
    &amp;&amp; python manage.py runserver 0.0.0.0:8000
  ""
</code></pre>
","2587797","","52499","","2019-07-11 20:24:25","2019-07-11 20:24:25","","","","11","","","","CC BY-SA 4.0"
"44785585","1","44785784","","2017-06-27 16:36:53","","499","330921","<p>I recently started using Docker and never realized that I should use <code>docker-compose down</code> instead of <code>ctrl-c</code> or <code>docker-compose stop</code> to get rid of my experiments. I now have a large number of unneeded docker images locally. </p>

<p>Is there a flag I can run to delete all the local docker images &amp; containers?</p>

<p>Something like <code>docker rmi --all --force</code> --all flag does not exist but I am looking for something with similar idea. </p>
","2335820","","10907864","","2021-01-28 15:43:28","2021-07-01 07:30:42","Docker: How to delete all local Docker images","<docker><docker-compose>","17","4","178","","","CC BY-SA 4.0","44785784","2","","44785585","2017-06-27 16:48:46","","1050","","<p><strong>For Unix</strong></p>
<p>To delete all containers including its volumes use,</p>
<pre><code>docker rm -vf $(docker ps -a -q)
</code></pre>
<p>To delete all the images,</p>
<pre><code>docker rmi -f $(docker images -a -q)
</code></pre>
<p>Remember, you should remove all the containers before removing all the images from which those containers were created.</p>
<p><strong>For Windows</strong></p>
<p>In case you are working on Windows (Powershell),</p>
<pre><code>$images = docker images -a -q
foreach ($image in $images) { docker image rm $image -f }
</code></pre>
<p>Based on the comment from CodeSix, one liner for Windows Powershell,</p>
<pre><code>docker images -a -q | % { docker image rm $_ -f }
</code></pre>
<p>For Windows using command line,</p>
<pre><code>for /F %i in ('docker images -a -q') do docker rmi -f %i
</code></pre>
","1257729","","1549818","","2020-12-14 13:30:16","2020-12-14 13:30:16","","","","11","","","","CC BY-SA 4.0"
"17665283","1","17870293","","2013-07-15 22:56:02","","859","701596","<p>I'm running Docker under Vagrant under OS X 10.8.4  (Mountain Lion), and whenever I try to delete a saved image, I get an error:</p>

<pre><code>$ docker rmi some-image-id
2013/07/15 hh:mm:ss unexpected JSON input
</code></pre>

<p>According to the <code>rmi</code> help, the proper syntax is <code>docker rmi IMAGE [IMAGE...]</code>, and I'm not sure what to make of that.</p>

<p>How can I delete an image?</p>

<pre><code>$ docker version
Client version: 0.4.8
Server version: 0.4.8
Go version: go1.1
</code></pre>

<p> </p>

<pre><code>$docker info
Containers: 1
Images: 3
</code></pre>

<p>Interestingly, when I run <code>docker ps</code>, no containers show up at all. Running <code>docker images</code> shows four (4) <code>base</code> images and one (1) <code>node</code> image.</p>
","1033027","","1797006","","2021-01-24 22:00:30","2021-01-24 22:00:30","How does one remove a Docker image?","<docker>","19","9","264","","","CC BY-SA 4.0","17870293","2","","17665283","2013-07-25 23:09:09","","1028","","<p>Try <code>docker rmi node</code>. That should work. </p>

<p>Seeing all created containers is as simple as <code>docker ps -a</code>. </p>

<p>To remove all existing containers (not images!) run <code>docker rm $(docker ps -aq)</code></p>
","4960","","3109182","","2015-03-23 16:05:05","2015-03-23 16:05:05","","","","5","","","","CC BY-SA 3.0"
"18496940","1","20652410","","2013-08-28 19:45:44","","1028","296210","<p>How do people deal with persistent storage for your Docker containers?</p>

<p>I am currently using this approach: build the image, e.g. for PostgreSQL, and then start the container with</p>

<pre><code>docker run --volumes-from c0dbc34fd631 -d app_name/postgres
</code></pre>

<p>IMHO, that has the drawback, that I must not ever (by accident) delete container ""c0dbc34fd631"".</p>

<p>Another idea would be to mount host volumes ""-v"" into the container, however, the <strong>userid</strong> within the container does not necessarily match the <strong>userid</strong> from the host, and then permissions might be messed up.</p>

<p>Note: Instead of <code>--volumes-from 'cryptic_id'</code> you can also use <code>--volumes-from my-data-container</code> where <code>my-data-container</code> is a name you assigned to a data-only container, e.g. <code>docker run --name my-data-container ...</code> (see the accepted answer)</p>
","226743","","5675325","","2018-10-22 12:19:36","2020-11-27 19:19:08","How to deal with persistent storage (e.g. databases) in Docker","<docker><docker-container>","15","4","594","","","CC BY-SA 4.0","20652410","2","","18496940","2013-12-18 07:50:09","","1000","","<h2>Docker 1.9.0 and above</h2>

<p>Use <a href=""https://docs.docker.com/engine/reference/commandline/volume_create/"" rel=""noreferrer"">volume API</a></p>

<pre><code>docker volume create --name hello
docker run -d -v hello:/container/path/for/volume container_image my_command
</code></pre>

<p>This means that the data-only container pattern must be abandoned in favour of the new volumes.</p>

<p>Actually the volume API is only a better way to achieve what was the data-container pattern.</p>

<p>If you create a container with a <code>-v volume_name:/container/fs/path</code> Docker will automatically create a named volume for you that can:</p>

<ol>
<li>Be listed through the <code>docker volume ls</code></li>
<li>Be identified through the <code>docker volume inspect volume_name</code></li>
<li>Backed up as a normal directory</li>
<li>Backed up as before through a <code>--volumes-from</code> connection</li>
</ol>

<p>The new volume API adds a useful command that lets you identify dangling volumes:</p>

<pre><code>docker volume ls -f dangling=true
</code></pre>

<p>And then remove it through its name:</p>

<pre><code>docker volume rm &lt;volume name&gt;
</code></pre>

<p>As @mpugach underlines in the comments, you can get rid of all the dangling volumes with a nice one-liner:</p>

<pre><code>docker volume rm $(docker volume ls -f dangling=true -q)
# Or using 1.13.x
docker volume prune
</code></pre>

<h2>Docker 1.8.x and below</h2>

<p>The approach that seems to work best for production is to use a <strong>data only container</strong>.</p>

<p>The data only container is run on a barebones image and actually does nothing except exposing a data volume.</p>

<p>Then you can run any other container to have access to the data container volumes:</p>

<pre><code>docker run --volumes-from data-container some-other-container command-to-execute
</code></pre>

<ul>
<li><a href=""http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html"" rel=""noreferrer"">Here</a> you can get a good picture of how to arrange the different containers.</li>
<li><a href=""http://crosbymichael.com/advanced-docker-volumes.html"" rel=""noreferrer"">Here</a> there is a good insight on how volumes work.</li>
</ul>

<p>In <a href=""http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/"" rel=""noreferrer"">this blog post</a> there is a good description of the so-called <strong>container as volume pattern</strong> which clarifies the main point of having <strong>data only containers</strong>.</p>

<p><a href=""https://docs.docker.com/engine/userguide/dockervolumes/"" rel=""noreferrer"">Docker documentation has now the DEFINITIVE description of the <strong>container as volume/s</strong> pattern.</a></p>

<p>Following is the backup/restore procedure for Docker 1.8.x and below.</p>

<p><strong>BACKUP:</strong></p>

<pre><code>sudo docker run --rm --volumes-from DATA -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data
</code></pre>

<ul>
<li>--rm: remove the container when it exits</li>
<li>--volumes-from DATA: attach to the volumes shared by the DATA container</li>
<li>-v $(pwd):/backup: bind mount the current directory into the container; to write the tar file to</li>
<li>busybox: a small simpler image - good for quick maintenance</li>
<li>tar cvf /backup/backup.tar /data: creates an uncompressed tar file of all the files in the /data directory</li>
</ul>

<p><strong>RESTORE:</strong></p>

<pre><code># Create a new data container
$ sudo docker run -v /data -name DATA2 busybox true
# untar the backup files into the new container᾿s data volume
$ sudo docker run --rm --volumes-from DATA2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar
data/
data/sven.txt
# Compare to the original container
$ sudo docker run --rm --volumes-from DATA -v `pwd`:/backup busybox ls /data
sven.txt
</code></pre>

<p>Here is a nice <a href=""http://container42.com/2014/11/18/data-only-container-madness/"" rel=""noreferrer"">article from the excellent Brian Goff</a> explaining why it is good to use the same image for a container and a data container.</p>
","204626","","63550","","2018-07-25 04:47:05","2018-07-25 04:47:05","","","","27","","","","CC BY-SA 4.0"
"48957195","1","48957722","","2018-02-23 22:38:58","","552","438241","<p>I installed Docker in my machine where I have Ubuntu OS.<br />
When I run:</p>
<pre><code>sudo docker run hello-world
</code></pre>
<p>All is ok, but I want to hide the word <code>sudo</code> to make more short the command.<br />
If I write the command without the word <code>sudo</code></p>
<pre><code>docker run hello-world
</code></pre>
<p>That displays the following:</p>
<pre><code>docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.35/containers/create: dial unix /var/run/docker.sock: connect: permission denied. See 'docker run --help'.
</code></pre>
<p>It has happened the same when I try to make:</p>
<pre><code>docker-compose up
</code></pre>
<p>How can I resolve this?</p>
","7288685","","2506522","","2021-05-17 13:18:38","2021-06-13 05:31:52","How to fix docker: Got permission denied issue","<docker><docker-compose>","27","4","150","","","CC BY-SA 4.0","48957722","2","","48957195","2018-02-23 23:40:15","","975","","<p>If you want to run docker as non-root user then you need to add it to the docker group.</p>

<ol>
<li>Create the docker group if it does not exist</li>
</ol>
<pre class=""lang-sh prettyprint-override""><code>$ sudo groupadd docker
</code></pre>
<ol start=""2"">
<li>Add your user to the docker group.</li>
</ol>
<pre class=""lang-sh prettyprint-override""><code>$ sudo usermod -aG docker $USER
</code></pre>
<ol start=""3"">
<li>Run the following command or Logout and login again  and run (that doesn't work you may need to reboot your machine first)</li>
</ol>
<pre class=""lang-sh prettyprint-override""><code>$ newgrp docker

</code></pre>
<ol start=""4"">
<li>Check if docker can be run without root</li>
</ol>
<pre class=""lang-sh prettyprint-override""><code>$ docker run hello-world
</code></pre>
<p>Reboot if still got error</p>
<pre class=""lang-sh prettyprint-override""><code>$ reboot
</code></pre>
<p>Taken from the docker official documentation:
<a href=""https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user"" rel=""noreferrer"">manage-docker-as-a-non-root-user</a></p>
","4375823","","5303119","","2020-09-09 21:13:37","2020-09-09 21:13:37","","","","20","","","","CC BY-SA 4.0"
"18497688","1","18498313","","2013-08-28 20:34:51","","655","987623","<p>After building a Docker image from a <code>dockerfile</code>, I see the image was built successfully, but what do I do with it? Shouldn't i be able to run it as a container?</p>
","949845","","7581507","","2020-08-26 08:50:44","2020-08-26 08:50:44","Run a Docker image as a container","<docker><docker-image>","11","0","120","","","CC BY-SA 4.0","18498313","2","","18497688","2013-08-28 21:14:50","","936","","<p>The specific way to run it depends on whether you gave the image a tag/name or not.</p>

<pre><code>$ docker images
REPOSITORY          TAG                 ID                  CREATED             SIZE
ubuntu              12.04               8dbd9e392a96        4 months ago        131.5 MB (virtual 131.5 MB)
</code></pre>

<p>With a name (let's use <em>Ubuntu</em>):</p>

<pre><code>$ docker run -i -t ubuntu:12.04 /bin/bash
</code></pre>

<p>Without a name, just using the ID:</p>

<pre><code>$ docker run -i -t 8dbd9e392a96 /bin/bash
</code></pre>

<p>Please see <em><a href=""https://docs.docker.com/engine/reference/run/"" rel=""noreferrer"">Docker run reference</a></em> for more information.</p>
","1452016","","63550","","2019-11-17 22:37:07","2019-11-17 22:37:07","","","","6","","","","CC BY-SA 4.0"
"39901311","1","39901446","","2016-10-06 16:33:07","","435","506333","<p>I've got a Docker container running Ubuntu which I did as follows:</p>

<pre><code>docker run -it ubuntu /bin/bash
</code></pre>

<p>however it doesn't seem to have <code>ping</code>. E.g.</p>

<pre><code>bash: ping: command not found
</code></pre>

<p>Do I need to install that?</p>

<p>Seems a pretty basic command to be missing. I tried <code>whereis ping</code> which doesn't report anything.</p>
","343204","","","","","2020-03-23 08:09:18","Docker - Ubuntu - bash: ping: command not found","<ubuntu><docker><ping>","7","2","61","","","CC BY-SA 3.0","39901446","2","","39901311","2016-10-06 16:41:30","","893","","<p>Docker images are pretty minimal, But you can install <code>ping</code> in your official ubuntu docker image via:</p>

<pre><code>apt-get update
apt-get install iputils-ping
</code></pre>

<p>Chances are you dont need <code>ping</code> your image, and just want to use it for testing purposes. Above example will help you out.</p>

<p>But if you need ping to exist on your image, you can create a <code>Dockerfile</code> or <code>commit</code> the container you ran the above commands in to a new image.</p>

<p>Commit:</p>

<pre><code>docker commit -m ""Installed iputils-ping"" --author ""Your Name &lt;name@domain.com&gt;"" ContainerNameOrId yourrepository/imagename:tag
</code></pre>

<p>Dockerfile:</p>

<pre><code>FROM ubuntu
RUN apt-get update &amp;&amp; apt-get install -y iputils-ping
CMD bash
</code></pre>

<p>Please note there are best practices on creating docker images, Like clearing apt cache files after and etc.</p>
","5867722","","5867722","","2016-10-31 04:53:23","2016-10-31 04:53:23","","","","3","","","","CC BY-SA 3.0"
"43099116","1","43099210","","2017-03-29 16:26:14","","594","366454","<p>I am running the following command from my <code>Jenkinsfile</code>. However, I get the error <em>""The input device is not a TTY""</em>.</p>

<pre><code>docker run -v $PWD:/foobar -it cloudfoundry/cflinuxfs2 /foobar/script.sh
</code></pre>

<p>Is there a way to run the script from the <code>Jenkinsfile</code> without doing interactive mode?</p>

<p>I basically have a file called <code>script.sh</code> that I would like to run inside the Docker container.</p>
","654203","","63550","","2018-07-21 18:43:14","2021-06-26 00:20:33","Error ""The input device is not a TTY""","<docker><jenkins><jenkins-pipeline>","13","2","79","","","CC BY-SA 4.0","43099210","2","","43099116","2017-03-29 16:31:12","","885","","<p>Remove the <code>-it</code> from your cli to make it non interactive and remove the TTY. If you don't need either, e.g. running your command inside of a Jenkins or cron script, you should do this.</p>
<p>Or you can change it to <code>-i</code> if you have input piped into the docker command that doesn't come from a TTY. If you have something like <code>xyz | docker ...</code> or <code>docker ... &lt;input</code> in your command line, do this.</p>
<p>Or you can change it to <code>-t</code> if you want TTY support but don't have it available on the input device. Do this for apps that check for a TTY to enable color formatting of the output in your logs, or for when you later attach to the container with a proper terminal.</p>
<p>Or if you need an interactive terminal and aren't running in a terminal on Linux or MacOS, use a different command line interface. PowerShell is reported to include this support on Windows.</p>
<hr />
<p>What is a TTY? It's a terminal interface that supports escape sequences, moving the cursor around, etc, that comes from the old days of dumb terminals attached to mainframes. Today it is provided by the Linux command terminals and ssh interfaces. See the <a href=""https://en.wikipedia.org/wiki/Terminal_emulator"" rel=""noreferrer"">wikipedia article for more details</a>.</p>
<p>To see the difference of running a container with and without a TTY, run a container without one: <code>docker run --rm -i ubuntu bash</code>. From inside that container, install vim with <code>apt-get update; apt-get install vim</code>. Note the lack of a prompt. When running vim against a file, try to move the cursor around within the file.</p>
","596285","","596285","","2021-01-25 15:38:21","2021-01-25 15:38:21","","","","3","","","","CC BY-SA 4.0"
"30853247","1","30859601","","2015-06-15 19:15:56","","622","504666","<p>I successfully shelled to a Docker container using:</p>

<pre><code>docker exec -i -t 69f1711a205e bash
</code></pre>

<p>Now I need to edit file and I don't have any editors inside:</p>

<pre><code>root@69f1711a205e:/# nano
bash: nano: command not found
root@69f1711a205e:/# pico
bash: pico: command not found
root@69f1711a205e:/# vi
bash: vi: command not found
root@69f1711a205e:/# vim
bash: vim: command not found
root@69f1711a205e:/# emacs
bash: emacs: command not found
root@69f1711a205e:/#
</code></pre>

<p>How do I edit files?</p>
","1268964","","3539857","","2020-02-23 16:22:58","2021-05-31 07:53:38","How do I edit a file after I shell to a Docker container?","<docker>","18","6","154","","","CC BY-SA 4.0","30859601","2","","30853247","2015-06-16 05:41:15","","882","","<p>As in the comments, there's no default editor set - strange - the <code>$EDITOR</code> environment variable is empty. You can log in into a container with:</p>

<pre><code>docker exec -it &lt;container&gt; bash
</code></pre>

<p>And run:</p>

<pre><code>apt-get update
apt-get install vim
</code></pre>

<p>Or use the following Dockerfile:</p>

<pre><code>FROM  confluent/postgres-bw:0.1

RUN [""apt-get"", ""update""]
RUN [""apt-get"", ""install"", ""-y"", ""vim""]
</code></pre>

<p>Docker images are delivered trimmed to the bare minimum - so no editor is installed with the shipped container. That's why there's a need to install it manually.</p>

<p><strong>EDIT</strong></p>

<p>I also encourage you read my <a href=""https://blog.softwaremill.com/editing-files-in-a-docker-container-f36d76b9613c"" rel=""noreferrer"">post</a> about the topic.</p>
","542270","","542270","","2018-12-14 12:16:32","2018-12-14 12:16:32","","","","14","","","","CC BY-SA 4.0"
"26504846","1","26504961","","2014-10-22 09:56:24","","460","602429","<p>I have read <a href=""http://docs.docker.com/engine/reference/builder/#add"" rel=""noreferrer"">http://docs.docker.com/engine/reference/builder/#add</a> however I met a problem. I want to copy the local directory <code>go</code> to docker <code>/user/local/</code></p>
<p>I tried:</p>
<pre><code>ADD go /usr/local/
</code></pre>
<p>and:</p>
<pre><code>ADD /go/ /usr/local/ 
</code></pre>
<p>also:</p>
<pre><code>RUN chmod 0755 /usr/local/go/src/make.bash
</code></pre>
<p>However, I see the following error message:</p>
<pre><code>/usr/local/go/src/make.bash: No such file or directory
</code></pre>
<p>but the local <code>go</code> directory does contain <code>make.bash</code>.</p>
","233618","","6862601","","2021-01-28 23:38:30","2021-01-28 23:38:30","Copy directory to another directory using ADD command","<docker>","3","0","60","","","CC BY-SA 4.0","26504961","2","","26504846","2014-10-22 10:03:14","","876","","<pre><code>ADD go /usr/local/
</code></pre>

<p>will copy the <strong>contents</strong> of your local <code>go</code> directory in the <code>/usr/local/</code> directory of your docker image.</p>

<p>To copy the <code>go</code> directory itself in <code>/usr/local/</code> use:</p>

<pre><code>ADD go /usr/local/go
</code></pre>

<p>or </p>

<pre><code>COPY go /usr/local/go
</code></pre>
","107049","","","","","2014-10-22 10:03:14","","","","12","","","","CC BY-SA 3.0"
"20813486","1","20816397","","2013-12-28 10:29:02","","796","723195","<p>I've noticed with docker that I need to understand what's happening inside a container or what files exist in there. One example is downloading images from the docker index - you don't have a clue what the image contains so it's impossible to start the application.</p>

<p>What would be ideal is to be able to ssh into them or equivalent. Is there a tool to do this, or is my conceptualisation of docker wrong in thinking I should be able to do this.</p>
","2668128","","42223","","2017-06-30 23:03:53","2021-06-23 13:15:36","Exploring Docker container's file system","<linux><docker><filesystems>","28","7","307","","","CC BY-SA 3.0","20816397","2","","20813486","2013-12-28 15:56:08","","873","","<p>Here are a couple different methods...</p>
<h3>A) Use docker exec <em>(easiest)</em></h3>
<p>Docker version 1.3 or newer supports the command <code>exec</code> that behave similar to <code>nsenter</code>. This command can run new process in already running container (container must have PID 1 process running already). You can run <code>/bin/bash</code> to explore container state:</p>
<pre><code>docker exec -t -i mycontainer /bin/bash
</code></pre>
<p>see <a href=""https://docs.docker.com/engine/reference/commandline/exec/"" rel=""noreferrer"">Docker command line documentation</a></p>
<h3>B) Use Snapshotting</h3>
<p>You can evaluate container filesystem this way:</p>
<pre><code># find ID of your running container:
docker ps

# create image (snapshot) from container filesystem
docker commit 12345678904b5 mysnapshot

# explore this filesystem using bash (for example)
docker run -t -i mysnapshot /bin/bash
</code></pre>
<p>This way, you can evaluate filesystem of the running container in the precise time moment. Container is still running, no future changes are included.</p>
<p>You can later delete snapshot using (filesystem of the running container is not affected!):</p>
<pre><code>docker rmi mysnapshot
</code></pre>
<h3>C) Use ssh</h3>
<p>If you need continuous access, you can install sshd to your container and run the sshd daemon:</p>
<pre><code> docker run -d -p 22 mysnapshot /usr/sbin/sshd -D
 
 # you need to find out which port to connect:
 docker ps
</code></pre>
<p>This way, you can run your app using ssh (connect and execute what you want).</p>
<h3>D) Use nsenter</h3>
<p>Use <code>nsenter</code>, see <a href=""https://web.archive.org/web/20160305150559/http://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/"" rel=""noreferrer"">Why you don't need to run SSHd in your Docker containers</a></p>
<blockquote>
<p><em>The short version is: with nsenter, you can get a shell into an
existing container, even if that container doesn’t run SSH or any kind
of special-purpose daemon</em></p>
</blockquote>
","39726","","150884","","2020-12-02 11:08:21","2020-12-02 11:08:21","","","","17","","","2018-03-19 12:08:07","CC BY-SA 4.0"
"23111631","1","28093517","","2014-04-16 13:58:32","","349","521381","<p>I installed Docker on my Ubuntu 13.10 (Saucy Salamander) and when I type in my console:</p>

<pre><code>sudo docker pull busybox
</code></pre>

<p>I get the following error:</p>

<pre><code>Pulling repository busybox
2014/04/16 09:37:07 Get https://index.docker.io/v1/repositories/busybox/images: dial tcp: lookup index.docker.io on 127.0.1.1:53: no answer from server
</code></pre>

<p>Docker version:</p>

<pre><code>$ sudo docker version

Client version: 0.10.0
Client API version: 1.10
Go version (client): go1.2.1
Git commit (client): dc9c28f
Server version: 0.10.0
Server API version: 1.10
Git commit (server): dc9c28f
Go version (server): go1.2.1
Last stable version: 0.10.0
</code></pre>

<p>I am behind a proxy server with no authentication, and this is my <code>/etc/apt/apt.conf</code> file:</p>

<pre><code>Acquire::http::proxy ""http://192.168.1.1:3128/"";
Acquire::https::proxy ""https://192.168.1.1:3128/"";
Acquire::ftp::proxy ""ftp://192.168.1.1:3128/"";
Acquire::socks::proxy ""socks://192.168.1.1:3128/"";
</code></pre>

<p>What am I doing wrong?</p>
","2172151","","63550","","2018-09-19 16:43:15","2021-06-12 18:17:08","Cannot download Docker images behind a proxy","<proxy><docker>","27","3","185","","","CC BY-SA 4.0","28093517","2","","23111631","2015-01-22 16:13:29","","867","","<p>Here is a link to the official Docker documentation for proxy HTTP:
<a href=""https://docs.docker.com/config/daemon/systemd/#httphttps-proxy"" rel=""noreferrer"">https://docs.docker.com/config/daemon/systemd/#httphttps-proxy</a></p>

<p>A quick outline:</p>

<p>First, create a systemd drop-in directory for the Docker service:</p>

<pre><code>mkdir /etc/systemd/system/docker.service.d
</code></pre>

<p>Now create a file called <code>/etc/systemd/system/docker.service.d/http-proxy.conf</code> that adds the <code>HTTP_PROXY</code> environment variable:</p>

<pre><code>[Service]
Environment=""HTTP_PROXY=http://proxy.example.com:80/""
</code></pre>

<p>If you have internal Docker registries that you need to contact without proxying you can specify them via the <code>NO_PROXY</code> environment variable:</p>

<pre><code>Environment=""HTTP_PROXY=http://proxy.example.com:80/""
Environment=""NO_PROXY=localhost,127.0.0.0/8,docker-registry.somecorporation.com""
</code></pre>

<p>Flush changes:</p>

<pre><code>$ sudo systemctl daemon-reload
</code></pre>

<p>Verify that the configuration has been loaded:</p>

<pre><code>$ sudo systemctl show --property Environment docker
Environment=HTTP_PROXY=http://proxy.example.com:80/
</code></pre>

<p>Restart Docker:</p>

<pre><code>$ sudo systemctl restart docker
</code></pre>
","1819355","","63550","","2018-09-25 10:54:01","2018-09-25 10:54:01","","","","22","","","","CC BY-SA 4.0"
"20845056","1","20851484","","2013-12-30 18:13:44","","557","355278","<p>So I have 3 ports that should be exposed to the machine's interface. Is it possible to do this with a Docker container?</p>
","118644","","3340702","","2017-10-09 15:58:55","2021-02-09 10:54:39","How can I expose more than 1 port with Docker?","<docker><docker-networking>","5","1","109","","","CC BY-SA 3.0","20851484","2","","20845056","2013-12-31 03:57:54","","862","","<p>To expose just one port, this is what you need to do:</p>

<pre><code>docker run -p &lt;host_port&gt;:&lt;container_port&gt;
</code></pre>

<p>To expose multiple ports, simply provide multiple <code>-p</code> arguments:</p>

<pre><code>docker run -p &lt;host_port1&gt;:&lt;container_port1&gt; -p &lt;host_port2&gt;:&lt;container_port2&gt;
</code></pre>
","316075","","1066031","","2014-08-21 22:46:25","2014-08-21 22:46:25","","","","7","","","","CC BY-SA 3.0"
"22111060","1","22150099","","2014-03-01 06:35:53","","619","229597","<p>I'm experimenting with Dockerfiles, and I think I understand most of the logic. However, I don't see the difference between ""exposing"" and ""publishing"" a port in this context.</p>

<p>All the tutorials I have seen first include the <code>EXPOSE</code> command in the Dockerfile:</p>

<pre><code>...
EXPOSE 8080
...
</code></pre>

<p>They then build an image from this Dockerfile:</p>

<pre><code>$ docker build -t an_image - &lt; Dockerfile
</code></pre>

<p>And then <em>publish</em> the same port as above when running the image:</p>

<pre><code>$ docker run -d -p 8080 an_image
</code></pre>

<p>or publish all ports using</p>

<pre><code>$ docker run -d -P an_image
</code></pre>

<p>What is the point of exposing a port in the Dockerfile, if it will be published anyway? Would there ever be a need to expose a port first, and <em>not</em> publish it later? Effectively, I would like to specify all the ports that I will use in the Dockerfile when creating the image, and then not bother with them again, running them simply with:</p>

<pre><code>$ docker run -d an_image
</code></pre>

<p>Is this possible?</p>
","1496984","","895245","","2018-04-02 16:57:18","2021-05-24 04:00:47","What is the difference between ""expose"" and ""publish"" in Docker?","<docker>","6","0","190","","","CC BY-SA 3.0","22150099","2","","22111060","2014-03-03 15:02:08","","828","","<p>Basically, you have three options:</p>

<ol>
<li>Neither specify <code>EXPOSE</code> nor <code>-p</code></li>
<li>Only specify <code>EXPOSE</code></li>
<li>Specify <code>EXPOSE</code> and <code>-p</code></li>
</ol>

<p>1) If you specify neither <code>EXPOSE</code> nor <code>-p</code>, the service in the container will only be accessible from <em>inside</em> the container itself.</p>

<p>2) If you <code>EXPOSE</code> a port, the service in the container is not accessible from outside Docker, but from inside other Docker containers. So this is good for inter-container communication.</p>

<p>3) If you <code>EXPOSE</code> and <code>-p</code> a port, the service in the container is accessible from anywhere, even outside Docker.</p>

<p>The reason why both are separated is IMHO because:</p>

<ul>
<li>choosing a host port depends on the host and hence does not belong to the Dockerfile (otherwise it would be depending on the host),</li>
<li>and often it's enough if a service in a container is accessible from other containers.</li>
</ul>

<p>The <a href=""https://docs.docker.com/engine/reference/builder/#expose"" rel=""noreferrer"">documentation</a> explicitly states:</p>

<blockquote>
  <p>The <code>EXPOSE</code> instruction exposes ports for use within links.</p>
</blockquote>

<p>It also points you to how to <a href=""https://docs.docker.com/userguide/dockerlinks/"" rel=""noreferrer"">link containers</a>, which basically is the inter-container communication I talked about.</p>

<p>PS: If you do <code>-p</code>, but do not <code>EXPOSE</code>, Docker does an implicit <code>EXPOSE</code>. This is because if a port is open to the public, it is automatically also open to other Docker containers. Hence <code>-p</code> includes <code>EXPOSE</code>. That's why I didn't list it above as a fourth case.</p>
","1333873","","11354266","","2019-08-02 20:07:22","2019-08-02 20:07:22","","","","15","","","","CC BY-SA 4.0"
"41984399","1","41984666","","2017-02-01 16:08:53","","528","430925","<p>I am following <a href=""https://docs.docker.com/engine/getstarted/step_four/"" rel=""noreferrer"">this link</a> to create my first docker Image and it went successfully and now I am trying to push this Image into my docker repository from this <a href=""https://docs.docker.com/engine/getstarted/step_six/"" rel=""noreferrer"">link</a>. But whenever I am trying to push this Image into repository , I  got this type of error. </p>

<pre><code>denied: requested access to the resource is denied
</code></pre>

<p><a href=""https://i.stack.imgur.com/GCu19.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/GCu19.png"" alt=""enter image description here""></a></p>

<p>Could anyone give me some hint towards this problem ? Any help would appreciated.</p>

<p>Note: I have successfully login into docker </p>
","2693841","","","","","2021-05-17 07:37:10","denied: requested access to the resource is denied : docker","<docker><dockerfile>","53","3","104","","","CC BY-SA 3.0","41984666","2","","41984399","2017-02-01 16:22:45","","821","","<p>You may need to switch your docker repo to private before docker push.</p>

<p>Thanks to the <a href=""https://stackoverflow.com/a/42403423/4096935"">answer</a> provided by <a href=""https://stackoverflow.com/users/7607604/dean-wu"">Dean Wu</a> and <a href=""https://stackoverflow.com/questions/41984399/denied-requested-access-to-the-resource-is-denied-docker/41984666#comment94770203_41984666"">this comment</a> by <a href=""https://stackoverflow.com/users/369759/ses"">ses</a>, before pushing, remember to <strong>log out</strong>, then <strong>log in</strong> from the command line to your docker hub account</p>

<pre><code># you may need log out first `docker logout` ref. https://stackoverflow.com/a/53835882/248616
docker login
</code></pre>

<p>According to the <a href=""https://docs.docker.com/engine/getstarted/step_six/#/step-1-tag-and-push-the-image"" rel=""noreferrer"">docs</a>:</p>

<pre><code>You need to include the namespace for Docker Hub to associate it with your account.
The namespace is the same as your Docker Hub account name.
You need to rename the image to YOUR_DOCKERHUB_NAME/docker-whale.
</code></pre>

<p>So, this means you have to <strong>tag</strong> your image before pushing:</p>

<pre><code>docker tag firstimage YOUR_DOCKERHUB_NAME/firstimage
</code></pre>

<p>and then you should be able to push it.</p>

<pre><code>docker push YOUR_DOCKERHUB_NAME/firstimage
</code></pre>
","4096935","","248616","","2020-03-04 14:45:35","2020-03-04 14:45:35","","","","19","","","","CC BY-SA 4.0"
"28996907","1","28997256","","2015-03-11 20:40:21","","398","266842","<p>Trying to follow the instructions for building a docker image from the docker website.</p>

<p><a href=""https://docs.docker.com/examples/running_redis_service/"">https://docs.docker.com/examples/running_redis_service/</a></p>

<p>this is the error I get will following the instructions on the doc and using this Dockerfile</p>

<pre><code>FROM        ubuntu:14.04
RUN         apt-get update &amp;&amp; apt-get install -y redis-server
EXPOSE      6379
ENTRYPOINT  [""/usr/bin/redis-server""]


sudo docker build -t myrepo/redis
docker: ""build"" requires 1 argument. See 'docker build --help'.
</code></pre>

<p>How do  resolve?</p>
","1203556","","3467532","","2017-07-25 16:08:05","2020-10-23 16:28:25","docker: ""build"" requires 1 argument. See 'docker build --help'","<docker><containers>","14","0","42","","","CC BY-SA 3.0","28997256","2","","28996907","2015-03-11 21:00:04","","819","","<p>You need to add a dot, which means to use the Dockerfile in the local directory.</p>
<p>For example:</p>
<p><code>docker build -t mytag .</code></p>
<p>It means you use the Dockerfile in the local directory, and if you use docker 1.5 you can specify a Dockerfile elsewhere. Extract from the help output from docker build:</p>
<p><code>-f, --file=&quot;&quot;        Name of the Dockerfile(Default is 'Dockerfile' at context root)</code></p>
","2915097","","284598","","2020-08-31 02:12:52","2020-08-31 02:12:52","","","","9","","","","CC BY-SA 4.0"
"27093612","1","38742545","","2014-11-23 19:58:33","","511","308371","<p>I have a dockerfile that download and builds GTK from source, but the following line is not updating my image's environment variable:</p>

<pre><code>RUN PATH=""/opt/gtk/bin:$PATH""
RUN export PATH
</code></pre>

<p>I read that that I should be using ENV to set environment values, but the following instruction doesn't seem to work either:</p>

<p><code>ENV PATH /opt/gtk/bin:$PATH</code></p>

<p>This is my entire Dockerfile:</p>

<pre><code>FROM ubuntu
RUN apt-get update
RUN apt-get install -y golang gcc make wget git libxml2-utils libwebkit2gtk-3.0-dev libcairo2 libcairo2-dev libcairo-gobject2 shared-mime-info libgdk-pixbuf2.0-* libglib2-* libatk1.0-* libpango1.0-* xserver-xorg xvfb

# Downloading GTKcd
RUN wget http://ftp.gnome.org/pub/gnome/sources/gtk+/3.12/gtk+-3.12.2.tar.xz
RUN tar xf gtk+-3.12.2.tar.xz
RUN cd gtk+-3.12.2

# Setting environment variables before running configure
RUN CPPFLAGS=""-I/opt/gtk/include""
RUN LDFLAGS=""-L/opt/gtk/lib""
RUN PKG_CONFIG_PATH=""/opt/gtk/lib/pkgconfig""
RUN export CPPFLAGS LDFLAGS PKG_CONFIG_PATH
RUN ./configure --prefix=/opt/gtk
RUN make
RUN make install

# running ldconfig after make install so that the newly installed libraries are found.
RUN ldconfig

# Setting the LD_LIBRARY_PATH environment variable so the systems dynamic linker can find the newly installed libraries.
RUN LD_LIBRARY_PATH=""/opt/gtk/lib""

# Updating PATH environment program so that utility binaries installed by the various libraries will be found.
RUN PATH=""/opt/gtk/bin:$PATH""
RUN export LD_LIBRARY_PATH PATH

# Collecting garbage
RUN rm -rf gtk+-3.12.2.tar.xz

# creating go code root
RUN mkdir gocode
RUN mkdir gocode/src
RUN mkdir gocode/bin
RUN mkdir gocode/pkg

# Setting the GOROOT and GOPATH enviornment variables, any commands created are automatically added to PATH
RUN GOROOT=/usr/lib/go
RUN GOPATH=/root/gocode
RUN PATH=$GOPATH/bin:$PATH
RUN export GOROOT GOPATH PATH
</code></pre>
","1315565","","402884","","2015-11-18 21:22:13","2020-12-03 03:02:22","In a Dockerfile, How to update PATH environment variable?","<docker><dockerhub>","4","3","63","","","CC BY-SA 3.0","38742545","2","","27093612","2016-08-03 11:39:55","","804","","<p>You can use <a href=""https://docs.docker.com/engine/reference/builder/#environment-replacement"" rel=""noreferrer"">Environment Replacement</a> in your <code>Dockerfile</code> as follows:</p>

<pre><code>ENV PATH=""/opt/gtk/bin:${PATH}""
</code></pre>
","939125","","939125","","2017-03-30 15:24:39","2017-03-30 15:24:39","","","","7","","","","CC BY-SA 3.0"
"27273412","1","27273543","","2014-12-03 13:50:37","","368","210527","<p>I installed Ubuntu 14.04 image on docker. After that, when I try to install packages inside the ubuntu image, I'm getting unable to locate package error: </p>

<pre><code>apt-get install curl

Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Unable to locate package curl
</code></pre>

<p>How to fix this error?</p>
","2424871","","60002","","2016-07-02 15:45:51","2021-05-24 14:24:03","Cannot install packages inside docker Ubuntu image","<docker><ubuntu-14.04>","6","0","78","","","CC BY-SA 3.0","27273543","2","","27273412","2014-12-03 13:56:57","","758","","<p>It is because there is no package cache in the image, you need to run:</p>

<pre><code>apt-get update
</code></pre>

<p>before installing packages, and if your command is in a Dockerfile, you'll then need:</p>

<pre><code>apt-get -y install curl
</code></pre>

<p>To suppress the standard output from a command use <code>-qq</code>. E.g.</p>

<pre><code>apt-get -qq -y install curl
</code></pre>
","1169435","","7872793","","2018-06-08 15:59:51","2018-06-08 15:59:51","","","","5","","","","CC BY-SA 4.0"
"28349392","1","28349540","","2015-02-05 16:42:49","","488","480535","<p>I have a docker image tagged as <code>me/my-image</code>, and I have a private repo on the dockerhub named <code>me-private</code>.<br>
When I push my <code>me/my-image</code>, I end up always hitting the public repo.</p>

<p>What is the exact syntax to specifically push my image to my private repo? </p>
","518012","","448591","","2020-04-29 17:40:52","2021-02-14 17:11:22","How to push a docker image to a private repository","<docker><docker-registry>","10","4","157","","","CC BY-SA 4.0","28349540","2","","28349392","2015-02-05 16:49:10","","748","","<p>You need to tag your image correctly first with your <code>registryhost</code>:</p>

<pre><code>docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]
</code></pre>

<p>Then docker push using that same tag.</p>

<pre><code>docker push NAME[:TAG]
</code></pre>

<p>Example:</p>

<pre><code>docker tag 518a41981a6a myRegistry.com/myImage
docker push myRegistry.com/myImage
</code></pre>
","47110","","916892","","2017-07-14 16:36:55","2017-07-14 16:36:55","","","","8","","","","CC BY-SA 3.0"
"19688314","1","19689048","","2013-10-30 16:20:14","","517","409332","<p>I can attach to a docker process but <kbd>Ctrl</kbd>+<kbd>c</kbd> doesn't work to detach from it. <code>exit</code> basically halts the process. </p>

<p>What's the recommended workflow to have the process running, occasionally attaching to it to make some changes, and then detaching?</p>
","671573","","33204","","2014-10-17 14:22:03","2020-07-01 18:36:26","How do you attach and detach from Docker's process?","<docker>","15","2","169","","","CC BY-SA 3.0","19689048","2","","19688314","2013-10-30 16:52:08","","743","","<p>To detach the tty without exiting the shell, use the escape sequence <kbd>Ctrl</kbd>+<kbd>P</kbd> followed by <kbd>Ctrl</kbd>+<kbd>Q</kbd>. More details <a href=""https://docs.docker.com/engine/reference/commandline/attach/"" rel=""noreferrer"">here</a>.</p>

<p>Additional info from <a href=""https://groups.google.com/forum/#!msg/docker-user/nWXAnyLP9-M/kbv-FZpF4rUJ"" rel=""noreferrer"">this source</a>:</p>

<ul>
<li>docker run -t -i → can be detached with <code>^P^Q</code>and reattached with docker attach</li>
<li>docker run -i → cannot be detached with <code>^P^Q</code>; will disrupt stdin</li>
<li>docker run → cannot be detached with <code>^P^Q</code>; can SIGKILL client; can reattach with docker attach</li>
</ul>
","356788","","7487335","","2020-01-31 19:28:04","2020-01-31 19:28:04","","","","16","","","","CC BY-SA 4.0"
"47536536","1","47537046","","2017-11-28 16:34:31","","448","92539","<p>While diving into Docker, Google Cloud and Kubernetes, and without clearly understanding all three of them yet, it seems to me these products are overlapping, yet they're not compatible.</p>

<p>For example, a <code>docker-compose.yml</code> file needs to be re-written so an app can be deployed to Kubernetes.</p>

<p>Could someone provide a high-level, rough description of where Docker, Docker Compose, Docker Cloud, and Kubernetes overlap and where one is dependent on the other?</p>
","458060","","458060","","2020-12-10 16:08:49","2021-06-24 01:02:52","What's the difference between Docker Compose and Kubernetes?","<docker><kubernetes><docker-compose>","5","0","147","","2021-05-18 12:55:54","CC BY-SA 4.0","47537046","2","","47536536","2017-11-28 17:00:29","","684","","<p><strong><a href=""https://www.docker.com/"" rel=""noreferrer"">Docker</a></strong>:</p>

<ul>
<li>Docker is the container technology that allows you to containerize your applications.</li>
<li>Docker is the core of using other technologies.</li>
</ul>

<p><strong><a href=""https://docs.docker.com/compose/"" rel=""noreferrer"">Docker Compose</a></strong></p>

<ul>
<li>Docker Compose allows configuring and starting multiple Docker containers.</li>
<li>Docker Compose is mostly used as a helper when you want to start multiple Docker containers and don't want to start each one separately using <code>docker run ...</code>.</li>
<li>Docker Compose is used for starting containers on the <strong>same</strong> host.</li>
<li>Docker Compose is used <strong>instead of all optional parameters</strong> when building and running a single docker container.</li>
</ul>

<p><strong><a href=""https://docs.docker.com/engine/swarm/"" rel=""noreferrer"">Docker Swarm</a></strong></p>

<ul>
<li>Docker Swarm is for running and connecting containers on <strong>multiple</strong> hosts.</li>
<li>Docker Swarm is a container cluster management and orchestration tool.</li>
<li>It manages containers running on multiple hosts and does things like scaling, starting a new container when one crashes, networking containers ...</li>
<li>Docker Swarm is Docker in production.
It is the <strong>native</strong> Docker <strong>orchestration tool</strong> that is embedded in the Docker Engine.</li>
<li>The Docker Swarm file named stack file is very similar to a Docker Compose file.</li>
</ul>

<p><strong><a href=""https://kubernetes.io/"" rel=""noreferrer"">Kubernetes</a></strong></p>

<ul>
<li>Kubernetes is a <strong>container orchestration tool</strong> developed by Google.</li>
<li>Kubernetes' goal is very similar to that for Docker Swarm.</li>
</ul>

<p><strong><a href=""https://cloud.docker.com/"" rel=""noreferrer"">Docker Cloud</a></strong></p>

<ul>
<li>A <a href=""https://cloud.docker.com/pricing/"" rel=""noreferrer"">paid</a> enterprise docker service that allows you to build and run containers on cloud servers or local servers.</li>
<li>It provides a Web UI and a central control panel to run and manage containers while providing all the Docker features in a user-friendly web interface.</li>
</ul>

<p><strong>Update:</strong></p>

<p><a href=""https://success.docker.com/article/cloud-migration"" rel=""noreferrer"">Docker cloud ""partially"" discontinued</a></p>

<blockquote>
  <p>The services on Docker Cloud that provide application, node, and swarm cluster management will be shutting down on May 21 [2020]...
  automated builds and registry storage services, will not be affected and will continue to be available</p>
</blockquote>
","6603816","","775954","","2020-05-29 20:27:19","2020-05-29 20:27:19","","","","8","","","2021-05-18 12:55:54","CC BY-SA 4.0"
"19234831","1","25978888","","2013-10-07 21:08:48","","944","946034","<p>I managed to find the containers under directory <code>/var/lib/docker/containers</code>, but I can't find the images.</p>

<p>What are the directories and files under <code>/var/lib/docker</code>?</p>
","714179","","63550","","2017-03-29 16:26:02","2021-05-26 15:51:44","Where are Docker images stored on the host machine?","<docker><docker-image>","29","1","271","","","CC BY-SA 3.0","25978888","2","","19234831","2014-09-22 16:31:39","","676","","<p>The contents of the <code>/var/lib/docker</code> directory vary depending on the <a href=""https://github.com/docker/docker/blob/990a3e30fa66e7bd3df3c78c873c97c5b1310486/daemon/graphdriver/driver.go#L37-L43"" rel=""noreferrer"">driver Docker is using for storage</a>. </p>

<p>By default this will be <code>aufs</code> but can fall back to <code>overlay</code>, <code>overlay2</code>, <code>btrfs</code>, <code>devicemapper</code> or <code>zfs</code> depending on your kernel support. In most places this will be <code>aufs</code> but the <a href=""http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/"" rel=""noreferrer"">RedHats went with <code>devicemapper</code></a>.</p>

<p>You can manually set the storage driver with the <a href=""https://docs.docker.com/engine/reference/commandline/dockerd/#/daemon-storage-driver-option"" rel=""noreferrer""><code>-s</code> or <code>--storage-driver=</code></a> option to the <a href=""https://docs.docker.com/engine/reference/commandline/dockerd/"" rel=""noreferrer"">Docker daemon</a>. </p>

<ul>
<li><code>/var/lib/docker/{driver-name}</code> will contain the driver specific storage for contents of the images. </li>
<li><code>/var/lib/docker/graph/&lt;id&gt;</code> now only contains metadata about the image, in the <code>json</code> and <code>layersize</code> files.</li>
</ul>

<p>In the case of <code>aufs</code>:</p>

<ul>
<li><code>/var/lib/docker/aufs/diff/&lt;id&gt;</code> has the file contents of the images.</li>
<li><code>/var/lib/docker/repositories-aufs</code> is a JSON file containing local image information. This can be viewed with the command <code>docker images</code>.</li>
</ul>

<p>In the case of <code>devicemapper</code>:</p>

<ul>
<li><code>/var/lib/docker/devicemapper/devicemapper/data</code> stores the images</li>
<li><code>/var/lib/docker/devicemapper/devicemapper/metadata</code> the metadata</li>
<li>Note these files are thin provisioned ""sparse"" files so aren't as big as they seem.</li>
</ul>
","44437","","1318694","","2017-02-13 22:15:05","2017-02-13 22:15:05","","","","11","","","2014-09-22 16:31:39","CC BY-SA 3.0"
"27380641","1","33023527","","2014-12-09 13:55:10","","317","205799","<p>How can I see the full command of a running container/process in Docker?</p>

<pre><code>$ docker ps --all
CONTAINER ID    IMAGE          COMMAND                 CREATED          STATUS                     PORTS    NAMES
5b6291859b61    nginx:1.7.8    ""nginx -g 'daemon of    4 minutes ago    Exited (0) 4 minutes ago            thirsty_brattain
</code></pre>

<p>I can only see ""nginx -g 'daemon of"".. here, not the full command.</p>
","1258192","","63550","","2018-07-23 19:48:29","2020-03-04 09:55:36","See full command of running/stopped container in Docker","<docker>","6","1","64","","","CC BY-SA 4.0","33023527","2","","27380641","2015-10-08 18:39:37","","664","","<p><code>docker ps --no-trunc</code> will display the full command along with the other details of the running containers.</p>
","1378202","","1378202","","2020-02-19 02:16:57","2020-02-19 02:16:57","","","","6","","","","CC BY-SA 4.0"
"24718706","1","29913462","","2014-07-13 01:10:38","","234","175529","<p>I'm trying to backup/restore a PostgreSQL database as is explained on the Docker website, but the data is not restored.</p>

<p>The volumes used by the database image are:</p>

<pre><code>VOLUME  [""/etc/postgresql"", ""/var/log/postgresql"", ""/var/lib/postgresql""]
</code></pre>

<p>and the CMD is:</p>

<pre><code>CMD [""/usr/lib/postgresql/9.3/bin/postgres"", ""-D"", ""/var/lib/postgresql/9.3/main"", ""-c"", ""config_file=/etc/postgresql/9.3/main/postgresql.conf""]
</code></pre>

<p>I create the DB container with this command:</p>

<pre><code>docker run -it --name ""$DB_CONTAINER_NAME"" -d ""$DB_IMAGE_NAME""
</code></pre>

<p>Then I connect another container to insert some data manually:</p>

<pre><code>docker run -it --rm --link ""$DB_CONTAINER_NAME"":db ""$DB_IMAGE_NAME"" sh -c 'exec bash'
psql -d test -h $DB_PORT_5432_TCP_ADDR
# insert some data in the db
&lt;CTRL-D&gt;
&lt;CTRL-D&gt;
</code></pre>

<p>The tar archive is then created:</p>

<pre><code>$ sudo docker run --volumes-from ""$DB_CONTAINER_NAME"" --rm -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /etc/postgresql /var/log/postgresql /var/lib/postgresql
</code></pre>

<p>Now I remove the container used for the db and create another one, with the same name, and try to restore the data inserted before:</p>

<pre><code>$ sudo docker run --volumes-from ""$DB_CONTAINER_NAME"" --rm -v $(pwd):/backup ubuntu tar xvf /backup/backup.tar 
</code></pre>

<p>But the tables are empty, why is the data not properly restored ?</p>
","2512774","","31493","","2016-07-06 20:51:56","2020-09-07 12:25:42","Backup/Restore a dockerized PostgreSQL database","<database><postgresql><backup><docker>","10","1","166","","","CC BY-SA 3.0","29913462","2","","24718706","2015-04-28 07:50:24","","640","","<h2>Backup your databases</h2>

<pre><code>docker exec -t your-db-container pg_dumpall -c -U postgres &gt; dump_`date +%d-%m-%Y""_""%H_%M_%S`.sql
</code></pre>

<h2>Restore your databases</h2>

<pre><code>cat your_dump.sql | docker exec -i your-db-container psql -U postgres
</code></pre>
","4840952","","46914","","2018-08-28 20:00:03","2018-08-28 20:00:03","","","","14","","","","CC BY-SA 4.0"
"36710459","1","36710513","","2016-04-19 06:42:05","","510","181352","<p>I am writing a Dockerfile. Is there a way to make comments in this file?</p>

<p>Does Docker have a comment option that takes the rest of a line and ignores it?</p>
","2334254","","63550","","2019-04-02 20:59:50","2021-04-03 04:28:25","How do I make a comment in a Dockerfile?","<docker><dockerfile>","7","1","36","","","CC BY-SA 4.0","36710513","2","","36710459","2016-04-19 06:45:25","","639","","<p>You can use <code>#</code> at the beginning of a line to start a <a href=""https://docs.docker.com/engine/reference/builder/#format"" rel=""noreferrer"">comment</a> (whitespaces before <code>#</code> are allowed):</p>
<pre class=""lang-dockerfile prettyprint-override""><code># do some stuff
RUN apt-get update \
    # install some packages
    &amp;&amp; apt-get install -y cron
</code></pre>
<p><code>#</code>'s in the middle of a string are passed to the command itself, e.g.:</p>
<pre class=""lang-dockerfile prettyprint-override""><code>RUN echo 'we are running some # of cool things'
</code></pre>
","4139856","","709537","","2021-04-03 04:28:25","2021-04-03 04:28:25","","","","4","","","","CC BY-SA 4.0"
"26852321","1","37479753","","2014-11-10 20:20:55","","252","85035","<p>I see that Docker has added something called restarting policies to handle restart of containers in case of, for instance, reboot.</p>

<p>While this is very useful, I see that the restart policy command just work with <code>docker run</code> and not <code>docker start</code>. So my question is:</p>

<p>Is there any way to add restarting policies to a container that was already created in the past?</p>
","392684","","","","","2019-07-14 14:03:14","Docker: Add a restart policy to a container that was already created","<docker>","3","1","40","","","CC BY-SA 3.0","37479753","2","","26852321","2016-05-27 09:24:48","","634","","<p>In recent versions of docker (as of 1.11) you have an <a href=""https://docs.docker.com/engine/reference/commandline/update/#/update-a-container-s-restart-policy"" rel=""noreferrer""><code>update</code></a> command:</p>

<pre><code>docker update --restart=always &lt;container&gt;
</code></pre>
","4808184","","4808184","","2017-01-25 16:57:11","2017-01-25 16:57:11","","","","9","","","","CC BY-SA 3.0"
"30209776","1","30209974","","2015-05-13 08:41:06","","423","552640","<p>According to tutorial I read so far, use ""<code>docker run -d</code>"" will start a container from image, and the container will run in background. This is how it looks like, we can see we already have container id.</p>

<pre><code>root@docker:/home/root# docker run -d centos
605e3928cdddb844526bab691af51d0c9262e0a1fc3d41de3f59be1a58e1bd1d
</code></pre>

<p>But if I ran ""<strong><code>docker ps</code></strong>"", nothing was returned.</p>

<p>So I tried ""<strong><code>docker ps -a</code></strong>"", I can see container already exited:</p>

<pre><code>root@docker:/home/root# docker ps -a
CONTAINER ID        IMAGE                 COMMAND             CREATED             STATUS                         PORTS               NAMES
605e3928cddd        centos:latest         ""/bin/bash""         31 minutes ago      Exited (0) 31 minutes ago                          kickass_swartz
</code></pre>

<p>Anything I did wrong? How can I troubleshoot this issue?</p>
","4414185","","6309","","2015-05-13 08:55:15","2021-06-20 08:33:54","Docker container will automatically stop after ""docker run -d""","<docker>","18","2","136","","","CC BY-SA 3.0","30209974","2","","30209776","2015-05-13 08:51:05","","620","","<p>The <a href=""https://github.com/CentOS/sig-cloud-instance-images/blob/d779d7567c6b3ae1b1b86d1049bab22e2a087c0f/docker/Dockerfile"" rel=""noreferrer"">centos dockerfile</a> has a default command <code>bash</code>.</p>
<p>That means, when run in background (<code>-d</code>), the shell exits immediately.</p>
<p><strong>Update 2017</strong></p>
<p>More recent versions of docker authorize to run a container both in <a href=""https://docs.docker.com/engine/reference/run/#detached--d"" rel=""noreferrer"">detached mode</a> <em>and</em> in <a href=""https://docs.docker.com/engine/reference/run/#foreground"" rel=""noreferrer"">foreground mode</a> (<code>-t</code>, <code>-i</code> or <code>-it</code>)</p>
<p>In that case, you don't need any additional command and this is enough:</p>
<pre><code>docker run -t -d centos
</code></pre>
<p>The bash will wait in the background.<br />
That was initially reported in <a href=""https://stackoverflow.com/users/5887772/kalyani-chaudhari"">kalyani-chaudhari</a>'s <a href=""https://stackoverflow.com/a/44369575/6309"">answer</a> and detailed in <a href=""https://stackoverflow.com/users/4143840/jersey-bean"">jersey bean</a>'s <a href=""https://stackoverflow.com/a/46442758/6309"">answer</a>.</p>
<pre><code>vonc@voncvb:~$ d ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
4a50fd9e9189        centos              &quot;/bin/bash&quot;         8 seconds ago       Up 2 seconds                            wonderful_wright
</code></pre>
<p>Note that for <strong><a href=""https://hub.docker.com/_/alpine"" rel=""noreferrer"">alpine</a></strong>, <a href=""https://stackoverflow.com/users/1555615/marinos-an"">Marinos An</a> reports <a href=""https://stackoverflow.com/questions/30209776/docker-container-will-automatically-stop-after-docker-run-d/30209974#comment97061884_30209974"">in the comments</a>:</p>
<blockquote>
<p><code>docker run -t -d alpine/git</code> does not keep the process up.<br />
Had to do: <code>docker run --entrypoint &quot;/bin/sh&quot; -it alpine/git</code></p>
</blockquote>
<hr />
<p>Original answer (2015)</p>
<p>As mentioned in <a href=""http://kimh.github.io/blog/en/docker/gotchas-in-writing-dockerfile-en/#hack_to_run_container_in_the_background"" rel=""noreferrer"">this article</a>:</p>
<blockquote>
<p>Instead of running with <code>docker run -i -t image your-command</code>, using <code>-d</code> is recommended because you can run your container with just one command and you don’t need to detach terminal of container by hitting <kbd>Ctrl</kbd> + <kbd>P</kbd> + <kbd>Q</kbd>.</p>
</blockquote>
<blockquote>
<p>However, there is a problem with <code>-d</code> option. <strong>Your container immediately stops unless the commands keep running in foreground</strong>.<br />
Docker requires your command to keep running in the foreground. Otherwise, it thinks that your applications stops and shutdown the container.</p>
</blockquote>
<blockquote>
<p>The problem is that some application does not run in the foreground. How can we make it easier?</p>
</blockquote>
<blockquote>
<p>In this situation, you can add <code>tail -f /dev/null</code> to your command.<br />
By doing this, even if your main command runs in the background, your container doesn’t stop because tail is keep running in the foreground.</p>
</blockquote>
<p>So this would work:</p>
<pre><code>docker run -d centos tail -f /dev/null
</code></pre>
<p>Or in Dockerfile:</p>
<pre><code>ENTRYPOINT [&quot;tail&quot;]
CMD [&quot;-f&quot;,&quot;/dev/null&quot;]
</code></pre>
<p>A <code>docker ps</code> would show the centos container still running.</p>
<p>From there, you can <a href=""https://stackoverflow.com/q/25267372/6309"">attach to it or detach from it</a> (or <code>docker exec</code> some commands).</p>
","6309","","5079799","","2021-03-10 05:24:06","2021-03-10 05:24:06","","","","15","","","","CC BY-SA 4.0"
"44084846","1","44719239","","2017-05-20 10:36:15","","275","182741","<p>I normally prefer to manage my apps on my OSX with brew</p>

<p>I am able to install docker, docker-compose and docker-machine</p>

<pre><code>docker --version
Docker version 17.05.0-ce, build 89658be
docker-compose --version
docker-compose version 1.13.0, build unknown
docker-machine --version
docker-machine version 0.11.0, build 5b27455
</code></pre>

<p>I did not download and run 'Docker for Mac' app.</p>

<p>However when I try to run</p>

<pre><code>&gt; docker run -d -p 80:80 --name webserver nginx
docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.
See 'docker run --help'.
</code></pre>

<p>I have already checked the sock file</p>

<pre><code>ls -lah /var/run/docker.sock /var/tmp/docker.sock
ls: /var/run/docker.sock: No such file or directory
ls: /var/tmp/docker.sock: No such file or directory
</code></pre>

<p>I have also tried this proposed solution: <a href=""https://stackoverflow.com/questions/36193300/mac-os-x-sudo-docker-cannot-connect-to-the-docker-daemon-is-the-docker-daemon-r"">Mac OS X sudo docker Cannot connect to the Docker daemon. Is the docker daemon running on this host?</a></p>

<p>But I got this error message:</p>

<pre><code>$ eval $(docker-machine env default)
Host does not exist: ""default""
</code></pre>

<p>Is it possible to get a docker service to run by command line tools?</p>
","58129","","-1","","2017-05-23 12:18:24","2021-06-03 19:57:38","Cannot connect to the Docker daemon on macOS","<macos><docker><macos-sierra>","16","2","71","","","CC BY-SA 3.0","44719239","2","","44084846","2017-06-23 10:31:51","","614","","<p>On a supported Mac, run:</p>
<pre><code>brew install --cask docker
</code></pre>
<p>Then launch the <strong>Docker</strong> app. Click next. It will ask for privileged access. Confirm. A whale icon should appear in the top bar. Click it and wait for &quot;Docker is running&quot; to appear.</p>
<p>You should be able to run <code>docker</code> commands now:</p>
<pre><code>docker ps
</code></pre>
<p>Because docker is a system-level package, you cannot install it using <code>brew install</code>, and must use <code>--cask</code> instead.</p>
<p>Note: This solution only works for Macs whose CPUs support virtualization, which may not include old Macs.</p>
","154133","","154133","","2020-12-26 05:39:52","2020-12-26 05:39:52","","","","14","","","","CC BY-SA 4.0"
"27701930","1","27703359","","2014-12-30 08:26:07","","358","413016","<p>I have a docker container with some processes (uwsgi and celery) running inside. I want to create a celery user and a uwsgi user for these processes as well as a worker group that they will both belong to, in order to assign permissions. </p>

<p>I tried adding <code>RUN adduser uwsgi</code> and <code>RUN adduser celery</code> to my Dockerfile, but this is causing problems, since these commands prompt for input (I've posted the responses from the build below). </p>

<p>What is the best way to add users to a Docker container so as to set permissions for workers running in the container?</p>

<p>My Docker image is built from the official Ubuntu14.04 base.</p>

<p>Here is the output from the Dockerfile when the adduser commands are run:</p>

<pre><code>Adding user `uwsgi' ...
Adding new group `uwsgi' (1000) ... 
Adding new user `uwsgi' (1000) with group `uwsgi' ... 
Creating home directory `/home/uwsgi' ...
Copying files from `/etc/skel' ... 
[91mEnter new UNIX password: Retype new UNIX password: [0m 
[91mpasswd: Authentication token manipulation error
passwd: password unchanged
[0m 
[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 563.
[0m 
[91mUse of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 564.
[0m 
Try again? [y/N] 
Changing the user information for uwsgi
Enter the new value, or press ENTER for the default
    Full Name []: 
Room Number []:     Work Phone []:  Home Phone []:  Other []: 
[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 589.
[0m 
[91mUse of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 590.
[0m 
Is the information correct? [Y/n] 
---&gt; 258f2f2f13df 
Removing intermediate container 59948863162a 
Step 5 : RUN adduser celery 
---&gt; Running in be06f1e20f64 
Adding user `celery' ...
Adding new group `celery' (1001) ... 
Adding new user `celery' (1001) with group `celery' ... 
Creating home directory `/home/celery' ...
Copying files from `/etc/skel' ... 
[91mEnter new UNIX password: Retype new UNIX password: [0m 
[91mpasswd: Authentication token manipulation error
passwd: password unchanged
[0m 
[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 563.
[0m 
[91mUse of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 564.
[0m 
Try again? [y/N] 
Changing the user information for celery
Enter the new value, or press ENTER for the default
    Full Name []:   Room Number []:     Work Phone []: 
Home Phone []:  Other []: 
[91mUse of uninitialized value $answer in chop at /usr/sbin/adduser line 589.
[0m 
[91mUse of uninitialized value $answer in pattern match (m//) at /usr/sbin/adduser line 590.
[0m 
Is the information correct? [Y/n] 
</code></pre>
","2686639","","7940996","","2020-05-26 02:55:03","2020-05-26 02:55:03","How to add users to Docker container?","<linux><ubuntu><dockerfile>","8","0","108","","","CC BY-SA 4.0","27703359","2","","27701930","2014-12-30 10:05:10","","609","","<p>The trick is to use <code>useradd</code> instead of its interactive wrapper <code>adduser</code>.
I usually create users with:</p>

<pre><code>RUN useradd -ms /bin/bash newuser
</code></pre>

<p>which creates a home directory for the user and ensures that bash is the default shell. </p>

<p>You can then add:</p>

<pre><code>USER newuser
WORKDIR /home/newuser
</code></pre>

<p>to your dockerfile. Every command afterwards as well as interactive sessions will be executed as user <code>newuser</code>:</p>

<pre><code>docker run -t -i image
newuser@131b7ad86360:~$
</code></pre>

<p>You might have to give <code>newuser</code> the permissions to execute the programs you intend to run before invoking the user command.</p>

<p>Using non-privileged users inside containers is a good idea for security reasons. It also has a few drawbacks. Most importantly, people deriving images from your image will have to switch back to root before they can execute commands with superuser privileges.</p>
","2916139","","307153","","2015-07-23 04:29:48","2015-07-23 04:29:48","","","","12","","","","CC BY-SA 3.0"
"18285212","1","18287169","","2013-08-17 04:47:11","","139","108197","<p>So I recently discovered this awesome tool, and it says </p>

<blockquote>
  <p>Docker is an open-source project to easily create lightweight,
  portable, self-sufficient containers from any application. The same
  container that a developer builds and tests on a laptop can run at
  scale, in production, on VMs, bare metal, OpenStack clusters, public
  clouds and more.</p>
</blockquote>

<p>Let's say I have a docker image which runs Nginx and a website connects to external database. How do I scale the container in production?</p>
","342553","","321731","","2014-05-02 12:04:02","2019-03-11 09:05:48","How to scale Docker containers in production","<scale><production><docker>","10","0","328","","","CC BY-SA 3.0","18287169","2","","18285212","2013-08-17 09:19:34","","595","","<h1>Update: 2019-03-11</h1>

<p>First of all thanks for those who have upvoted this answer over the years.</p>

<p>Please be aware that this question was asked in August 2013, when Docker was still a very new technology. Since then: <a href=""https://kubernetes.io/"" rel=""noreferrer"">Kubernetes</a> was launched on June 2014, <a href=""https://docs.docker.com/engine/swarm/"" rel=""noreferrer"">Docker swarm</a> was integrated into the Docker engine in Feb 2015, Amazon launched it's <a href=""https://aws.amazon.com/about-aws/whats-new/2015/04/amazon-ec2-container-service-is-now-generally-available/"" rel=""noreferrer"">container solution, ECS,</a> in April 2015 and <a href=""https://cloud.google.com/kubernetes-engine/"" rel=""noreferrer"">Google launched GKE</a> in August 2015. It's fair to say the production container landscape has changed substantially.</p>

<hr>

<p>The short answer is that you'd have to write your own logic to do this.</p>

<p>I would expect this kind of feature to emerge from the following projects, built on top of docker, and designed to support applications in production:</p>

<ul>
<li><a href=""https://flynn.io/"" rel=""noreferrer"">flynn</a></li>
<li><a href=""http://deis.io/"" rel=""noreferrer"">deis</a></li>
<li><a href=""http://coreos.com/"" rel=""noreferrer"">coreos</a></li>
<li><a href=""http://mesosphere.io/2013/09/26/docker-on-mesos/"" rel=""noreferrer"">Mesos</a></li>
</ul>

<h1>Update 1</h1>

<p>Another related project I recently discovered:</p>

<ul>
<li><a href=""https://github.com/toscanini/maestro"" rel=""noreferrer"">maestro</a></li>
</ul>

<h1>Update 2</h1>

<p>The latest release Openstack contains support for managing Docker containers:</p>

<ul>
<li><a href=""https://wiki.openstack.org/wiki/Docker"" rel=""noreferrer"">Docker Openstack</a></li>
<li><a href=""http://www.sebastien-han.fr/blog/2013/10/31/build-a-paas-zone-within-your-openstack-cloud/"" rel=""noreferrer"">Paas zone within OpenStack</a></li>
</ul>

<h1>Update 3</h1>

<p>System for managing Docker instances</p>

<ul>
<li><a href=""http://shipyard-project.com/"" rel=""noreferrer"">Shipyard</a></li>
</ul>

<p>And a presentation on how to use tools like <a href=""http://www.packer.io/"" rel=""noreferrer"">Packer</a>, Docker and <a href=""http://www.serfdom.io/"" rel=""noreferrer"">Serf</a> to deliver an immutable server infrastructure pattern</p>

<ul>
<li><a href=""http://www.infoq.com/news/2013/12/futureops"" rel=""noreferrer"">FutureOps with Immutable Infrastructure</a></li>
<li><a href=""http://www.slideshare.net/profyclub_ru/8-mitchell-hashimoto-hashicorp"" rel=""noreferrer"">Slides</a></li>
</ul>

<h1>Update 4</h1>

<p>A neat article on how to wire together docker containers using <a href=""http://www.serfdom.io/"" rel=""noreferrer"">serf</a>:</p>

<ul>
<li><a href=""http://www.centurylinklabs.com/decentralizing-docker-how-to-use-serf-with-docker/"" rel=""noreferrer"">Decentralizing Docker: How to use serf with Docker</a></li>
</ul>

<h1>Update 5</h1>

<p>Run Docker on <a href=""http://mesos.apache.org/"" rel=""noreferrer"">Mesos</a> using the <a href=""https://github.com/mesosphere/marathon"" rel=""noreferrer"">Marathon</a> framework</p>

<p><a href=""https://mesosphere.io/learn/run-docker-on-mesosphere-cluster/"" rel=""noreferrer"">Mesosphere Docker Developer Tutorial</a></p>

<h1>Update 6</h1>

<p>Run Docker on <a href=""http://www.tsuru.io"" rel=""noreferrer"">Tsuru</a> as it supports <a href=""https://github.com/tsuru/docker-cluster"" rel=""noreferrer"">docker-cluster</a> and <a href=""http://docs.tsuru.io/en/latest/provisioners/docker/schedulers.html"" rel=""noreferrer"">segregated scheduler deploy</a></p>

<ul>
<li><a href=""http://blog.tsuru.io/2014/04/04/running-tsuru-in-production-scaling-and-segregating-docker-containers/"" rel=""noreferrer"">http://blog.tsuru.io/2014/04/04/running-tsuru-in-production-scaling-and-segregating-docker-containers/</a></li>
</ul>

<h1>Update 7</h1>

<p>Docker-based environments orchestration</p>

<p><a href=""https://github.com/signalfuse/maestro-ng"" rel=""noreferrer"">maestro-ng</a></p>

<h1>Update 8</h1>

<p><a href=""http://decking.io/"" rel=""noreferrer"">decking.io</a></p>

<h1>Update 9</h1>

<p>Google <a href=""https://github.com/GoogleCloudPlatform/kubernetes"" rel=""noreferrer"">kubernetes</a></p>

<h1>Update 10</h1>

<p>Redhat have refactored their openshift PAAS to integrate Docker</p>

<ul>
<li><a href=""http://www.projectatomic.io/"" rel=""noreferrer"">Project Atomic</a></li>
<li><a href=""http://openshift.github.io/geard/"" rel=""noreferrer"">Geard</a></li>
</ul>

<h1>Update 11</h1>

<p>A Docker NodeJS lib wrapping the Docker command line and managing it from a json file.</p>

<ul>
<li><a href=""https://github.com/iorga-group/docker-cmd"" rel=""noreferrer"">docker-cmd</a></li>
</ul>

<h1>Update 12</h1>

<p>Amazon's new <a href=""https://aws.amazon.com/ecs/details/"" rel=""noreferrer"">container service</a> enables scaling in the cluster. </p>

<h1>Update 13</h1>

<p>Strictly speaking <a href=""https://github.com/ClusterHQ/flocker"" rel=""noreferrer"">Flocker</a> does not ""scale"" applications, but it is designed to fufil a related function of making stateful containers (running databases services?) portable across multiple docker hosts:</p>

<p><a href=""https://clusterhq.com/"" rel=""noreferrer"">https://clusterhq.com/</a></p>

<h1>Update 14</h1>

<p>A project to create portable templates that describe Docker applications:</p>

<p><a href=""http://panamax.io/"" rel=""noreferrer"">http://panamax.io/</a></p>

<h1>Update 15</h1>

<p>The Docker project is now addressing orchestration natively (See <a href=""https://blog.docker.com/2015/02/orchestrating-docker-with-machine-swarm-and-compose/"" rel=""noreferrer"">announcement</a>)</p>

<ul>
<li><a href=""https://docs.docker.com/machine/"" rel=""noreferrer"">Docker machine</a></li>
<li><a href=""https://docs.docker.com/swarm/"" rel=""noreferrer"">Docker swarm</a></li>
<li><a href=""https://docs.docker.com/compose/"" rel=""noreferrer"">Docker compose</a></li>
</ul>

<h1>Update 16</h1>

<p><a href=""https://github.com/spotify/helios"" rel=""noreferrer"">Spotify Helios</a></p>

<p>See also:</p>

<ul>
<li><a href=""https://blog.docker.com/tag/helios/"" rel=""noreferrer"">https://blog.docker.com/tag/helios/</a></li>
</ul>

<h1>Update 17</h1>

<p>The Openstack project now has a new ""container as a service"" project called Magnum:</p>

<ul>
<li><a href=""https://wiki.openstack.org/wiki/Magnum"" rel=""noreferrer"">https://wiki.openstack.org/wiki/Magnum</a></li>
</ul>

<p>Shows a lot of promise, enables the easy setup of Docker orchestration frameworks like Kubernetes and Docker swarm.</p>

<h1>Update 18</h1>

<p>Rancher is a project that is maturing rapidly</p>

<p><a href=""http://rancher.com/"" rel=""noreferrer"">http://rancher.com/</a></p>

<p>Nice UI and strong focus on hyrbrid Docker infrastructures</p>

<h1>Update 19</h1>

<p>The <a href=""http://lattice.cf/"" rel=""noreferrer"">Lattice project</a> is an offshoot of Cloud Foundry for managing container clusters. </p>

<h1>Update 20</h1>

<p>Docker recently bought Tutum:</p>

<p><a href=""https://www.docker.com/tutum"" rel=""noreferrer"">https://www.docker.com/tutum</a></p>

<h1>Update 21</h1>

<p>Package manager for applications deployed on <a href=""http://kubernetes.io/"" rel=""noreferrer"">Kubernetes</a>.</p>

<p><a href=""http://helm.sh/"" rel=""noreferrer"">http://helm.sh/</a></p>

<h1>Update 22</h1>

<p>Vamp is an open source and self-hosted platform for managing (micro)service oriented architectures that rely on container technology. </p>

<p><a href=""http://vamp.io/"" rel=""noreferrer"">http://vamp.io/</a></p>

<h1>Update 23</h1>

<p>A Distributed, Highly Available, Datacenter-Aware Scheduler</p>

<ul>
<li><a href=""https://www.nomadproject.io/"" rel=""noreferrer"">https://www.nomadproject.io/</a></li>
</ul>

<p>From the guys that gave us Vagrant and other powerful tools.</p>

<h1>Update 24</h1>

<p>Container hosting solution for AWS, open source and based on <a href=""http://kubernetes.io/"" rel=""noreferrer"">Kubernetes</a></p>

<p><a href=""https://supergiant.io/"" rel=""noreferrer"">https://supergiant.io/</a></p>

<h1>Update 25</h1>

<p>Apache Mesos based container hosted located in Germany</p>

<p><a href=""https://sloppy.io/features/#features"" rel=""noreferrer"">https://sloppy.io/features/#features</a></p>

<p>And Docker Inc. also provide a container hosting service called Docker cloud</p>

<p><a href=""https://cloud.docker.com/"" rel=""noreferrer"">https://cloud.docker.com/</a></p>

<h1>Update 26</h1>

<p><a href=""https://jelastic.com/blog/docker-swarm-auto-clustering-and-scaling-with-paas/"" rel=""noreferrer"">Jelastic</a> is a hosted PAAS service that scales containers automatically.</p>
","256618","","256618","","2019-03-11 09:05:48","2019-03-11 09:05:48","","","","25","","","","CC BY-SA 4.0"
"43747776","1","43747867","","2017-05-02 21:48:02","","374","183335","<p>In a Dockerfile, I have</p>

<pre><code>COPY . .
</code></pre>

<p>I want to exclude an entire directory, in my case, node_modules directory.</p>

<p>Something like this:</p>

<pre><code>   COPY [all but **/node_modules/**] .
</code></pre>

<p>Is this possible with Docker?</p>
","1223975","","","","","2021-03-18 13:40:04","COPY with docker but with exclusion","<docker><dockerfile><docker-copy>","6","2","38","","","CC BY-SA 3.0","43747867","2","","43747776","2017-05-02 21:54:36","","590","","<p>Create file <code>.dockerignore</code> in your docker build context directory (so in this case, most likely a directory that is a parent to node_modules) with one line in it: </p>

<pre><code>**/node_modules
</code></pre>

<p>although you probably just want:</p>

<pre><code>node_modules
</code></pre>

<p>Info about dockerignore: <a href=""https://docs.docker.com/engine/reference/builder/#dockerignore-file"" rel=""noreferrer"">https://docs.docker.com/engine/reference/builder/#dockerignore-file</a></p>
","4529152","","46914","","2019-03-21 21:03:21","2019-03-21 21:03:21","","","","6","","","","CC BY-SA 4.0"
"26153686","1","27708039","","2014-10-02 02:34:25","","537","593730","<p>I created a container with <code>-d</code> so it's not interactive.</p>

<pre><code>docker run -d shykes/pybuilder bin/bash
</code></pre>

<p>I see that the container has exited:</p>

<pre><code>CONTAINER ID        IMAGE                     COMMAND             CREATED             STATUS                      PORTS               NAMES
d6c45e8cc5f0        shykes/pybuilder:latest   ""bin/bash""          41 minutes ago      Exited (0) 2 seconds ago                        clever_bardeen
</code></pre>

<p>Now I would like to run occasional commands on the machine and exit. Just to get the response.</p>

<p>I tried to start the machine. I tried attaching. I thought I could call <code>run</code> with a container, but that does not seem to be allowed. Using <code>start</code> just seems to run and then exist quickly.</p>

<p>I'd like to get back into interactive mode after exiting.</p>

<p>I tried:</p>

<pre><code>docker attach d6c45e8cc5f0
</code></pre>

<p>But I get:</p>

<pre><code>2014/10/01 22:33:34 You cannot attach to a stopped container, start it first
</code></pre>

<p>But if I start it, it exits anyway. Catch 22. I can't win.</p>
","974407","","63550","","2017-03-13 19:10:24","2020-05-27 06:47:45","How do I run a command on an already existing Docker container?","<docker>","19","3","135","","","CC BY-SA 3.0","27708039","2","","26153686","2014-12-30 15:21:41","","582","","<p>In October 2014 the <a href=""http://blog.docker.com/2014/10/docker-1-3-signed-images-process-injection-security-options-mac-shared-directories/"" rel=""noreferrer"">Docker team introduced <code>docker exec</code> command</a>: <a href=""https://docs.docker.com/engine/reference/commandline/exec/"" rel=""noreferrer"">https://docs.docker.com/engine/reference/commandline/exec/</a></p>

<p>So now you can run any command in a running container just knowing its ID (or name):</p>

<pre><code>docker exec -it &lt;container_id_or_name&gt; echo ""Hello from container!""
</code></pre>

<p>Note that <code>exec</code> command works only on already running container. If the container is currently stopped, you need to first run it with the following command:</p>

<pre><code>docker run -it -d shykes/pybuilder /bin/bash
</code></pre>

<p>The most important thing here is the <code>-d</code> option, which stands for <code>detached</code>. It means that the command you initially provided to the container (<code>/bin/bash</code>) will be run in the background and the container will not <em>stop immediately</em>.</p>
","1813669","","71522","","2017-04-26 15:48:17","2017-04-26 15:48:17","","","","13","","","","CC BY-SA 3.0"
"37461868","1","37462208","","2016-05-26 13:11:20","","398","127967","<p>I'm confused about when should I use <code>CMD</code> vs <code>RUN</code>. For example, to execute bash/shell commands (i.e. <code>ls -la</code>) I would always use <code>CMD</code> or is there a situation where I would use <code>RUN</code>? Trying to understand the best practices about these two similar <code>Dockerfile</code> directives.</p>
","6386350","","7154924","","2019-10-14 08:45:26","2020-04-19 11:15:45","Difference between RUN and CMD in a Dockerfile","<docker><dockerfile>","9","1","92","","","CC BY-SA 4.0","37462208","2","","37461868","2016-05-26 13:25:55","","576","","<p><a href=""https://docs.docker.com/engine/reference/builder/#run"" rel=""noreferrer"">RUN</a> is an image build step, the state of the container after a <code>RUN</code> command will be committed to the container image. A Dockerfile can have many <code>RUN</code> steps that layer on top of one another to build the image. </p>

<p><a href=""https://docs.docker.com/engine/reference/builder/#cmd"" rel=""noreferrer"">CMD</a> is the command the container executes by default when you launch the built image. A Dockerfile will only use the final <code>CMD</code> defined. The <code>CMD</code> can be overridden when starting a container with <code>docker run $image $other_command</code>. </p>

<p><a href=""https://docs.docker.com/engine/reference/builder/#entrypoint"" rel=""noreferrer"">ENTRYPOINT</a> is also closely related to <code>CMD</code> and can modify the way a container starts an image.</p>
","1318694","","1318694","","2020-04-19 11:15:45","2020-04-19 11:15:45","","","","5","","","","CC BY-SA 4.0"
"44769315","1","44769468","","2017-06-26 22:01:49","","452","321245","<p>I did a docker pull and can list the image that's downloaded. I want to see the contents of this image. Did a search on the net but no straight answer.</p>
","7865278","","1839439","","2019-10-02 10:39:41","2020-11-22 15:07:53","How to see docker image contents","<docker>","9","4","128","","","CC BY-SA 4.0","44769468","2","","44769315","2017-06-26 22:16:57","","573","","<p>You can just run an interactive shell container using that image and explore whatever content that image has.</p>

<p>For instance:</p>

<pre><code>docker run -it image_name sh
</code></pre>

<p>Or following for images with an <code>entrypoint</code></p>

<pre><code>docker run -it --entrypoint sh image_name
</code></pre>

<p>Or, if you want to see how the image was build, meaning the steps in its <code>Dockerfile</code>, you can:</p>

<pre><code>docker image history --no-trunc image_name &gt; image_history
</code></pre>

<p>The steps will be logged into the <code>image_history</code> file.</p>
","4000674","","2829988","","2020-01-04 17:32:53","2020-01-04 17:32:53","","","","10","","","","CC BY-SA 4.0"
"30256386","1","30316600","","2015-05-15 09:49:49","","324","234188","<p>The following <code>Dockerfile</code> contains four <code>COPY</code> layers:</p>

<pre><code>COPY README.md ./
COPY package.json ./
COPY gulpfile.js ./
COPY __BUILD_NUMBER ./
</code></pre>

<p>How to copy these files using one layer instead? The following was tried:</p>

<pre><code>COPY [
    ""__BUILD_NUMBER ./"",
    ""README.md ./"",
    ""gulpfile ./"",
    ""another_file ./"",
]
</code></pre>
","2537772","","2777965","","2017-03-27 07:54:10","2021-05-05 21:11:51","How to copy multiple files in one layer using a Dockerfile?","<dockerfile>","6","0","32","","","CC BY-SA 3.0","30316600","2","","30256386","2015-05-19 04:08:22","","564","","<pre><code>COPY README.md package.json gulpfile.js __BUILD_NUMBER ./
</code></pre>

<p>or</p>

<pre><code>COPY [""__BUILD_NUMBER"", ""README.md"", ""gulpfile"", ""another_file"", ""./""]
</code></pre>

<p>You can also use wildcard characters in the sourcefile specification. <a href=""https://docs.docker.com/engine/reference/builder/#/copy"" rel=""noreferrer"">See the docs for a little more detail</a>.</p>

<p><strong>Directories are special!</strong> If you write</p>

<pre><code>COPY dir1 dir2 ./
</code></pre>

<p>that actually works like</p>

<pre><code>COPY dir1/* dir2/* ./
</code></pre>

<p>If you want to copy multiple directories (not their contents) under a destination directory in a single command, you'll need to set up the build context so that your source directories are under a common parent and then <code>COPY</code> that parent.</p>
","1220269","","633098","","2018-08-07 22:04:00","2018-08-07 22:04:00","","","","7","","","","CC BY-SA 4.0"
"26982274","1","26982502","","2014-11-17 21:26:14","","327","188838","<p>I want to do a ps command in a docker container derived from Debian official Docker hub repository:</p>

<pre><code>$ docker run -ti debian:wheezy /bin/bash
root@51afd6b09af8:/# ps
bash: ps: command not found
</code></pre>
","2763877","","1033581","","2017-04-16 04:33:09","2020-08-02 17:51:24","ps command doesn't work in docker container","<debian><docker>","5","0","42","","","CC BY-SA 3.0","26982502","2","","26982274","2014-11-17 21:41:12","","558","","<p><code>ps</code> is not installed in the base <code>wheezy</code> image. Try this from within the container:</p>

<pre><code>RUN apt-get update &amp;&amp; apt-get install -y procps
</code></pre>
","2105103","","5265621","","2020-04-23 22:12:44","2020-04-23 22:12:44","","","","9","","","","CC BY-SA 4.0"
"17989306","1","18208445","","2013-08-01 08:50:42","","412","107126","<p>If you take a look at Docker's features, most of them are already provided by LXC.</p>

<p>So what does Docker add? Why would I use Docker over plain LXC?</p>
","247696","","1305344","","2015-08-02 21:12:10","2018-06-29 09:16:52","What does Docker add to lxc-tools (the userspace LXC tools)?","<docker><lxc>","5","0","277","","","CC BY-SA 3.0","18208445","2","","17989306","2013-08-13 11:54:43","","554","","<p>From the <a href=""https://docs.docker.com/engine/faq/"">Docker FAQ</a>:</p>

<p>Docker is not a replacement for lxc. ""lxc"" refers to capabilities of the linux kernel (specifically namespaces and control groups) which allow sandboxing processes from one another, and controlling their resource allocations.</p>

<p>On top of this low-level foundation of kernel features, Docker offers a high-level tool with several powerful functionalities:</p>

<ul>
<li><p><em>Portable deployment across machines.</em> Docker defines a format for bundling an application and all its dependencies into a single object which can be transferred to any docker-enabled machine, and executed there with the guarantee that the execution environment exposed to the application will be the same. Lxc implements process sandboxing, which is an important pre-requisite for portable deployment, but that alone is not enough for portable deployment. If you sent me a copy of your application installed in a custom lxc configuration, it would almost certainly not run on my machine the way it does on yours, because it is tied to your machine's specific configuration: networking, storage, logging, distro, etc. Docker defines an abstraction for these machine-specific settings, so that the exact same docker container can run - unchanged - on many different  machines, with many different configurations.</p></li>
<li><p><em>Application-centric.</em> Docker is optimized for the deployment of <em>applications</em>, as opposed to machines. This is reflected in its API, user interface, design philosophy and documentation. By contrast, the lxc helper scripts focus on containers as lightweight machines - basically servers that boot faster and need less ram. We think there's more to containers than just that.</p></li>
<li><p><em>Automatic build</em>. Docker includes a tool for developers to automatically assemble a container from their source code, with full control over application dependencies, build tools, packaging etc. They are free to use make, maven, chef, puppet, salt, debian packages, rpms, source tarballs, or any combination of the above, <em>regardless of the configuration of the machines</em>.</p></li>
<li><p><em>Versioning.</em> Docker includes git-like capabilities for tracking successive versions of a container, inspecting the diff between versions, committing new versions, rolling back etc. The history also includes <em>how</em> a container was assembled and by whom, so you get full traceability from the production server all the way back to the upstream developer. Docker also implements incremental uploads and downloads, similar to ""git pull"", so new versions of a container can be transferred by only sending diffs.</p></li>
<li><p><em>Component re-use.</em> Any container can be used as an ""base image"" to create more specialized components. This can be done manually or as part of an automated build. For example you can prepare the ideal python environment, and use it as a base for 10 different applications. Your ideal postgresql setup can be re-used for all your future projects. And so on.</p></li>
<li><p><em>Sharing.</em> Docker has access to a public registry (<a href=""https://registry.hub.docker.com/"">https://registry.hub.docker.com/</a>) where thousands of people have uploaded useful containers: anything from redis, couchdb, postgres to irc bouncers to rails app servers to hadoop to base images for various distros. The registry also includes an official ""standard library"" of useful containers maintained by the docker team. The registry itself is open-source, so anyone can deploy their own registry to store and transfer private containers, for internal server deployments for example.</p></li>
<li><p><em>Tool ecosystem.</em> Docker defines an API for automating and customizing the creation and deployment of containers. There are a huge number of tools integrating with docker to extend its capabilities. PaaS-like deployment (Dokku, Deis, Flynn), multi-node orchestration (maestro, salt, mesos, openstack nova), management dashboards (docker-ui, openstack horizon, shipyard), configuration management (chef, puppet), continuous integration (jenkins, strider, travis), etc. Docker is rapidly establishing itself as the standard for container-based tooling.</p></li>
</ul>

<p>I hope this helps!</p>
","2678466","","468725","","2016-07-23 18:59:27","2016-07-23 18:59:27","","","","10","","","","CC BY-SA 3.0"
"27068596","1","34392052","","2014-11-21 19:11:28","","625","319138","<p>How can I include files from outside of Docker's build context using the ""ADD"" command in the Docker file?</p>

<p>From the Docker documentation:</p>

<blockquote>
  <p>The  path must be inside the context of the build; you cannot ADD
  ../something/something, because the first step of a docker build is to
  send the context directory (and subdirectories) to the docker daemon.</p>
</blockquote>

<p>I do not want to restructure my whole project just to accommodate Docker in this matter. I want to keep all my Docker files in the same sub-directory.</p>

<p>Also, it appears Docker does not yet (and may not ever) support symlinks: <a href=""https://github.com/docker/docker/issues/1676"" rel=""noreferrer"">Dockerfile ADD command does not follow symlinks on host #1676.</a> </p>

<p>The only other thing I can think of is to include a pre-build step to copy the files into the Docker build context (and configure my version control to ignore those files). Is there a better workaround for than that?</p>
","2048879","","321731","","2018-08-12 16:34:56","2021-06-04 10:21:59","How to include files outside of Docker's build context?","<docker>","16","4","85","","","CC BY-SA 4.0","34392052","2","","27068596","2015-12-21 09:02:47","","547","","<p>The best way to work around this is to specify the Dockerfile independently of the build context, using -f.</p>
<p>For instance, this command will give the ADD command access to anything in your current directory.</p>
<pre><code>docker build -f docker-files/Dockerfile .
</code></pre>
<p><strong>Update</strong>: Docker now allows having the Dockerfile outside the build context (fixed in 18.03.0-ce). So you can also do something like</p>
<pre><code>docker build -f ../Dockerfile .
</code></pre>
","1591921","","1591921","","2021-06-04 10:21:59","2021-06-04 10:21:59","","","","18","","","","CC BY-SA 4.0"
"42564058","1","42564211","","2017-03-02 19:16:34","","411","220297","<p>I have several docker images that I want to use with <code>minikube</code>. I don't want to first have to upload and then download the same image instead of just using the local image directly. How do I do this?</p>
<p>Stuff I tried:
<br>1. I tried running these commands (separately, deleting the instances of minikube both times and starting fresh)</p>
<pre><code>kubectl run hdfs --image=fluxcapacitor/hdfs:latest --port=8989
kubectl run hdfs --image=fluxcapacitor/hdfs:latest --port=8989 imagePullPolicy=Never
</code></pre>
<p>Output:</p>
<pre><code>NAME                    READY     STATUS              RESTARTS   AGE
hdfs-2425930030-q0sdl   0/1       ContainerCreating   0          10m
</code></pre>
<p>It just gets stuck on some status but never reaches the ready state.</p>
<p><br>2. I tried creating a registry and then putting images into it but that didn't work either. I might've done that incorrectly but I can't find proper instructions to do this task.</p>
<p>Please provide instructions to use local docker images in local kubernetes instance.
<br>OS: ubuntu 16.04
<br>Docker : Docker version 1.13.1, build 092cba3
<br>Kubernetes :</p>
<pre><code>Client Version: version.Info{Major:&quot;1&quot;, Minor:&quot;5&quot;, GitVersion:&quot;v1.5.3&quot;, GitCommit:&quot;029c3a408176b55c30846f0faedf56aae5992e9b&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2017-02-15T06:40:50Z&quot;, GoVersion:&quot;go1.7.4&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}
Server Version: version.Info{Major:&quot;1&quot;, Minor:&quot;5&quot;, GitVersion:&quot;v1.5.2&quot;, GitCommit:&quot;08e099554f3c31f6e6f07b448ab3ed78d0520507&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;1970-01-01T00:00:00Z&quot;, GoVersion:&quot;go1.7.1&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}
</code></pre>
<p>If someone could help me get a solution that uses docker-compose to do this, that'd be awesome.</p>
<p><strong>Edit:</strong></p>
<p>Images loaded in <code>eval $(minikube docker-env</code>:</p>
<pre><code>REPOSITORY                                            TAG                 IMAGE ID            CREATED             SIZE
fluxcapacitor/jupyterhub                              latest              e5175fb26522        4 weeks ago         9.59 GB
fluxcapacitor/zeppelin                                latest              fe4bc823e57d        4 weeks ago         4.12 GB
fluxcapacitor/prediction-pmml                         latest              cae5b2d9835b        4 weeks ago         973 MB
fluxcapacitor/scheduler-airflow                       latest              95adfd56f656        4 weeks ago         8.89 GB
fluxcapacitor/loadtest                                latest              6a777ab6167c        5 weeks ago         899 MB
fluxcapacitor/hdfs                                    latest              00fa0ed0064b        6 weeks ago         1.16 GB
fluxcapacitor/sql-mysql                               latest              804137671a8c        7 weeks ago         679 MB
fluxcapacitor/metastore-1.2.1                         latest              ea7ce8c5048f        7 weeks ago         1.35 GB
fluxcapacitor/cassandra                               latest              3cb5ff117283        7 weeks ago         953 MB
fluxcapacitor/apachespark-worker-2.0.1                latest              14ee3e4e337c        7 weeks ago         3.74 GB
fluxcapacitor/apachespark-master-2.0.1                latest              fe60b42d54e5        7 weeks ago         3.72 GB
fluxcapacitor/package-java-openjdk-1.8                latest              1db08965289d        7 weeks ago         841 MB
gcr.io/google_containers/kubernetes-dashboard-amd64   v1.5.1              1180413103fd        7 weeks ago         104 MB
fluxcapacitor/stream-kafka-0.10                       latest              f67750239f4d        2 months ago        1.14 GB
fluxcapacitor/pipeline                                latest              f6afd6c5745b        2 months ago        11.2 GB
gcr.io/google-containers/kube-addon-manager           v6.1                59e1315aa5ff        3 months ago        59.4 MB
gcr.io/google_containers/kubedns-amd64                1.9                 26cf1ed9b144        3 months ago        47 MB
gcr.io/google_containers/kube-dnsmasq-amd64           1.4                 3ec65756a89b        5 months ago        5.13 MB
gcr.io/google_containers/exechealthz-amd64            1.2                 93a43bfb39bf        5 months ago        8.37 MB
gcr.io/google_containers/pause-amd64           
</code></pre>
","6930923","","1788806","","2020-09-14 08:23:09","2021-04-25 09:08:48","How to use local docker images with Minikube?","<linux><docker><kubernetes><docker-compose>","24","0","169","","","CC BY-SA 4.0","42564211","2","","42564058","2017-03-02 19:25:14","","545","","<p>As the <a href=""https://github.com/kubernetes/minikube/blob/0c616a6b42b28a1aab8397f5a9061f8ebbd9f3d9/README.md#reusing-the-docker-daemon"" rel=""noreferrer"">README</a> describes, you can reuse the Docker daemon from Minikube with <code>eval $(minikube docker-env)</code>.</p>
<p>So to use an image without uploading it, you can follow these steps:</p>
<ol>
<li>Set the environment variables with <code>eval $(minikube docker-env)</code></li>
<li>Build the image with the Docker daemon of Minikube (eg <code>docker build -t my-image .</code>)</li>
<li>Set the image in the pod spec like the build tag (eg <code>my-image</code>)</li>
<li>Set the <a href=""https://kubernetes.io/docs/concepts/containers/images/#updating-images"" rel=""noreferrer""><code>imagePullPolicy</code></a> to <code>Never</code>, otherwise Kubernetes will try to download the image.</li>
</ol>
<p><strong>Important note:</strong> You have to run <code>eval $(minikube docker-env)</code> on each terminal you want to use, since it only sets the environment variables for the current shell session.</p>
","393157","","1910759","","2020-08-24 20:41:25","2020-08-24 20:41:25","","","","14","","","","CC BY-SA 4.0"
"21889053","1","26149994","","2014-02-19 18:19:45","","612","187048","<p>I'd like to comprehensively understand the run-time performance cost of a Docker container. I've found references to <a href=""https://stackoverflow.com/questions/21691540/how-to-optimize-performance-for-a-docker-container/21707838#21707838"">networking anecdotally being ~100µs slower</a>.</p>

<p>I've also found references to the run-time cost being ""negligible"" and ""close to zero"" but I'd like to know more precisely what those costs are. Ideally I'd like to know what Docker is abstracting with a performance cost and things that are abstracted without a performance cost. Networking, CPU, memory, etc.</p>

<p>Furthermore, if there are abstraction costs, are there ways to get around the abstraction cost. For example, perhaps I can mount a disk directly vs. virtually in Docker.</p>
","251630","","1459669","","2021-05-12 23:06:50","2021-05-12 23:06:50","What is the runtime performance cost of a Docker container?","<linux><docker><performance><virtual-machine><containerd>","3","6","217","","","CC BY-SA 4.0","26149994","2","","21889053","2014-10-01 20:26:14","","544","","<p>An excellent 2014 IBM research paper “<a href=""http://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/$File/rc25482.pdf"" rel=""noreferrer"">An Updated Performance Comparison of Virtual Machines and Linux Containers</a>” by Felter et al. provides a comparison between bare metal, KVM, and Docker containers. The general result is: <strong>Docker is nearly identical to native performance and faster than KVM in every category.</strong></p>

<p>The exception to this is Docker’s NAT — if you use port mapping (e.g., <code>docker run -p 8080:8080</code>), then you can expect a minor hit in latency, as shown below. However, you can now use the host network stack (e.g., <code>docker run --net=host</code>) when launching a Docker container, which will perform identically to the Native column (as shown in the Redis latency results lower down). </p>

<p><img src=""https://i.stack.imgur.com/4yRh1m.png"" alt=""Docker NAT overhead""></p>

<p>They also ran latency tests on a few specific services, such as Redis. You can see that above 20 client threads, highest latency overhead goes Docker NAT, then KVM, then a rough tie between Docker host/native. </p>

<p><img src=""https://i.stack.imgur.com/9RH9lm.png"" alt=""Docker Redis Latency Overhead""></p>

<p>Just because it’s a really useful paper, here are some other figures. Please download it for full access. </p>

<p>Taking a look at Disk I/O:</p>

<p><img src=""https://i.stack.imgur.com/2Ftytm.png"" alt=""Docker vs. KVM vs. Native I/O Performance""></p>

<p>Now looking at CPU overhead: </p>

<p><img src=""https://i.stack.imgur.com/wZZH6m.png"" alt=""Docker CPU Overhead""></p>

<p>Now some examples of memory (read the paper for details, memory can be extra tricky):</p>

<p><img src=""https://i.stack.imgur.com/aHPVkm.png"" alt=""Docker Memory Comparison""></p>
","119592","","254635","","2020-03-14 02:49:20","2020-03-14 02:49:20","","","","18","","","","CC BY-SA 4.0"
"26753087","1","33344280","","2014-11-05 09:01:17","","304","242076","<p>I can see that Docker takes 12GB of my filesystem:</p>

<pre><code>2.7G    /var/lib/docker/vfs/dir
2.7G    /var/lib/docker/vfs
2.8G    /var/lib/docker/devicemapper/mnt
6.3G    /var/lib/docker/devicemapper/devicemapper
9.1G    /var/lib/docker/devicemapper
12G     /var/lib/docker
</code></pre>

<p>But, how do I know how this is distributed over the containers?</p>

<p>I tried to attach to the containers by running (the new v1.3 command)</p>

<pre><code>docker exec -it &lt;container_name&gt; bash
</code></pre>

<p>and then running 'df -h' to analyze the disk usage. It seems to be working, but not with containers that use 'volumes-from'.</p>

<p>For example, I use a data-only container for MongoDB, called 'mongo-data'.</p>

<p>When I run <code>docker run -it --volumes-from mongo-data  busybox</code>, and then <code>df -h</code> inside the container, It says that the filesystem mounted on <code>/data/db</code> (my 'mongo-data' data-only container) uses 11.3G, but when I do <code>du -h /data/db</code>, it says that it uses only 2.1G.</p>

<p>So, how do I analyze a container/volume disk usage? Or, in my case, how do I find out the 'mongo-data' container size?</p>
","1563935","","321731","","2019-06-27 08:55:02","2021-04-06 13:30:55","How to analyze disk usage of a Docker container","<docker><lxc><device-mapper>","11","2","82","","","CC BY-SA 4.0","33344280","2","","26753087","2015-10-26 11:10:25","","524","","<p>To see the file size of your containers, you can use the <code>--size</code> argument of <code>docker ps</code>:</p>

<pre><code>docker ps --size
</code></pre>
","5475103","","321731","","2019-06-27 08:57:29","2019-06-27 08:57:29","","","","8","","","","CC BY-SA 4.0"
"30215830","1","30220096","","2015-05-13 13:09:42","","348","296041","<p>I'm trying to copy a number of files and folders to a docker image build from my localhost.</p>

<p>The files are like this:</p>

<pre><code>folder1
    file1
    file2
folder2
    file1
    file2
</code></pre>

<p>I'm trying to make the copy like this:</p>

<pre><code>COPY files/* /files/
</code></pre>

<p>However, all files are placed in /files/ is there a way in Docker to keep the subdirectory structure as well as copying the files into their directories?</p>
","1220022","","","","","2020-10-29 03:51:43","Dockerfile copy keep subdirectory structure","<copy><docker><dockerfile>","4","1","36","","","CC BY-SA 3.0","30220096","2","","30215830","2015-05-13 16:08:06","","521","","<p>Remove star from COPY, with this Dockerfile:</p>
<pre><code>FROM ubuntu
COPY files/ /files/
RUN ls -la /files/*
</code></pre>
<p>Structure is there:</p>
<pre class=""lang-sh prettyprint-override""><code>$ docker build .
Sending build context to Docker daemon 5.632 kB
Sending build context to Docker daemon 
Step 0 : FROM ubuntu
 ---&gt; d0955f21bf24
Step 1 : COPY files/ /files/
 ---&gt; 5cc4ae8708a6
Removing intermediate container c6f7f7ec8ccf
Step 2 : RUN ls -la /files/*
 ---&gt; Running in 08ab9a1e042f
/files/folder1:
total 8
drwxr-xr-x 2 root root 4096 May 13 16:04 .
drwxr-xr-x 4 root root 4096 May 13 16:05 ..
-rw-r--r-- 1 root root    0 May 13 16:04 file1
-rw-r--r-- 1 root root    0 May 13 16:04 file2

/files/folder2:
total 8
drwxr-xr-x 2 root root 4096 May 13 16:04 .
drwxr-xr-x 4 root root 4096 May 13 16:05 ..
-rw-r--r-- 1 root root    0 May 13 16:04 file1
-rw-r--r-- 1 root root    0 May 13 16:04 file2
 ---&gt; 03ff0a5d0e4b
Removing intermediate container 08ab9a1e042f
Successfully built 03ff0a5d0e4b
</code></pre>
","1169435","","6925187","","2020-07-18 12:04:50","2020-07-18 12:04:50","","","","7","","","","CC BY-SA 4.0"
"31466428","1","31485685","","2015-07-16 23:55:01","","435","256703","<p>I have a <code>docker-compose.yml</code> file that contains 4 containers: <code>redis</code>, <code>postgres</code>, <code>api</code> and <code>worker</code>.</p>
<p>During the development of the <code>worker</code> container, I often need to restart it in order to apply changes. Is there any good way to restart a single container (e.g. <code>worker</code>) without restarting the others?</p>
","642626","","362951","","2021-06-20 11:17:03","2021-06-20 11:17:03","How to restart a single container with docker-compose","<docker><docker-compose>","9","1","106","","","CC BY-SA 4.0","31485685","2","","31466428","2015-07-17 22:36:47","","521","","<p>It is very simple: Use the command:</p>

<pre><code>docker-compose restart worker
</code></pre>

<p>You can set the time to wait for stop before killing the container (in seconds)</p>

<pre><code>docker-compose restart -t 30 worker
</code></pre>

<p>Note that this will restart the container but without rebuilding it. If you want to apply your changes and then restart, take a look at the other answers. </p>
","5129184","","783510","","2019-05-16 18:03:13","2019-05-16 18:03:13","","","","7","","","","CC BY-SA 4.0"
"28302178","1","33956387","","2015-02-03 15:08:17","","398","305932","<p>I have a Docker container that I've created simply by installing Docker on Ubuntu and doing:</p>
<pre><code>sudo docker run -i -t ubuntu /bin/bash
</code></pre>
<p>I immediately started installing Java and some other tools, spent some time with it, and stopped the container by</p>
<pre><code>exit
</code></pre>
<p>Then I wanted to add a volume and realised that this is not as straightforward as I thought it would be. If I use <code>sudo docker -v /somedir run ...</code> then I end up with a fresh new container, so I'd have to install Java and do what I've already done before just to arrive at a container with a mounted volume.</p>
<p>All the documentation about mounting a folder from the host seems to imply that mounting a volume is something that can be done when creating a container. So the only option I have to avoid reconfiguring a new container from scratch is to commit the existing container to a repository and use that as the basis of a new one whilst mounting the volume.</p>
<p>Is this indeed the only way to add a volume to an existing container?</p>
","238517","","1402846","","2020-07-15 09:31:44","2021-06-05 15:43:30","How can I add a volume to an existing Docker container?","<docker>","8","0","101","","","CC BY-SA 4.0","33956387","2","","28302178","2015-11-27 11:27:56","","520","","<p>You can commit your existing container (that is create a new image from container’s changes) and then run it with your new mounts.</p>
<p>Example:</p>
<pre><code>$ docker ps  -a
CONTAINER ID        IMAGE                 COMMAND                  CREATED              STATUS                          PORTS               NAMES
    5a8f89adeead        ubuntu:14.04          &quot;/bin/bash&quot;              About a minute ago   Exited (0) About a minute ago                       agitated_newton

$ docker commit 5a8f89adeead newimagename

$ docker run -ti -v &quot;$PWD/somedir&quot;:/somedir newimagename /bin/bash
</code></pre>
<p>If it's all OK, stop your old container, and use this new one.</p>
<p>That´s it :)</p>
","5611997","","1260896","","2020-12-09 10:52:54","2020-12-09 10:52:54","","","","8","","","","CC BY-SA 4.0"
"28490874","1","28490909","","2015-02-13 01:04:04","","290","162585","<p>I'm trying to run MULTIPLE commands like this.</p>

<pre><code>docker run image cd /path/to/somewhere &amp;&amp; python a.py
</code></pre>

<p>But this gives me ""No such file or directory"" error because it is interpreted as...</p>

<pre><code>""docker run image cd /path/to/somewhere"" &amp;&amp; ""python a.py""
</code></pre>

<p>It seems that some ESCAPE characters like """" or () are needed.</p>

<p>So I also tried </p>

<pre><code>docker run image ""cd /path/to/somewhere &amp;&amp; python a.py""
docker run image (cd /path/to/somewhere &amp;&amp; python a.py)
</code></pre>

<p>but these didn't work.</p>

<p>I have searched for <a href=""https://docs.docker.com/reference/run/"">Docker Run Reference</a> but have not find any hints about ESCAPE characters.</p>
","4561679","","4671027","","2018-10-02 16:28:20","2021-06-21 10:57:46","docker run <IMAGE> <MULTIPLE COMMANDS>","<docker><docker-image>","8","1","69","","","CC BY-SA 3.0","28490909","2","","28490874","2015-02-13 01:07:53","","499","","<p>To run multiple commands in docker, use <code>/bin/bash -c</code> and semicolon <code>;</code></p>

<pre><code>docker run image_name /bin/bash -c ""cd /path/to/somewhere; python a.py""
</code></pre>

<p>In case we need command2 (python) will be executed if and only if command1 (cd) returned zero (no error) exit status, use <code>&amp;&amp;</code> instead of <code>;</code></p>

<pre><code>docker run image_name /bin/bash -c ""cd /path/to/somewhere &amp;&amp; python a.py""
</code></pre>
","3015960","","2757916","","2019-06-20 21:44:57","2019-06-20 21:44:57","","","","6","","","","CC BY-SA 4.0"
"31251356","1","31750543","","2015-07-06 16:47:39","","256","539688","<p>I'm using docker registry v1 and I'm interested in migrating to the newer version, v2. But I need some way to get a list of images present on registry; for example with registry v1 I can execute a GET request to <code>http://myregistry:5000/v1/search?</code> and the result is:</p>

<pre><code>{
  ""num_results"": 2,
  ""query"": """",
  ""results"": [
    {
      ""description"": """",
      ""name"": ""deis/router""
    },
    {
      ""description"": """",
      ""name"": ""deis/database""
    }
  ]
}
</code></pre>

<p>But I can't find on <a href=""https://docs.docker.com/registry/spec/api/"" rel=""noreferrer"">official documentation</a> something similar to get a list of image on registry. Anybody knows a way to do it on new version v2?</p>
","896830","","1736679","","2016-06-27 06:28:22","2021-04-20 14:00:03","How to get a list of images on docker registry v2","<docker><docker-registry>","16","2","78","","","CC BY-SA 3.0","31750543","2","","31251356","2015-07-31 16:04:41","","490","","<p>For the latest (as of 2015-07-31) version of Registry V2, you can get <a href=""https://registry.hub.docker.com/u/distribution/registry/"" rel=""noreferrer"">this image</a> from DockerHub:</p>
<pre><code>docker pull distribution/registry:master
</code></pre>
<p>List all repositories (effectively images):</p>
<pre><code>curl -X GET https://myregistry:5000/v2/_catalog
&gt; {&quot;repositories&quot;:[&quot;redis&quot;,&quot;ubuntu&quot;]}
</code></pre>
<p>List all tags for a repository:</p>
<pre><code>curl -X GET https://myregistry:5000/v2/ubuntu/tags/list
&gt; {&quot;name&quot;:&quot;ubuntu&quot;,&quot;tags&quot;:[&quot;14.04&quot;]}
</code></pre>
<p>If the registry needs authentication you have to specify username and password in the <code>curl</code> command</p>
<pre><code>curl -X GET -u &lt;user&gt;:&lt;pass&gt; https://myregistry:5000/v2/_catalog
curl -X GET -u &lt;user&gt;:&lt;pass&gt; https://myregistry:5000/v2/ubuntu/tags/list
</code></pre>
","6995808","","12144008","","2021-04-20 14:00:03","2021-04-20 14:00:03","","","","7","","","","CC BY-SA 4.0"
"21398087","1","29357318","","2014-01-28 06:04:18","","274","241687","<p>I've the following images:</p>

<pre><code>alex@alexvps:~$ sudo docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
&lt;none&gt;              &lt;none&gt;              70c0e19168cf        5 days ago          1.069 GB
&lt;none&gt;              &lt;none&gt;              c2ce80b62174        8 days ago          399.2 MB
&lt;none&gt;              &lt;none&gt;              60afe4036d97        8 days ago          325.1 MB
</code></pre>

<p>and when I try to remove one of them I get:</p>

<pre><code>alex@alexvps:~$ sudo docker rmi 60afe4036d97
Error: Conflict, 60afe4036d97 wasn't deleted
2014/01/28 00:54:00 Error: failed to remove one or more images
</code></pre>

<p>How can I remove them? Why is there such conflict?</p>
","236227","","224479","","2017-01-10 22:03:54","2019-03-13 21:26:21","How can I delete Docker's images?","<docker>","17","0","101","","","CC BY-SA 3.0","29357318","2","","21398087","2015-03-30 22:15:32","","489","","<p><strong>In order to delete all images, use the given command</strong></p>

<pre><code>docker rmi $(docker images -q)
</code></pre>

<p><strong>In order to delete all containers, use the given command</strong></p>

<pre><code>docker rm $(docker ps -a -q)
</code></pre>

<p><em>Warning: This will destroy all your images and containers. It will not be possible to restore them!</em></p>

<p>This solution is provided by <a href=""https://techoverflow.net/2013/10/22/docker-remove-all-images-and-containers/?q=/blog/2013/10/22/docker-remove-all-images-and-containers/"" rel=""noreferrer"">Techoverflow.net</a>.</p>
","","user1378912","7272147","","2017-09-18 12:51:00","2017-09-18 12:51:00","","","","11","","","","CC BY-SA 3.0"
"29181032","1","37898591","","2015-03-21 09:13:31","","269","106857","<p>Supposed I have a Docker container and a folder on my host <code>/hostFolder</code>. Now if I want to add this folder to the Docker container as a volume, then I can do this either by using <code>ADD</code> in the <code>Dockerfile</code> or mounting it as a volume.</p>

<p>So far, so good.</p>

<p>Now <code>/hostFolder</code> contains a sub-folder, <code>/hostFolder/subFolder</code>.</p>

<p>I want to mount <code>/hostFolder</code> into the Docker container (whether as read-write or read-only does not matter, works both for me), but I do <strong>NOT</strong> want to have it included <code>/hostFolder/subFolder</code>. I want to exclude this, and I also want the Docker container be able to make changes to this sub-folder, without the consequence of having it changed on the host as well.</p>

<p>Is this possible? If so, how?</p>
","1333873","","","","","2020-07-08 16:22:10","Add a volume to Docker, but exclude a sub-folder","<docker><dockerfile>","9","2","74","","","CC BY-SA 3.0","37898591","2","","29181032","2016-06-18 15:24:03","","488","","<p>Using docker-compose I'm able to use node_modules locally, but ignore it in the docker container using the following syntax in the <code>docker-compose.yml</code></p>

<pre><code>volumes:
   - './angularApp:/opt/app'
   - /opt/app/node_modules/
</code></pre>

<p>So everything in <code>./angularApp</code> is mapped to <code>/opt/app</code> and then I create another mount volume <code>/opt/app/node_modules/</code> which is now empty directory - even if in my local machine <code>./angularApp/node_modules</code> is not empty.</p>
","314848","","","","","2016-06-18 15:24:03","","","","21","","","","CC BY-SA 3.0"
"31990757","1","32023104","","2015-08-13 14:16:00","","204","71261","<p>I installed <a href=""https://www.docker.com/toolbox"">Docker-Toolbox</a> just now while following their <a href=""http://docs.docker.com/mac/step_one/"">webpage</a> </p>

<p>I started with <code>Docker QuickStart Terminal</code> and see following</p>

<pre><code>                        ##         .
                  ## ## ##        ==
               ## ## ## ## ##    ===
           /""""""""""""""""""""""""""""""""""\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~
           \______ o           __/
             \    \         __/
              \____\_______/


docker is configured to use the default machine with IP 192.168.99.100
For help getting started, check out the docs at https://docs.docker.com

bash-3.2$ 
</code></pre>

<p>But when I try to perform <code>docker pull hello-world</code>, this is what I see  </p>

<pre><code>bash-3.2$ docker run hello-world
Unable to find image 'hello-world:latest' locally
Pulling repository docker.io/library/hello-world
Network timed out while trying to connect to https://index.docker.io/v1/repositories/library/hello-world/images. You may want to check your internet connection or if you are behind a proxy.
bash-3.2$ 
</code></pre>

<p>What's wrong?</p>
","379235","","2706422","","2015-08-13 14:24:16","2019-01-30 04:48:03","Network timed out while trying to connect to https://index.docker.io","<docker><docker-machine><docker-toolbox>","19","0","60","","","CC BY-SA 3.0","32023104","2","","31990757","2015-08-15 08:45:51","","481","","<p>I had the same problem this morning and the following fixed it for me:</p>

<pre><code>$ docker-machine restart default      # Restart the environment
$ eval $(docker-machine env default)  # Refresh your environment settings
</code></pre>

<p>It appears that this is due to the Docker virtual machine getting itself into a strange state. There is an open <a href=""https://github.com/docker/docker/issues/20910"">github issue here</a></p>
","5229796","","4924793","","2016-03-13 21:19:06","2016-03-13 21:19:06","","","","11","","","","CC BY-SA 3.0"
"34782678","1","46138763","","2016-01-14 06:04:08","","396","128833","<p>In practice to <strong>start</strong> a container I do:</p>

<pre><code>docker run a8asd8f9asdf0
</code></pre>

<p>If thats the case, what does:</p>

<pre><code>docker start
</code></pre>

<p>do?</p>

<p>In the manual it says</p>

<blockquote>
  <p>Start one or more stopped containers</p>
</blockquote>
","1454775","","145307","","2017-11-28 07:59:31","2020-07-13 07:17:55","Difference between Running and Starting a Docker container","<docker>","6","5","73","","","CC BY-SA 3.0","46138763","2","","34782678","2017-09-10 08:28:18","","480","","<p>This is a very important question and the answer is very simple, but fundamental:</p>

<ol>
<li>Run: create a new container of an image, and execute the container. You can create N clones of the same image. The command is:
<code>docker run IMAGE_ID</code> <strong>and not</strong> <code>docker run CONTAINER_ID</code></li>
</ol>

<p><a href=""https://i.stack.imgur.com/AgpZe.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/AgpZe.jpg"" alt=""enter image description here""></a></p>

<ol start=""2"">
<li>Start: Launch a container previously stopped. For example, if you had stopped a database with the command <code>docker stop CONTAINER_ID</code>, you can relaunch the same container with the command <code>docker start CONTAINER_ID</code>, and the data and settings will be the same.</li>
</ol>

<p><a href=""https://i.stack.imgur.com/0C19P.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0C19P.jpg"" alt=""enter image description here""></a></p>
","3467532","","1478762","","2018-07-20 17:45:22","2018-07-20 17:45:22","","","","7","","","","CC BY-SA 4.0"
"38088279","1","38089080","","2016-06-29 00:13:57","","390","225027","<p>I have two separate <code>docker-compose.yml</code> files in two different folders:</p>

<ul>
<li><code>~/front/docker-compose.yml</code></li>
<li><code>~/api/docker-compose.yml</code></li>
</ul>

<p>How can I make sure that a container in <code>front</code> can send requests to a container in <code>api</code>?</p>

<p>I know that <code>--default-gateway</code> option can be set using <code>docker run</code> for an individual container, so that a specific IP address can be assigned to this container, but it seems that this option is not available when using <code>docker-compose</code>.</p>

<p>Currently I end up doing a <code>docker inspect my_api_container_id</code> and look at the gateway in the output. It works but the problem is that this IP is randomly attributed, so I can't rely on it.</p>

<p>Another form of this question might thus be:</p>

<ul>
<li>Can I attribute a fixed IP address to a particular container using docker-compose?</li>
</ul>

<p>But in the end what I'm looking after is:</p>

<ul>
<li>How can two different docker-compose projects communicate with each other?</li>
</ul>
","2091169","","1549950","","2019-06-21 11:48:53","2020-11-23 08:40:36","Communication between multiple docker-compose projects","<networking><docker><docker-compose>","13","1","125","","","CC BY-SA 4.0","38089080","2","","38088279","2016-06-29 01:58:03","","477","","<p>You just need to make sure that the containers you want to talk to each other are on the same network. Networks are a first-class docker construct, and not specific to compose.</p>
<pre class=""lang-yaml prettyprint-override""><code># front/docker-compose.yml
version: '2'
services:
  front:
    ...
    networks:
      - some-net
networks:
  some-net:
    driver: bridge
</code></pre>
<p>...</p>
<pre class=""lang-yaml prettyprint-override""><code># api/docker-compose.yml
version: '2'
services:
  api:
    ...
    networks:
      - front_some-net
networks:
  front_some-net:
    external: true
</code></pre>
<blockquote>
<p>Note: Your app’s network is given a name based on the “project name”, which is based on the name of the directory it lives in, in this case a prefix <code>front_</code> was added</p>
</blockquote>
<p>They can then talk to each other using the service name. From <code>front</code> you can do <code>ping api</code> and vice versa.</p>
","559504","","13087977","","2020-11-23 08:40:36","2020-11-23 08:40:36","","","","15","","","","CC BY-SA 4.0"
"41485217","1","41489151","","2017-01-05 12:32:21","","204","205918","<p><strong>Description</strong></p>

<p>I am using Docker version 1.12.5 on Windows 10 via Hyper-V and want to use container executables as commands in the current path. I built a Docker image that is running fine, but I have a problem to mount the current path. The idea is to create an alias and do a <code>docker run --rm [...]</code> command so that it could be used system-wide in the current directory.</p>

<p><strong>Setup</strong></p>

<p>I have a drive E with a folder ""test"" and in there a folder called ""folder on windows host"" to show that the command is working. The Dockerfile create the directory <code>/data</code>, defines it as VOLUME and WORKDIR.</p>

<p>Having <code>E:\test</code> as the current directory in PowerShell and executing the Docker command with an absolute path, I can see the content of <code>E:\test</code>:</p>

<pre><code>PS E:\test&gt; docker run --rm -it -v E:\test:/data mirkohaaser/docker-clitools ls -la
total 0
drwxr-xr-x 2 root root 0 Jan  4 11:45 .
drwxr-xr-x 2 root root 0 Jan  5 12:17 folder on windows host
</code></pre>

<p><strong>Problem</strong></p>

<p>I want to use the current directory and not an absolute notation. I could not use pwd in the volume because of different error messages:</p>

<p>Trying with ($pwd)</p>

<pre><code>PS E:\test&gt; docker run --rm -it -v ($pwd):/data mirkohaaser/docker-clitools ls -la
C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Error parsing reference: "":/data"" is not a valid repository/tag.
See 'C:\Program Files\Docker\Docker\Resources\bin\docker.exe run --help'.
</code></pre>

<p>Trying with /($pwd)</p>

<pre><code>PS E:\test&gt; docker run --rm -it -v /($pwd):/data mirkohaaser/docker-clitools ls -la
C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Error parsing reference: ""E:\\test"" is not a valid repository/tag.
See 'C:\Program Files\Docker\Docker\Resources\bin\docker.exe run --help'.
</code></pre>

<p>Trying with \´pwd\´</p>

<pre><code>PS E:\test&gt; docker run --rm -it -v ´$pwd´:/data mirkohaaser/docker-clitools ls -la
C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Error response from daemon: Invalid bind mount spec ""´E:\\test´:/data"": invalid mode: /data.
See 'C:\Program Files\Docker\Docker\Resources\bin\docker.exe run --help'.
</code></pre>

<p>Trying with `pwd`</p>

<pre><code>PS E:\test&gt; docker run --rm -it -v `$pwd`:/data mirkohaaser/docker-clitools ls -la
C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Error response from daemon: create $pwd: ""$pwd"" includes invalid characters for a local volume name, only ""[a-zA-Z0-9][a-zA-Z0-9_.-]"" are allowed.
See 'C:\Program Files\Docker\Docker\Resources\bin\docker.exe run --help'.
</code></pre>

<p>What is the correct syntax of mounting the current directory as a volume in Docker on Windows 10?</p>
","4034179","","63550","","2018-08-06 17:20:28","2020-06-22 12:17:43","Mount current directory as a volume in Docker on Windows 10","<windows><docker>","10","1","70","","","CC BY-SA 4.0","41489151","2","","41485217","2017-01-05 15:49:06","","474","","<p>In Windows Command Line (<code>cmd</code>), you can mount the current directory like so:</p>

<pre><code>docker run --rm -it -v %cd%:/usr/src/project gcc:4.9
</code></pre>

<p>In PowerShell, you use <code>${PWD}</code>, which gives you the current directory:</p>

<pre><code>docker run --rm -it -v ${PWD}:/usr/src/project gcc:4.9
</code></pre>

<p>On Linux:</p>

<pre><code>docker run --rm -it -v $(pwd):/usr/src/project gcc:4.9
</code></pre>

<p><strong>Cross Platform</strong></p>

<p>The following options will work on both PowerShell and on Linux (at least Ubuntu):</p>

<pre><code>docker run --rm -it -v ${PWD}:/usr/src/project gcc:4.9
docker run --rm -it -v $(pwd):/usr/src/project gcc:4.9
</code></pre>
","2026105","","2026105","","2019-03-28 13:42:27","2019-03-28 13:42:27","","","","8","","","","CC BY-SA 4.0"
"42297387","1","42297949","","2017-02-17 11:57:44","","245","176999","<p>According to the <a href=""https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables-build-arg"" rel=""noreferrer"">documentation</a>, it's possible to define multiple args for the flag <code>--build-arg</code>, but I can't find out how. I tried the following:</p>

<pre><code>docker build -t essearch/ess-elasticsearch:1.7.6 --build-arg number_of_shards=5 number_of_replicas=2 --no-cache .
</code></pre>

<p>=> This returns an error.</p>

<p>I also tried:</p>

<pre><code>docker build -t essearch/ess-elasticsearch:1.7.6 --build-arg number_of_shards=5,number_of_replicas=2 --no-cache .
</code></pre>

<p>=> This sets one variable, <code>number_of_shards</code>, to the value ""5,number_of_replicas=2""</p>

<p>Any idea how I can define multiple arguments?</p>
","2858871","","1828296","","2018-12-26 06:13:04","2021-04-09 10:42:04","docker build with --build-arg with multiple arguments","<docker><build><arguments>","5","0","27","","","CC BY-SA 3.0","42297949","2","","42297387","2017-02-17 12:26:15","","472","","<p>Use <code>--build-arg</code> with each argument.</p>

<p>If you are passing two argument then add <code>--build-arg</code> with each argument like:</p>

<pre><code>docker build \
-t essearch/ess-elasticsearch:1.7.6 \
--build-arg number_of_shards=5 \
--build-arg number_of_replicas=2 \
--no-cache .
</code></pre>
","5035803","","6440904","","2018-10-19 06:31:02","2018-10-19 06:31:02","","","","1","","","","CC BY-SA 4.0"
"37458287","1","37458519","","2016-05-26 10:32:53","","369","427285","<p>I am trying to run a cronjob inside a docker container that invokes a shell script.</p>

<p>Yesterday I have been searching all over the web and stack overflow, but I could not really find a solution that works.<br>
How can I do this?</p>

<p><strong>EDIT:</strong></p>

<p>I've created a <a href=""https://github.com/cheyer/docker-cron"" rel=""noreferrer"">(commented) github repository</a> with a working docker cron container that invokes a shell script at given interval.</p>
","6268839","","6268839","","2016-05-26 14:24:07","2021-06-27 23:59:26","How to run a cron job inside a docker container?","<docker><cron><containers><sh>","22","0","181","","","CC BY-SA 3.0","37458519","2","","37458287","2016-05-26 10:42:39","","468","","<p>You can copy your crontab into an image, in order for the container launched from said image to run the job.</p>
<p>See &quot;<a href=""https://github.com/Ekito/docker-cron"" rel=""noreferrer"">Run a cron job with Docker</a>&quot; from <a href=""https://github.com/julienboulay"" rel=""noreferrer"">Julien Boulay</a> in his <a href=""https://github.com/Ekito/docker-cron"" rel=""noreferrer""><strong><code>Ekito/docker-cron</code></strong></a>:</p>
<blockquote>
<p>Let’s create a new file called &quot;<code>hello-cron</code>&quot; to describe our job.</p>
</blockquote>
<pre><code>* * * * * echo &quot;Hello world&quot; &gt;&gt; /var/log/cron.log 2&gt;&amp;1
# An empty line is required at the end of this file for a valid cron file.
</code></pre>
<p>If you are wondering what is 2&gt;&amp;1, <a href=""https://stackoverflow.com/users/40005/ayman-hourieh"">Ayman Hourieh</a> <a href=""https://stackoverflow.com/a/818284"">explains</a>.</p>
<blockquote>
<p>The following Dockerfile describes all the steps to build your image</p>
</blockquote>
<pre><code>FROM ubuntu:latest
MAINTAINER docker@ekito.fr

RUN apt-get update &amp;&amp; apt-get -y install cron

# Copy hello-cron file to the cron.d directory
COPY hello-cron /etc/cron.d/hello-cron
 
# Give execution rights on the cron job
RUN chmod 0644 /etc/cron.d/hello-cron

# Apply cron job
RUN crontab /etc/cron.d/hello-cron
 
# Create the log file to be able to run tail
RUN touch /var/log/cron.log
 
# Run the command on container startup
CMD cron &amp;&amp; tail -f /var/log/cron.log
</code></pre>
<p>(see <a href=""https://stackoverflow.com/users/3716153/gaafar"">Gaafar</a>'s <a href=""https://stackoverflow.com/questions/37458287/how-to-run-a-cron-job-inside-a-docker-container/37458519?noredirect=1#comment67411829_37458519"">comment</a> and <a href=""https://askubuntu.com/questions/258219/how-do-i-make-apt-get-install-less-noisy#comment326577_258226"">How do I make <code>apt-get</code> install less noisy?</a>:<br />
<code>apt-get -y install -qq --force-yes cron</code> can work too)</p>
<p>As noted by <a href=""https://stackoverflow.com/users/3417592/nathan-lloyd"">Nathan Lloyd</a> in <a href=""https://stackoverflow.com/questions/37458287/how-to-run-a-cron-job-inside-a-docker-container/37458519#comment107451752_37458519"">the comments</a>:</p>
<blockquote>
<p>Quick note about a gotcha:<br />
If you're adding a script file and telling cron to run it, remember to<br />
<strong><code>RUN chmod 0744 /the_script</code></strong><br />
<strong>Cron fails silently if you forget</strong>.</p>
</blockquote>
<hr />
<p>OR, make sure your job itself redirect directly to stdout/stderr instead of a log file, as described in <a href=""https://stackoverflow.com/users/7906071/hugoshaka"">hugoShaka</a>'s <a href=""https://stackoverflow.com/a/46220104/6309"">answer</a>:</p>
<pre><code> * * * * * root echo hello &gt; /proc/1/fd/1 2&gt;/proc/1/fd/2
</code></pre>
<p>Replace the last Dockerfile line with</p>
<pre><code>CMD [&quot;cron&quot;, &quot;-f&quot;]
</code></pre>
<p>See also (about <code>cron -f</code>, which is to say cron &quot;foreground&quot;) &quot;<a href=""https://stackoverflow.com/q/30529057/6309"">docker ubuntu <code>cron -f</code> is not working</a>&quot;</p>
<hr />
<p>Build and run it:</p>
<pre><code>sudo docker build --rm -t ekito/cron-example .
sudo docker run -t -i ekito/cron-example
</code></pre>
<blockquote>
<p>Be patient, wait for 2 minutes and your commandline should display:</p>
</blockquote>
<pre><code>Hello world
Hello world
</code></pre>
<hr />
<p><a href=""https://stackoverflow.com/users/1032870/eric"">Eric</a> adds <a href=""https://stackoverflow.com/questions/37458287/how-to-run-a-cron-job-inside-a-docker-container/37458519#comment84898391_37458519"">in the comments</a>:</p>
<blockquote>
<p>Do note that <code>tail</code> may not display the correct file if it is created during image build.<br />
If that is the case, you need to create or touch the file during container runtime in order for tail to pick up the correct file.</p>
</blockquote>
<p>See &quot;<a href=""https://stackoverflow.com/a/43807880/6309"">Output of <code>tail -f</code> at the end of a docker <code>CMD</code> is not showing</a>&quot;.</p>
<hr />
<p>See more in &quot;<a href=""https://blog.thesparktree.com/cron-in-docker"" rel=""noreferrer""><strong>Running Cron in Docker</strong></a>&quot; (Apr. 2021) from <a href=""https://stackoverflow.com/users/1157633/jason-kulatunga""><strong>Jason Kulatunga</strong></a>, as he <a href=""https://stackoverflow.com/questions/37458287/how-to-run-a-cron-job-inside-a-docker-container/37458519#comment118918017_37458519"">commented below</a></p>
<p>See Jason's image <a href=""https://github.com/AnalogJ/docker-cron"" rel=""noreferrer""><code>AnalogJ/docker-cron</code></a> based on:</p>
<ul>
<li><p>Dockerfile installing <code>cronie</code>/<code>crond</code>, depending on distribution.</p>
</li>
<li><p>an entrypoint initializing <code>/etc/environment</code> and then calling</p>
<pre><code>cron -f -l 2
</code></pre>
</li>
</ul>
","6309","","6309","","2021-04-27 07:35:47","2021-04-27 07:35:47","","","","36","","","","CC BY-SA 4.0"
"19537645","1","34600106","","2013-10-23 09:16:03","","295","270611","<p>I'm building a container for a ruby app. My app's configuration is contained within environment variables (loaded inside the app with <a href=""http://github.com/bkeepers/dotenv"">dotenv</a>).</p>

<p>One of those configuration variables is the public ip of the app, which is used internally to make links.
I need to add a dnsmasq entry pointing this ip to 127.0.0.1 inside the container, so it can fetch the app's links as if it were not containerized.</p>

<p>I'm therefore trying to set an <code>ENV</code> in my Dockerfile which would pass an environment variable to the container.</p>

<p>I tried a few things.</p>

<pre><code>ENV REQUEST_DOMAIN $REQUEST_DOMAIN
ENV REQUEST_DOMAIN `REQUEST_DOMAIN`
</code></pre>

<p>Everything passes the ""REQUEST_DOMAIN"" string instead of the value of the environment variable though.
Is there a way to pass environment variables values from the host machine to the container?</p>
","122080","","","","","2020-05-17 14:34:17","Get environment variable value in Dockerfile","<docker>","6","0","59","","","CC BY-SA 3.0","34600106","2","","19537645","2016-01-04 21:23:22","","466","","<p>You should use the <a href=""https://docs.docker.com/engine/reference/builder/#arg"" rel=""noreferrer""><code>ARG</code> directive</a> in your Dockerfile which is meant for this purpose.</p>

<blockquote>
  <p>The <code>ARG</code> instruction defines a variable that users can pass at build-time to the builder with the docker build command using the <code>--build-arg &lt;varname&gt;=&lt;value&gt;</code> flag.</p>
</blockquote>

<p>So your <em>Dockerfile</em> will have this line:</p>

<pre><code>ARG request_domain
</code></pre>

<p>or if you'd prefer a default value:</p>

<pre><code>ARG request_domain=127.0.0.1
</code></pre>

<p>Now you can reference this variable inside your Dockerfile:</p>

<pre><code>ENV request_domain=$request_domain
</code></pre>

<p>then you will build your container like so:</p>

<pre><code>$ docker build --build-arg request_domain=mydomain Dockerfile
</code></pre>

<p><br>
<strong>Note 1:</strong> Your image will not build if you have referenced an <code>ARG</code> in your Dockerfile but excluded it in <code>--build-arg</code>. </p>

<p><strong>Note 2:</strong> If a user specifies a build argument that was not defined in the Dockerfile, the build outputs a warning:</p>

<blockquote>
  <p>[Warning] One or more build-args [foo] were not consumed.</p>
</blockquote>
","3025825","","3032209","","2018-02-15 17:35:05","2018-02-15 17:35:05","","","","9","","","","CC BY-SA 3.0"
"32353055","1","39329138","","2015-09-02 12:23:18","","308","260949","<p>I would like to start a stopped Docker container with a different command, as the default command crashes - meaning I can't start the container and then use 'docker exec'. </p>

<p>Basically I would like to start a shell so I can inspect the contents of the container.</p>

<p>Luckily I created the container with the -it option!</p>
","150050","","","","","2021-03-30 13:56:46","How to start a stopped Docker container with a different command?","<docker>","9","0","116","","","CC BY-SA 3.0","39329138","2","","32353055","2016-09-05 10:58:15","","465","","<h1>Find your stopped container id</h1>

<pre><code>docker ps -a
</code></pre>

<h1>Commit the stopped container:</h1>

<p>This command saves modified container state into a new image <code>user/test_image</code></p>

<pre><code>docker commit $CONTAINER_ID user/test_image
</code></pre>

<h1>Start/run with a different entry point:</h1>

<pre><code>docker run -ti --entrypoint=sh user/test_image
</code></pre>

<p>Entrypoint argument description: <a href=""https://docs.docker.com/engine/reference/run/#/entrypoint-default-command-to-execute-at-runtime"" rel=""noreferrer"">https://docs.docker.com/engine/reference/run/#/entrypoint-default-command-to-execute-at-runtime</a></p>

<h1>Note:</h1>

<p>Steps above just start a stopped container with the same filesystem state. That is great for a quick investigation. But environment variables, network configuration, attached volumes and other staff is not inherited, you should specify all these arguments explicitly.</p>

<p>Steps to start a stopped container have been borrowed from here: (last comment) <a href=""https://github.com/docker/docker/issues/18078"" rel=""noreferrer"">https://github.com/docker/docker/issues/18078</a> </p>
","1421254","","1421254","","2017-09-01 10:51:51","2017-09-01 10:51:51","","","","13","","","","CC BY-SA 3.0"
"40944479","1","40944512","","2016-12-03 05:14:18","","286","211500","<p>I created a docker image from openjdk:8-jdk-alpine but when I try to execute simple commands I get the following errors:</p>

<pre><code>RUN bash
/bin/sh: bash: not found

RUN ./gradlew build
env: can't execute 'bash': No such file or directory
</code></pre>
","4830460","","10907864","","2020-11-07 11:35:59","2020-11-07 11:35:59","Docker: How to use bash with an Alpine based docker image?","<bash><docker><dockerfile><alpine>","4","2","55","","","CC BY-SA 4.0","40944512","2","","40944479","2016-12-03 05:18:06","","458","","<p>Alpine docker image doesn't have bash installed by default. You will need to add following commands to get <code>bash</code>:</p>

<pre><code>RUN apk update &amp;&amp; apk add bash
</code></pre>

<p>If youre using <code>Alpine 3.3+</code> then you can just do</p>

<pre><code>RUN apk add --no-cache bash
</code></pre>

<p>to keep docker image size small. (Thanks to comment from @sprkysnrky)</p>
","548225","","548225","","2016-12-03 15:22:58","2016-12-03 15:22:58","","","","3","","","","CC BY-SA 3.0"
"26598738","1","26599273","","2014-10-27 23:47:58","","266","276233","<p>I have been trying to set up a container for a development postgres instance by creating a custom user &amp; database. I am using the <a href=""https://registry.hub.docker.com/_/postgres/"" rel=""noreferrer"">official postgres docker image</a>. In the documentation it instructs you to insert a bash script inside of the <code>/docker-entrypoint-initdb.d/</code> folder to set up the database with any custom parameters.</p>

<h2>My bash script: make_db.sh</h2>

<pre><code>su postgres -c ""createuser -w -d -r -s docker""
su postgres -c ""createdb -O docker docker""
</code></pre>

<h2>Dockerfile</h2>

<pre><code>FROM library/postgres

RUN [""mkdir"", ""/docker-entrypoint-initdb.d""]
ADD make_db.sh /docker-entrypoint-initdb.d/
</code></pre>

<p>The error I get from the <code>docker logs -f db</code> (db is my container name) is:</p>

<blockquote>
  <p>createuser: could not connect to database postgres: could not connect to server: No such file or directory</p>
</blockquote>

<p>It seems that the commands inside of the <code>/docker-entrypoint-initdb.d/</code> folder are being executed before postgres is started. My question is, how do I set up a user/database programmatically using the official postgres container? Is there any way to do this with a script?</p>
","2308178","","46914","","2017-02-13 04:52:29","2021-07-02 13:02:08","How to create User/Database in script for Docker Postgres","<bash><postgresql><docker><dockerhub>","8","0","91","","","CC BY-SA 3.0","26599273","2","","26598738","2014-10-28 00:58:38","","457","","<h2>EDIT - since Jul 23, 2015</h2>

<p>The <a href=""https://hub.docker.com/_/postgres/"" rel=""noreferrer"">official postgres docker image</a> will run <code>.sql</code> scripts found in the <code>/docker-entrypoint-initdb.d/</code> folder. </p>

<p>So all you need is to create the following sql script: </p>

<p><em>init.sql</em></p>

<pre><code>CREATE USER docker;
CREATE DATABASE docker;
GRANT ALL PRIVILEGES ON DATABASE docker TO docker;
</code></pre>

<p>and add it in your Dockerfile:</p>

<p><em>Dockerfile</em></p>

<pre><code>FROM library/postgres
COPY init.sql /docker-entrypoint-initdb.d/
</code></pre>

<hr>

<p>But since July 8th, 2015, <strong>if all you need is to create a user and database</strong>, it is easier to just make use to the <code>POSTGRES_USER</code>, <code>POSTGRES_PASSWORD</code> and <code>POSTGRES_DB</code> environment variables:</p>

<pre><code>docker run -e POSTGRES_USER=docker -e POSTGRES_PASSWORD=docker -e POSTGRES_DB=docker library/postgres
</code></pre>

<p>or with a Dockerfile:</p>

<pre><code>FROM library/postgres
ENV POSTGRES_USER docker
ENV POSTGRES_PASSWORD docker
ENV POSTGRES_DB docker
</code></pre>

<hr>

<h2>for images older than Jul 23, 2015</h2>

<p>From <a href=""https://registry.hub.docker.com/_/postgres/"" rel=""noreferrer"">the documentation of the postgres Docker image</a>, it is said that</p>

<blockquote>
  <p>[...] it will source any *.sh script found in that directory [<code>/docker-entrypoint-initdb.d</code>] to do further initialization before starting the service</p>
</blockquote>

<p>What's important here is <em>""before starting the service""</em>. This means your script <em>make_db.sh</em> will be executed before the postgres service would be started, hence the error message <em>""could not connect to database postgres""</em>.</p>

<p>After that there is another useful piece of information:</p>

<blockquote>
  <p>If you need to execute SQL commands as part of your initialization, the use of Postgres single user mode is highly recommended.</p>
</blockquote>

<p>Agreed this can be a bit mysterious at the first look. What it says is that your initialization script should start the postgres service in single mode before doing its actions. So you could change your <em>make_db.ksh</em> script as follows and it should get you closer to what you want:</p>

<p><strong>NOTE</strong>, this has changed recently <a href=""https://github.com/docker-library/postgres/pull/75/commits"" rel=""noreferrer"">in the following commit</a>.  This will work with the latest change:</p>

<pre class=""lang-sh prettyprint-override""><code>export PGUSER=postgres
psql &lt;&lt;- EOSQL
    CREATE USER docker;
    CREATE DATABASE docker;
    GRANT ALL PRIVILEGES ON DATABASE docker TO docker;
EOSQL
</code></pre>

<p>Previously, the use of <code>--single</code> mode was required:</p>

<pre class=""lang-sh prettyprint-override""><code>gosu postgres postgres --single &lt;&lt;- EOSQL
    CREATE USER docker;
    CREATE DATABASE docker;
    GRANT ALL PRIVILEGES ON DATABASE docker TO docker;
EOSQL
</code></pre>
","107049","","368896","","2018-06-26 14:22:30","2018-06-26 14:22:30","","","","20","","","","CC BY-SA 4.0"
"33562109","1","33782459","","2015-11-06 08:06:32","","254","233972","<p>I want to make a move to Docker, so I've just started to mess around with it. I've installed Docker on a VirtualBox Ubuntu 15.10 (Wily Werewolf) installation and as <a href=""https://blog.docker.com/2015/04/tips-for-deploying-nginx-official-image-with-docker/"" rel=""noreferrer"">suggested here</a> I then tried running a basic <a href=""http://en.wikipedia.org/wiki/Nginx"" rel=""noreferrer"">nginx</a> Docker image:</p>

<pre><code>$ docker run --name mynginx1 -P -d nginx
Cannot connect to the Docker daemon. Is the docker daemon running on this host?
</code></pre>

<p>So I checked out whether Docker was running:</p>

<pre><code>$ sudo service docker status
● docker.service - Docker Application Container Engine
   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
   Active: active (running) since vr 2015-11-06 08:41:48 CET; 15min ago
     Docs: https://docs.docker.com
 Main PID: 7542 (docker)
   CGroup: /system.slice/docker.service
           └─7542 /usr/bin/docker daemon -H fd://

nov 06 08:41:47 kramer65-VirtualBox systemd[1]: Starting Docker Application Container Engine...
nov 06 08:41:47 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:47.900410966+01:00"" level=info msg=""API ...ock""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.033514149+01:00"" level=info msg=""Fire...lse""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.141594321+01:00"" level=info msg=""Defa...ess""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.416294436+01:00"" level=warning msg=""Y...it.""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.565507576+01:00"" level=info msg=""Load...rt.""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.567907022+01:00"" level=info msg=""Load...ne.""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.567945214+01:00"" level=info msg=""Daem...ion""
nov 06 08:41:48 kramer65-VirtualBox docker[7542]: time=""2015-11-06T08:41:48.567969891+01:00"" level=info msg=""Dock....9.0
nov 06 08:41:48 kramer65-VirtualBox systemd[1]: Started Docker Application Container Engine.
Hint: Some lines were ellipsized, use -l to show in full.
</code></pre>

<p>This suggests that the Docker daemon is actually already running, but to be sure I just started the Docker daemon manually:</p>

<pre><code>$ sudo docker daemon
INFO[0000] API listen on /var/run/docker.sock           
INFO[0000] [graphdriver] using prior storage driver ""aufs"" 
INFO[0000] Firewalld running: false                     
INFO[0000] Default bridge (docker0) is assigned with an IP address XXX.XX.X.X/XX. Daemon option --bip can be used to set a preferred IP address 
WARN[0000] Your kernel does not support swap memory limit. 
INFO[0000] Loading containers: start.                   

INFO[0000] Loading containers: done.                    
INFO[0000] Daemon has completed initialization          
INFO[0000] Docker daemon                                 commit=76d6bc9 execdriver=native-0.2 graphdriver=aufs version=1.9.0
</code></pre>

<p>I then tried running the image again, but with the same result:</p>

<pre><code>$ docker run --name mynginx1 -P -d nginx
Cannot connect to the Docker daemon. Is the docker daemon running on this host?
</code></pre>

<p>I tried sudo'ing the command, but to no avail. What am I doing wrong here? </p>
","1650012","","63550","","2017-03-11 10:22:37","2021-01-22 12:20:14","Docker command can't connect to Docker daemon","<linux><ubuntu><docker><daemon>","24","8","72","","","CC BY-SA 3.0","33782459","2","","33562109","2015-11-18 14:19:51","","454","","<p>You need to add your current user to the docker group as follows:</p>

<pre><code>sudo usermod -aG docker $(whoami)
</code></pre>

<p>then <strong>logout &amp; login again</strong> into the system or restart the system.
test by <code>docker version</code></p>

<p>for further info how to install docker-engine follow <a href=""http://docs.docker.com/engine/installation/ubuntulinux/"" rel=""noreferrer"">docker documentation</a></p>
","1520197","","11272717","","2019-04-30 15:12:39","2019-04-30 15:12:39","","","","9","","","","CC BY-SA 4.0"
"42248198","1","42260979","","2017-02-15 11:33:27","","343","357349","<p>I am trying to dockerize a PHP application. In the dockerfile, I download the archive, extract it, etc.</p>
<p>Everything works fine. However, if a new version gets released and I update the dockerfile, I have to reinstall the application, because the config.php gets overwritten.</p>
<p>So I thought I can mount the file as a volume, like I do with the database.</p>
<p>I tried it two ways, with a volume and a direct path.</p>
<p>docker-compose:</p>
<pre class=""lang-yaml prettyprint-override""><code>version: '2'
services:
  app:
    build: src
    ports:
      - &quot;8080:80&quot;
    depends_on:
      - mysql
    volumes:
      -  app-conf:/var/www/html/upload
      -  app-conf:/var/www/html/config.php
    environment:
      DB_TYPE: mysql
      DB_MANAGER: MysqlManager

  mysql:
    image: mysql:5.6
    container_name: mysql
    volumes:
      - mysqldata:/var/lib/mysql
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD:
      MYSQL_DATABASE:
      MYSQL_USER:
      MYSQL_PASSWORD:

volumes:
  mysqldata:
  app-conf:
</code></pre>
<p>Which results in the error:</p>
<p>And I tried it with a given path, as a mounted volume.</p>
<pre><code>/src/docker/myapp/upload:/var/www/html/upload
/src/docker/myapp/upload:/var/www/html/config.php
</code></pre>
<p>However, both ways are not working. With the mounted volume, I see that upload gets created.</p>
<p>But then it fails with:</p>
<blockquote>
<p>/var/www/html/config.php\&quot; caused \&quot;not a directory\&quot;&quot;&quot;</p>
</blockquote>
<p>If I try it with</p>
<pre><code>/src/docker/myapp/upload/config.php:/var/www/html/config.php
</code></pre>
<p>Docker creates the upload folder and then a config.php folder. Not a file.</p>
<p>Or is there another way to persist the config?</p>
","3791380","","1402846","","2020-10-06 00:19:11","2021-04-21 13:28:31","How to mount a single file in a volume","<docker><docker-compose>","15","1","52","","","CC BY-SA 4.0","42260979","2","","42248198","2017-02-15 22:06:14","","453","","<blockquote>
  <h1>TL;DR/Notice:</h1>
  
  <p>If you experience a directory being created in place of the file you are trying to mount, you have probably failed to supply a <strong>valid</strong> and <strong>absolute</strong> path. This is a common mistake with a silent and confusing failure mode.</p>
</blockquote>

<p>File volumes are done this way in docker (absolute path example (can use env variables), and you need to mention the file name) :</p>

<pre><code>    volumes:
      - /src/docker/myapp/upload:/var/www/html/upload
      - /src/docker/myapp/upload/config.php:/var/www/html/config.php
</code></pre>

<p>You can also do:</p>

<pre><code>    volumes:
      - ${PWD}/upload:/var/www/html/upload
      - ${PWD}/upload/config.php:/var/www/html/config.php
</code></pre>

<p>If you fire the docker-compose from <code>/src/docker/myapp</code> folder</p>
","5281340","","117471","","2019-03-29 21:25:23","2019-03-29 21:25:23","","","","10","","","","CC BY-SA 4.0"
"26220957","1","26222636","","2014-10-06 16:50:19","","338","118043","<p>I'm trying to build a new Docker image for our development process, using <code>cpanm</code> to install a bunch of Perl modules as a base image for various projects.</p>

<p>While developing the Dockerfile, <code>cpanm</code> returns a failure code because some of the modules did not install cleanly.</p>

<p>I'm fairly sure I need to get <code>apt</code> to install some more things.</p>

<p>My question is, where can I find the <code>/.cpanm/work</code> directory quoted in the output, in order to inspect the logs? In the general case, how can I inspect the file system of a failed <code>docker build</code> command?</p>

<p><strong>Morning edit</strong> After biting the bullet and running a <code>find</code> I discovered</p>

<pre><code>/var/lib/docker/aufs/diff/3afa404e[...]/.cpanm
</code></pre>

<p>Is this reliable, or am I better off building a ""bare"" container and running stuff manually until I have all the things I need?</p>
","2386199","","2386199","","2014-10-07 08:37:43","2021-05-03 14:05:25","How can I inspect the file system of a failed `docker build`?","<debugging><docker><cpanm>","6","1","106","","","CC BY-SA 3.0","26222636","2","","26220957","2014-10-06 18:38:36","","437","","<p>Everytime docker successfully executes a <code>RUN</code> command from a Dockerfile, <a href=""https://docs.docker.com/storage/storagedriver/#images-and-layers"" rel=""noreferrer"">a new layer in the image filesystem</a> is committed. Conveniently you can use those layers ids as images to start a new container.</p>

<p>Take the following Dockerfile:</p>

<pre><code>FROM busybox
RUN echo 'foo' &gt; /tmp/foo.txt
RUN echo 'bar' &gt;&gt; /tmp/foo.txt
</code></pre>

<p>and build it:</p>

<pre><code>$ docker build -t so-2622957 .
Sending build context to Docker daemon 47.62 kB
Step 1/3 : FROM busybox
 ---&gt; 00f017a8c2a6
Step 2/3 : RUN echo 'foo' &gt; /tmp/foo.txt
 ---&gt; Running in 4dbd01ebf27f
 ---&gt; 044e1532c690
Removing intermediate container 4dbd01ebf27f
Step 3/3 : RUN echo 'bar' &gt;&gt; /tmp/foo.txt
 ---&gt; Running in 74d81cb9d2b1
 ---&gt; 5bd8172529c1
Removing intermediate container 74d81cb9d2b1
Successfully built 5bd8172529c1
</code></pre>

<p>You can now start a new container from <code>00f017a8c2a6</code>, <code>044e1532c690</code> and <code>5bd8172529c1</code>:</p>

<pre><code>$ docker run --rm 00f017a8c2a6 cat /tmp/foo.txt
cat: /tmp/foo.txt: No such file or directory

$ docker run --rm 044e1532c690 cat /tmp/foo.txt
foo

$ docker run --rm 5bd8172529c1 cat /tmp/foo.txt
foo
bar
</code></pre>

<p>of course you might want to start a shell to explore the filesystem and try out commands:</p>

<pre><code>$ docker run --rm -it 044e1532c690 sh      
/ # ls -l /tmp
total 4
-rw-r--r--    1 root     root             4 Mar  9 19:09 foo.txt
/ # cat /tmp/foo.txt 
foo
</code></pre>

<hr>

<p>When one of the Dockerfile command fails, what you need to do is to look for the <strong>id of the preceding layer</strong> and run a shell in a container created from that id:</p>

<pre><code>docker run --rm -it &lt;id_last_working_layer&gt; bash -il
</code></pre>

<p>Once in the container:</p>

<ul>
<li>try the command that failed, and reproduce the issue</li>
<li>then fix the command and test it</li>
<li>finally update your Dockerfile with the fixed command</li>
</ul>

<hr>

<p>If you really need to experiment in the actual layer that failed instead of working from the last working layer, see <a href=""https://stackoverflow.com/a/35387446/107049"">Drew's answer</a>.</p>
","107049","","107049","","2018-06-10 07:34:03","2018-06-10 07:34:03","","","","12","","","","CC BY-SA 4.0"
"47854463","1","48450294","","2017-12-17 11:08:22","","271","267551","<p>I am new to docker. I just tried to use docker in my local machine(Ubuntu 16.04) with Jenkins. </p>

<p>I configured a new job with below pipeline script.</p>

<pre class=""lang-groovy prettyprint-override""><code>node {
    stage('Build') {
      docker.image('maven:3.3.3').inside {
        sh 'mvn --version'
      }
    }
}
</code></pre>

<p>But it fails with below error.</p>

<p><a href=""https://i.stack.imgur.com/nz6Ig.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/nz6Ig.png"" alt=""enter image description here""></a></p>
","1294150","","10907864","","2020-04-21 20:17:54","2021-06-23 19:54:09","Docker: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock","<docker><jenkins><jenkins-pipeline>","31","3","81","","","CC BY-SA 4.0","48450294","2","","47854463","2018-01-25 19:14:20","","435","","<p>The user <code>jenkins</code> needs to be added to the group <code>docker</code>:</p>
<pre><code>sudo usermod -a -G docker jenkins
</code></pre>
<p>Then restart Jenkins.</p>
<h2>Edit</h2>
<p>If you arrive to this question of stack overflow because you receive this message from docker, but you don't use jenkins, most probably the error is the same: your unprivileged user does not belong to the docker group.</p>
<p>You can do:</p>
<pre><code>sudo usermod -a -G docker [user]
</code></pre>
<p>Insert your user name where <code>[user]</code> is.</p>
<p>You can check it was successful by doing <code>grep docker /etc/group</code> and see something like this:</p>
<pre><code>docker:x:998:[user]
</code></pre>
<p>in one of the lines.</p>
<p>Then change your users group ID to <code>docker</code>:</p>
<pre><code>newgrp docker
</code></pre>
<p>Finally, log out and log in again</p>
","3322238","","199700","","2021-06-15 15:41:40","2021-06-15 15:41:40","","","","16","","","","CC BY-SA 4.0"
"19585028","1","19586345","","2013-10-25 08:36:30","","418","293924","<p>Despite Docker's <a href=""http://www.docker.io/gettingstarted/"" rel=""noreferrer"">Interactive tutorial</a> and <a href=""http://docs.docker.io/en/latest/faq/#do-i-lose-my-data-when-the-container-exits"" rel=""noreferrer"">faq</a> I lose my data when the container exits.</p>

<p>I have installed Docker as described here: <a href=""http://docs.docker.io/en/latest/installation/ubuntulinux"" rel=""noreferrer"">http://docs.docker.io/en/latest/installation/ubuntulinux</a>
without any problem on ubuntu 13.04.</p>

<p>But it loses all data when exits.</p>

<pre><code>iman@test:~$ sudo docker version
Client version: 0.6.4 
Go version (client): go1.1.2 
Git commit (client): 2f74b1c 
Server version: 0.6.4 
Git commit (server): 2f74b1c 
Go version (server): go1.1.2 
Last stable version: 0.6.4 


iman@test:~$ sudo docker run ubuntu ping
2013/10/25 08:05:47 Unable to locate ping 
iman@test:~$ sudo docker run ubuntu apt-get install ping
Reading package lists... 
Building dependency tree... 
The following NEW packages will be installed: 
  iputils-ping 
0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded. 
Need to get 56.1 kB of archives. 
After this operation, 143 kB of additional disk space will be used. 
Get:1 http://archive.ubuntu.com/ubuntu/ precise/main iputils-ping amd64 3:20101006-1ubuntu1 [56.1 kB] 
debconf: delaying package configuration, since apt-utils is not installed 
Fetched 56.1 kB in 0s (195 kB/s) 
Selecting previously unselected package iputils-ping. 
(Reading database ... 7545 files and directories currently installed.) 
Unpacking iputils-ping (from .../iputils-ping_3%3a20101006-1ubuntu1_amd64.deb) ... 
Setting up iputils-ping (3:20101006-1ubuntu1) ... 
iman@test:~$ sudo docker run ubuntu ping
2013/10/25 08:06:11 Unable to locate ping 
iman@test:~$ sudo docker run ubuntu touch /home/test
iman@test:~$ sudo docker run ubuntu ls /home/test
ls: cannot access /home/test: No such file or directory 
</code></pre>

<p>I also tested it with interactive sessions with the same result. Did I forget something?</p>

<h2>EDIT: IMPORTANT FOR NEW DOCKER USERS</h2>

<p>As @mohammed-noureldin and others said, actually this is <strong>NOT</strong> a <strong>container exiting</strong>. Every time it just creates a new container.</p>
","1675586","","1675586","","2019-04-03 06:40:09","2019-11-15 11:19:21","I lose my data when the container exits","<docker>","11","5","173","","","CC BY-SA 3.0","19586345","2","","19585028","2013-10-25 09:42:08","","430","","<p>You need to <a href=""https://docs.docker.com/engine/reference/commandline/commit/"">commit</a> the changes you make to the container and then run it. Try this:</p>

<pre><code>sudo docker pull ubuntu

sudo docker run ubuntu apt-get install -y ping
</code></pre>

<p>Then get the container id using this command:</p>

<pre><code>sudo docker ps -l
</code></pre>

<p>Commit changes to the container:</p>

<pre><code>sudo docker commit &lt;container_id&gt; iman/ping 
</code></pre>

<p>Then run the container:</p>

<pre><code>sudo docker run iman/ping ping www.google.com
</code></pre>

<p>This should work.</p>
","2469747","","471376","","2016-08-05 01:51:57","2016-08-05 01:51:57","","","","14","","","","CC BY-SA 3.0"
"30133664","1","30133768","","2015-05-08 22:18:17","","284","264071","<p>When using docker images from registries, I often need to see the volumes created by the image's containers.</p>

<p><em>Note: I'm using docker version 1.3.2 on Red Hat 7.</em></p>

<h2>Example</h2>

<p>The <code>postgres</code> official image from the Docker Registry has a volume configured for containers at <code>/var/lib/postgresql/data</code>.</p>

<p>What's the most succinct command to show the volume at <code>/var/lib/postgresql/data</code> in a <code>postgres</code> container?</p>
","2125392","","39974","","2017-03-07 13:07:42","2021-06-23 08:25:50","How do you list volumes in docker containers?","<docker>","15","1","62","","","CC BY-SA 3.0","30133768","2","","30133664","2015-05-08 22:29:44","","427","","<p>Use <code>docker ps</code> to get the container id.</p>

<p>Then <code>docker inspect -f '{{ .Mounts }}' containerid</code></p>

<p>Example:  </p>

<p>terminal 1</p>

<pre><code>$ docker run -it -v /tmp:/tmp ubuntu:14.04 /bin/bash
</code></pre>

<p>terminal 2</p>

<pre><code>$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES
ddb7b55902cc        ubuntu:14.04        ""/bin/bash""         About a minute ago   Up About a minute                       distracted_banach   

$ docker inspect -f ""{{ .Mounts }}"" ddb7
map[/tmp:/tmp]
</code></pre>

<p>The output </p>

<pre><code>map[/tmp:/tmp] 
</code></pre>

<p>is, apparently, due to the use of the <em>Go</em> language to implement the docker command tools.</p>

<p>The <code>docker inspect</code> command without the <code>-f format</code> is quite verbose.  Since it is JSON you could pipe it to python or nodejs and extract whatever you needed. </p>

<pre><code>paul@home:~$ docker inspect ddb7
[{
    ""AppArmorProfile"": """",
    ""Args"": [],
    ""Config"": {
        ""AttachStderr"": true,
        ""AttachStdin"": true,
        ""AttachStdout"": true,
        ""Cmd"": [
            ""/bin/bash""
        ],
        ""CpuShares"": 0,
        ""Cpuset"": """",
        ""Domainname"": """",
        ""Entrypoint"": null,
        ""Env"": [
            ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin""
        ],
        ""ExposedPorts"": null,
        ""Hostname"": ""ddb7b55902cc"",
        ""Image"": ""ubuntu:14.04"",
        ""MacAddress"": """",
        ""Memory"": 0,
        ""MemorySwap"": 0,
        ""NetworkDisabled"": false,
        ""OnBuild"": null,
        ""OpenStdin"": true,
        ""PortSpecs"": null,
        ""StdinOnce"": true,
        ""Tty"": true,
        ""User"": """",
        ""Volumes"": null,
        ""WorkingDir"": """"
    },
    ""Created"": ""2015-05-08T22:41:44.74862921Z"",
    ""Driver"": ""devicemapper"",
    ""ExecDriver"": ""native-0.2"",
    ""ExecIDs"": null,
    ""HostConfig"": {
        ""Binds"": [
            ""/tmp:/tmp""
        ],
        ""CapAdd"": null,
        ""CapDrop"": null,
        ""ContainerIDFile"": """",
        ""Devices"": [],
        ""Dns"": null,
        ""DnsSearch"": null,
        ""ExtraHosts"": null,
        ""IpcMode"": """",
        ""Links"": null,
        ""LxcConf"": [],
        ""NetworkMode"": ""bridge"",
        ""PidMode"": """",
        ""PortBindings"": {},
        ""Privileged"": false,
        ""PublishAllPorts"": false,
        ""ReadonlyRootfs"": false,
        ""RestartPolicy"": {
            ""MaximumRetryCount"": 0,
            ""Name"": """"
        },
        ""SecurityOpt"": null,
        ""VolumesFrom"": null
    },
    ""HostnamePath"": ""/var/lib/docker/containers/ddb7b55902cc328612d794570fe9a936d96a9644411e89c4ea116a5fef4c311a/hostname"",
    ""HostsPath"": ""/var/lib/docker/containers/ddb7b55902cc328612d794570fe9a936d96a9644411e89c4ea116a5fef4c311a/hosts"",
    ""Id"": ""ddb7b55902cc328612d794570fe9a936d96a9644411e89c4ea116a5fef4c311a"",
    ""Image"": ""ed5a78b7b42bde1e3e4c2996e02da778882dca78f8919cbd0deb6694803edec3"",
    ""MountLabel"": """",
    ""Name"": ""/distracted_banach"",
    ""NetworkSettings"": {
        ""Bridge"": ""docker0"",
        ""Gateway"": ""172.17.42.1"",
        ""GlobalIPv6Address"": """",
        ""GlobalIPv6PrefixLen"": 0,
        ""IPAddress"": ""172.17.0.4"",
        ""IPPrefixLen"": 16,
        ""IPv6Gateway"": """",
        ""LinkLocalIPv6Address"": ""fe80::42:acff:fe11:4"",
        ""LinkLocalIPv6PrefixLen"": 64,
        ""MacAddress"": ""02:42:ac:11:00:04"",
        ""PortMapping"": null,
        ""Ports"": {}
    },
    ""Path"": ""/bin/bash"",
    ""ProcessLabel"": """",
    ""ResolvConfPath"": ""/var/lib/docker/containers/ddb7b55902cc328612d794570fe9a936d96a9644411e89c4ea116a5fef4c311a/resolv.conf"",
    ""RestartCount"": 0,
    ""State"": {
        ""Error"": """",
        ""ExitCode"": 0,
        ""FinishedAt"": ""0001-01-01T00:00:00Z"",
        ""OOMKilled"": false,
        ""Paused"": false,
        ""Pid"": 6115,
        ""Restarting"": false,
        ""Running"": true,
        ""StartedAt"": ""2015-05-08T22:41:45.367432585Z""
    },
    ""Volumes"": {
        ""/tmp"": ""/tmp""
    },
    ""VolumesRW"": {
        ""/tmp"": true
    }
}
]
</code></pre>

<p><code>docker history &lt;image name&gt;</code> will show the layers baked into an image.  Unfortunately, <code>docker history</code> seems hobbled by its formatting and lack of options to choose what is displayed. </p>

<p>You can choose terse and verbose formats, via the --no-trunc flag.</p>

<pre><code>$ docker history drpaulbrewer/spark-worker
IMAGE               CREATED             CREATED BY                                      SIZE
438ff4e1753a        2 weeks ago         /bin/sh -c #(nop) CMD [/bin/sh -c /spark/my-s   0 B
6b664e299724        2 weeks ago         /bin/sh -c #(nop) ADD file:09da603c5f0dca7cc6   296 B
f6ae126ae124        2 weeks ago         /bin/sh -c #(nop) MAINTAINER drpaulbrewer@eaf   0 B
70bcb3ffaec9        2 weeks ago         /bin/sh -c #(nop) EXPOSE 2222/tcp 4040/tcp 60   0 B
1332ac203849        2 weeks ago         /bin/sh -c apt-get update &amp;&amp; apt-get --yes up   1.481 GB
8e6f1e0bb1b0        2 weeks ago         /bin/sh -c sed -e 's/archive.ubuntu.com/www.g   1.975 kB
b3d242776b1f        2 weeks ago         /bin/sh -c #(nop) WORKDIR /spark/spark-1.3.1    0 B
ac0d6cc5aa3f        2 weeks ago         /bin/sh -c #(nop) ADD file:b6549e3d28e2d149c0   25.89 MB
6ee404a44b3f        5 weeks ago         /bin/sh -c #(nop) WORKDIR /spark                0 B
c167faff18cf        5 weeks ago         /bin/sh -c adduser --disabled-password --home   335.1 kB
f55d468318a4        5 weeks ago         /bin/sh -c #(nop) MAINTAINER drpaulbrewer@eaf   0 B
19c8c047d0fe        8 weeks ago         /bin/sh -c #(nop) CMD [/bin/bash]               0 B
c44d976a473f        8 weeks ago         /bin/sh -c sed -i 's/^#\s*\(deb.*universe\)$/   1.879 kB
14dbf1d35e28        8 weeks ago         /bin/sh -c echo '#!/bin/sh' &gt; /usr/sbin/polic   701 B
afa7a164a0d2        8 weeks ago         /bin/sh -c #(nop) ADD file:57f97478006b988c0c   131.5 MB
511136ea3c5a        23 months ago                                                       0 B
</code></pre>

<p>Here's a verbose example.</p>

<pre><code>docker history --no-trunc=true drpaulbrewer/spark-worker
IMAGE                                                              CREATED             CREATED BY                                                                                                                                                                                                                                                                                                                                                                                                                        SIZE
438ff4e1753a60779f389a3de593d41f7d24a61da6e1df76dded74a688febd64   2 weeks ago         /bin/sh -c #(nop) CMD [/bin/sh -c /spark/my-spark-worker.sh]                                                                                                                                                                                                                                                                                                                                                                      0 B
6b664e29972481b8d6d47f98167f110609d9599f48001c3ca11c22364196c98a   2 weeks ago         /bin/sh -c #(nop) ADD file:09da603c5f0dca7cc60f1911caf30c3c70df5e4783f7eb10468e70df66e2109f in /spark/                                                                                                                                                                                                                                                                                                                            296 B
f6ae126ae124ca211c04a1257510930b37ea78425e31a273ea0b1495fa176c57   2 weeks ago         /bin/sh -c #(nop) MAINTAINER drpaulbrewer@eaftc.com                                                                                                                                                                                                                                                                                                                                                                               0 B
70bcb3ffaec97a0d14e93b170ed70cc7d68c3c9dfb0222c1d360a300d6e05255   2 weeks ago         /bin/sh -c #(nop) EXPOSE 2222/tcp 4040/tcp 6066/tcp 7077/tcp 7777/tcp 8080/tcp 8081/tcp                                                                                                                                                                                                                                                                                                                                           0 B
1332ac20384947fe1f15107213b675e5be36a68d72f0e81153d6d5a21acf35af   2 weeks ago         /bin/sh -c apt-get update &amp;&amp; apt-get --yes upgrade     &amp;&amp; apt-get --yes install sed nano curl wget openjdk-8-jdk scala     &amp;&amp; echo ""JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64"" &gt;&gt;/etc/environment     &amp;&amp; export MAVEN_OPTS=""-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m""     &amp;&amp; ./build/mvn -Phive -Phive-thriftserver -DskipTests clean package     &amp;&amp; chown -R spark:spark /spark     &amp;&amp; mkdir /var/run/sshd   1.481 GB
8e6f1e0bb1b0b9286947d3a4b443cc8099b00f9670aab1d58654051e06f62e51   2 weeks ago         /bin/sh -c sed -e 's/archive.ubuntu.com/www.gtlib.gatech.edu\/pub/' /etc/apt/sources.list &gt; /tmp/sources.list &amp;&amp; mv /tmp/sources.list /etc/apt/sources.list                                                                                                                                                                                                                                                                       1.975 kB
b3d242776b1f1f1ae5685471d06a91a68f92845ef6fc6445d831835cd55e5d0b   2 weeks ago         /bin/sh -c #(nop) WORKDIR /spark/spark-1.3.1                                                                                                                                                                                                                                                                                                                                                                                      0 B
ac0d6cc5aa3fdc3b65fc0173f6775af283c3c395c8dae945cf23940435f2785d   2 weeks ago         /bin/sh -c #(nop) ADD file:b6549e3d28e2d149c0bc84f69eb0beab16f62780fc4889bcc64cfc9ce9f762d6 in /spark/                                                                                                                                                                                                                                                                                                                            25.89 MB
6ee404a44b3fdd3ef3318dc10f3d002f1995eea238c78f4eeb9733d00bb29404   5 weeks ago         /bin/sh -c #(nop) WORKDIR /spark                                                                                                                                                                                                                                                                                                                                                                                                  0 B
c167faff18cfecedef30343ef1cb54aca45f4ef0478a3f6296746683f69d601b   5 weeks ago         /bin/sh -c adduser --disabled-password --home /spark spark                                                                                                                                                                                                                                                                                                                                                                        335.1 kB
f55d468318a4778733160d377c5d350dc8f593683009699c2af85244471b15a3   5 weeks ago         /bin/sh -c #(nop) MAINTAINER drpaulbrewer@eaftc.com                                                                                                                                                                                                                                                                                                                                                                               0 B
19c8c047d0fe2de7239120f2b5c1a20bbbcb4d3eb9cbf0efa59ab27ab047377a   8 weeks ago         /bin/sh -c #(nop) CMD [/bin/bash]                                                                                                                                                                                                                                                                                                                                                                                                 0 B
c44d976a473f143937ef91449c73f2cabd109b540f6edf54facb9bc2b4fff136   8 weeks ago         /bin/sh -c sed -i 's/^#\s*\(deb.*universe\)$/\1/g' /etc/apt/sources.list                                                                                                                                                                                                                                                                                                                                                          1.879 kB
14dbf1d35e2849a00c6c2628055030fa84b4fb55eaadbe0ecad8b82df65cc0db   8 weeks ago         /bin/sh -c echo '#!/bin/sh' &gt; /usr/sbin/policy-rc.d                                                                                                                                                                                                                                                                                                                                                                               &amp;&amp; echo 'exit 101' &gt;&gt; /usr/sbin/policy-rc.d    &amp;&amp; chmod +x /usr/sbin/policy-rc.d                        &amp;&amp; dpkg-divert --local --rename --add /sbin/initctl    &amp;&amp; cp -a /usr/sbin/policy-rc.d /sbin/initctl    &amp;&amp; sed -i 's/^exit.*/exit 0/' /sbin/initctl                        &amp;&amp; echo 'force-unsafe-io' &gt; /etc/dpkg/dpkg.cfg.d/docker-apt-speedup                        &amp;&amp; echo 'DPkg::Post-Invoke { ""rm -f /var/cache/apt/archives/*.deb /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true""; };' &gt; /etc/apt/apt.conf.d/docker-clean    &amp;&amp; echo 'APT::Update::Post-Invoke { ""rm -f /var/cache/apt/archives/*.deb /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true""; };' &gt;&gt; /etc/apt/apt.conf.d/docker-clean    &amp;&amp; echo 'Dir::Cache::pkgcache """"; Dir::Cache::srcpkgcache """";' &gt;&gt; /etc/apt/apt.conf.d/docker-clean                        &amp;&amp; echo 'Acquire::Languages ""none"";' &gt; /etc/apt/apt.conf.d/docker-no-languages                        &amp;&amp; echo 'Acquire::GzipIndexes ""true""; Acquire::CompressionTypes::Order:: ""gz"";' &gt; /etc/apt/apt.conf.d/docker-gzip-indexes   701 B
afa7a164a0d215dbf45cd1aadad2a4d12b8e33fc890064568cc2ea6d42ef9b3c   8 weeks ago         /bin/sh -c #(nop) ADD file:57f97478006b988c0c68e5bf82684372e427fd45f21cd7baf5d974d2cfb29e65 in /                                                                                                                                                                                                                                                                                                                                  131.5 MB
511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158   23 months ago                                                                                                                                                                                                                                                                                                                                                                                                                                         0 B
</code></pre>
","103081","","2653","","2017-09-15 09:18:55","2017-09-15 09:18:55","","","","6","","","","CC BY-SA 3.0"
"39684974","1","39989990","","2016-09-25 08:45:26","","207","233737","<p>I've installed Docker and I'm getting this error when I run the GUI:</p>

<blockquote>
  <p>Hardware assisted virtualization and data execution protection must
  be enabled in the BIOS</p>
</blockquote>

<p>Seems like a bug since Docker works like a charm from the command line, but I'm wondering if anyone has a clue about why this is happening?</p>

<p>Before you ask, yes, I've enabled virtualization in the BIOS and the Intel Processor Identification Utility confirms that it's activated. Docker, docker-machine and docker-compose all work from the command line, Virtualbox works, running Docker from a Debian or Ubuntu VM works.</p>

<p>There's just this weird issue about the GUI.</p>

<p>My specs:</p>

<ul>
<li>Windows 10 Pro x64 Anniversary Edition</li>
<li>Intel core i5-6300HQ @ 2.30GHz</li>
</ul>
","2273553","","","","","2021-05-26 16:04:13","Docker for Windows error: ""Hardware assisted virtualization and data execution protection must be enabled in the BIOS""","<windows><docker>","23","0","79","","","CC BY-SA 3.0","39989990","2","","39684974","2016-10-12 03:21:50","","425","","<p>If the features described are enabled, the problem is with Hyper-V that is disabled or Hypervisor agent not running.</p>
<p><strong>SOLUTION A</strong> (If Hyper-V is totally disabled or not installed)</p>
<ol>
<li><p>Open PowerShell as administrator and</p>
</li>
<li><p>Enable Hyper-V with</p>
<p><code>dism.exe /Online /Enable-Feature:Microsoft-Hyper-V /All</code></p>
</li>
</ol>
<p><strong>SOLUTION B</strong> (If Hyper-V feature is already enabled but doesn't work)</p>
<p>Enable Hypervisor with</p>
<pre><code>bcdedit /set hypervisorlaunchtype auto
</code></pre>
<p>Now restart the system and try again.</p>
<p><strong>SOLUTION C</strong></p>
<p>If the problem persists, probably Hyper-V on your system is corrupted, so</p>
<ol>
<li><p>Go in <code>Control Panel -&gt; [Programs] -&gt; [Windows Features]</code> and completely uncheck all Hyper-V related components. Restart the system.</p>
</li>
<li><p>Enable Hyper-V again. Restart.</p>
</li>
</ol>
<p><strong><em>NOTE 1</em>:</strong></p>
<p>Hyper-V needs hardware virtualization as prerequisite. Make sure your PC supports it, if yes and still won't work, there is the possibility your BIOS is not configured correctly and this feature is disabled. In this case, check, enable it and try again. The virtualization features could be reported under different names according the platform used (e.g if you don't see any option that uses virtualization label explicitly, on AMD you have to check <em>SVM</em> feature state, on Intel the <em>VT-x</em> feature state).</p>
<p><em><strong>NOTE 2:</strong></em></p>
<p>Hyper-V <strong>can</strong> be installed only with some version e.g.:</p>
<blockquote>
<p>Windows 10 Enterprise; Windows 10 Professional; Windows 10 Education.</p>
</blockquote>
<p>Hyper-V <strong>cannot</strong> be installed on cheaper or mobile Windows versions e.g.:</p>
<blockquote>
<p>Windows 10 Home; Windows 10 Mobile; Windows 10 Mobile Enterprise.</p>
</blockquote>
","1389756","","1389756","","2021-05-08 20:17:14","2021-05-08 20:17:14","","","","23","","","","CC BY-SA 4.0"
"45142855","1","45143116","","2017-07-17 11:18:39","","154","169244","<p>I am trying to change a dockerFile to work with aspell. I have a bash script that i want to wrap in a dock</p>

<pre><code>Step 4: Wrap the script in a Docker container.

The sample SDK we downloaded earlier contains an example of an action wrapped in a Docker container. In particular, the sample SDK includes a Dockerfile that builds the C program in client/example.c and installs the binary as /blackbox/client/action .

The key line in the sample Dockerfile is:

RUN cd /blackbox/client; gcc -o action example.c

Instead of compiling example.c and installing the binary as an action, we’ll change the Dockerfile to install aspell into the Linux environment, and then install our action.sh script as the executable action command.

To do so, we delete the RUN command above, and insert the following commands into the Dockerfile:

RUN apt-get install -y aspell
RUN rm -f /blackbox/client/action
ADD action.sh /blackbox/client/action
</code></pre>

<p>i am trying to do this on the dockerfile below</p>

<pre><code># Dockerfile for example whisk docker action
FROM openwhisk/dockerskeleton

ENV FLASK_PROXY_PORT 8080

### Add source file(s)
ADD example.c /action/example.c

RUN sudo apt-get install -y aspell
RUN rm -f /blackbox/client/action
ADD action.sh /blackbox/client/action



CMD [""/home/huseyin/bin"", ""-c"", ""cd actionProxy &amp;&amp; python -u actionproxy.py""]
</code></pre>

<p>the tutorial is outdated so i can't succeed doing it. Can you help me?</p>
","7877578","","","","","2019-07-11 09:00:24","/bin/sh: apt-get: not found","<bash><docker><dockerfile><aspell>","2","2","22","","","CC BY-SA 3.0","45143116","2","","45142855","2017-07-17 11:29:43","","420","","<p>The <a href=""https://hub.docker.com/r/openwhisk/dockerskeleton/~/dockerfile/"" rel=""noreferrer"">image you're using</a> is <a href=""https://alpinelinux.org"" rel=""noreferrer"">Alpine based</a>, so you can't use <code>apt-get</code> because it's Ubuntu's package manager.</p>

<p>To fix this just use: </p>

<p><code>apk update</code> and <code>apk add</code></p>
","3411861","","457268","","2017-07-17 11:33:41","2017-07-17 11:33:41","","","","2","","","","CC BY-SA 3.0"
"42510002","1","42510314","","2017-02-28 13:25:28","","313","350260","<p>I use <code>docker logs [container-name]</code> to see the logs of a specific container.</p>

<p>Is there an elegant way to clear these logs?</p>
","6288254","","63550","","2018-07-24 16:13:54","2021-05-03 13:06:09","How to clear the logs properly for a Docker container?","<docker><docker-compose><boot2docker><docker-machine>","19","2","102","","","CC BY-SA 4.0","42510314","2","","42510002","2017-02-28 13:39:12","","415","","<p>First the bad answer. From <a href=""https://serverfault.com/q/637996/351549"">this question</a> there's a one-liner that you can run:</p>
<pre><code>echo &quot;&quot; &gt; $(docker inspect --format='{{.LogPath}}' &lt;container_name_or_id&gt;)
</code></pre>
<p>instead of echo, there's the simpler:</p>
<pre><code>: &gt; $(docker inspect --format='{{.LogPath}}' &lt;container_name_or_id&gt;)
</code></pre>
<p>or there's the truncate command:</p>
<pre><code>truncate -s 0 $(docker inspect --format='{{.LogPath}}' &lt;container_name_or_id&gt;)
</code></pre>
<hr />
<p>I'm not a big fan of either of those since they modify Docker's files directly. The external log deletion could happen while docker is writing json formatted data to the file, resulting in a partial line, and breaking the ability to read any logs from the <code>docker logs</code> cli. For an example of that happening, see <a href=""https://stackoverflow.com/questions/42510002/how-to-clear-the-logs-properly-for-a-docker-container/42510314?noredirect=1#comment98713207_43570083"">this comment on duketwo's answer</a>:</p>
<blockquote>
<p>after emptying the logfile, I get this error: <code>error from daemon in stream: Error grabbing logs: invalid character '\x00' looking for beginning of value</code></p>
</blockquote>
<p>Instead, you can have Docker automatically rotate the logs for you. This is done with additional flags to dockerd if you are using the default <a href=""https://docs.docker.com/config/containers/logging/json-file/"" rel=""noreferrer"">JSON logging driver</a>:</p>
<pre><code>dockerd ... --log-opt max-size=10m --log-opt max-file=3
</code></pre>
<p>You can also set this as part of your <a href=""https://docs.docker.com/engine/reference/commandline/dockerd/#on-linux"" rel=""noreferrer"">daemon.json</a> file instead of modifying your startup scripts:</p>
<pre><code>{
  &quot;log-driver&quot;: &quot;json-file&quot;,
  &quot;log-opts&quot;: {&quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;3&quot;}
}
</code></pre>
<p>These options need to be configured with root access. Make sure to run a <code>systemctl reload docker</code> after changing this file to have the settings applied. This setting will then be the default for any newly created containers. Note, existing containers need to be deleted and recreated to receive the new log limits.</p>
<hr />
<p>Similar log options can be passed to individual containers to override these defaults, allowing you to save more or fewer logs on individual containers. From <code>docker run</code> this looks like:</p>
<pre><code>docker run --log-driver json-file --log-opt max-size=10m --log-opt max-file=3 ...
</code></pre>
<p>or in a compose file:</p>
<pre><code>version: '3.7'
services:
  app:
    image: ...
    logging:
      options:
        max-size: &quot;10m&quot;
        max-file: &quot;3&quot;
</code></pre>
<hr />
<p>For additional space savings, you can switch from the json log driver to the &quot;local&quot; log driver. It takes the same max-size and max-file options, but instead of storing in json it uses a binary syntax that is faster and smaller. This allows you to store more logs in the same sized file. The daemon.json entry for that looks like:</p>
<pre><code>{
  &quot;log-driver&quot;: &quot;local&quot;,
  &quot;log-opts&quot;: {&quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;3&quot;}
}
</code></pre>
<p>The downside of the local driver is external log parsers/forwarders that depended on direct access to the json logs will no longer work. So if you use a tool like filebeat to send to Elastic, or Splunk's universal forwarder, I'd avoid the &quot;local&quot; driver.</p>
<p>I've got a bit more on this in my <a href=""https://sudo-bmitch.github.io/presentations/dc2019/tips-and-tricks-of-the-captains.html#logs"" rel=""noreferrer"">Tips and Tricks presentation</a>.</p>
","596285","","596285","","2021-04-11 20:04:58","2021-04-11 20:04:58","","","","16","","","","CC BY-SA 4.0"
"37599128","1","37600885","","2016-06-02 18:03:51","","189","81681","<p>I can enable auto-restart with <code>--restart=always</code>, but after I stop the container, how do I turn off that attribute?</p>

<p>I normally run a webserver and typically map port 80:</p>

<pre><code>docker run -d --restart=always -p 80:80 -i -t myuser/myproj /bin/bash
</code></pre>

<p>But there are times when I want to run a newer version of my image, but I want to keep the old container around.  The problem is that if there are multiple containers with <code>--restart=always</code>, only one of them (random?) starts because they're all contending for port 80 on the host.</p>
","1760405","","","","","2021-06-29 10:35:48","docker - how do you disable auto-restart on a container?","<docker>","6","0","54","","","CC BY-SA 3.0","37600885","2","","37599128","2016-06-02 19:51:09","","396","","<p>You can use the <code>--restart=unless-stopped</code> option, as @Shibashis mentioned, or update the restart policy (this requires docker 1.11 or newer);</p>

<p>See the <a href=""https://github.com/docker/docker/blob/v1.11.2/docs/reference/commandline/update.md#update-a-containers-restart-policy"" rel=""noreferrer"">documentation for <code>docker update</code></a> and <a href=""https://docs.docker.com/engine/reference/run/#restart-policies---restart"" rel=""noreferrer"">Docker restart policies</a>.</p>

<pre><code>docker update --restart=no my-container
</code></pre>

<p>that updates the restart-policy for an existing container (<code>my-container</code>)</p>
","1811501","","911945","","2018-06-01 12:39:48","2018-06-01 12:39:48","","","","1","","","","CC BY-SA 4.0"
"31746182","1","41854997","","2015-07-31 12:25:23","","419","310502","<p>I am using rabbitmq and a simple python sample from <a href=""https://www.rabbitmq.com/tutorials/tutorial-one-python.html"" rel=""noreferrer"">here</a>
together with docker-compose. My problem is that I need to wait for rabbitmq to be fully started. From what I searched so far, I don't know how to wait with container x (in my case worker) until y (rabbitmq) is started.</p>
<p>I found this <a href=""http://blog.chmouel.com/2014/11/04/avoiding-race-conditions-between-containers-with-docker-and-fig/"" rel=""noreferrer"">blog post</a> where he checks if the other host is online.
I also found this <a href=""https://docs.docker.com/reference/commandline/wait/"" rel=""noreferrer"">docker command</a>:</p>
<blockquote>
<p><strong>wait</strong></p>
<p>Usage: docker wait CONTAINER [CONTAINER...]</p>
<p>Block until a container stops, then print its exit code.</p>
</blockquote>
<p>Waiting for a container to stop is maybe not what I am looking for but if
it is, is it possible to use that command inside the docker-compose.yml?
My solution so far is to wait some seconds and check the port, but is this the way to achieve this? If I don't wait, I get an error.</p>
<p><strong>docker-compose.yml</strong></p>
<pre class=""lang-yaml prettyprint-override""><code>worker:
    build: myapp/.
    volumes:
    - myapp/.:/usr/src/app:ro

    links:
    - rabbitmq
rabbitmq:
    image: rabbitmq:3-management
</code></pre>
<p><strong>python hello sample (rabbit.py):</strong></p>
<pre class=""lang-py prettyprint-override""><code>import pika
import time

import socket

pingcounter = 0
isreachable = False
while isreachable is False and pingcounter &lt; 5:
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    try:
        s.connect(('rabbitmq', 5672))
        isreachable = True
    except socket.error as e:
        time.sleep(2)
        pingcounter += 1
    s.close()

if isreachable:
    connection = pika.BlockingConnection(pika.ConnectionParameters(
            host=&quot;rabbitmq&quot;))
    channel = connection.channel()

    channel.queue_declare(queue='hello')

    channel.basic_publish(exchange='',
                          routing_key='hello',
                          body='Hello World!')
    print (&quot; [x] Sent 'Hello World!'&quot;)
    connection.close()
</code></pre>
<p><strong>Dockerfile for worker:</strong></p>
<pre><code>FROM python:2-onbuild
RUN [&quot;pip&quot;, &quot;install&quot;, &quot;pika&quot;]

CMD [&quot;python&quot;,&quot;rabbit.py&quot;]
</code></pre>
<p><strong>Update Nov 2015</strong>:</p>
<p>A shell script or waiting inside your program is maybe a possible solution. But after seeing this <a href=""https://github.com/docker/compose/issues/374"" rel=""noreferrer"">Issue</a> I am looking for a command or feature of docker/docker-compose itself.</p>
<p>They mention a  solution for implementing a health check, which may be the best option. A open tcp connection does not mean your service is ready or may remain ready. In addition to that I need to change my entrypoint in my dockerfile.</p>
<p>So I am hoping for an answer with docker-compose on board commands, which will hopefully the case if they finish this issue.</p>
<p><strong>Update March 2016</strong></p>
<p>There is a <a href=""https://github.com/docker/docker/issues/21142"" rel=""noreferrer"">proposal</a> for providing a built-in way to determine if a container is &quot;alive&quot;. So docker-compose can maybe make use of it in near future.</p>
<p><strong>Update June 2016</strong></p>
<p>It seems that the healthcheck will be <a href=""https://github.com/docker/docker/pull/23218"" rel=""noreferrer"">integrated</a> into docker in Version 1.12.0</p>
<p><strong>Update January 2017</strong></p>
<p>I found a docker-compose solution see:
<a href=""https://stackoverflow.com/questions/31746182/docker-compose-wait-for-container-x-before-starting-y/41854997#41854997"">Docker Compose wait for container X before starting Y</a></p>
","1584115","","1402846","","2020-09-30 09:38:41","2021-04-12 18:09:39","Docker Compose wait for container X before starting Y","<docker-compose>","18","2","149","","","CC BY-SA 4.0","41854997","2","","31746182","2017-01-25 15:10:24","","376","","<p>Finally found a solution with a docker-compose method. Since docker-compose file format 2.1 you can define <a href=""https://docs.docker.com/compose/compose-file/#healthcheck"" rel=""noreferrer"">healthchecks</a>.</p>
<p>I did it in a <a href=""https://github.com/svenhornberg/healthcheckcompose"" rel=""noreferrer"">example project</a>
you need to install at least docker 1.12.0+.
I also needed to <a href=""https://raw.githubusercontent.com/svenhornberg/healthcheckcompose/master/rabbitmq/Dockerfile"" rel=""noreferrer"">extend the rabbitmq-management Dockerfile</a>, because curl isn't installed on the official image.</p>
<p>Now I test if the management page of the rabbitmq-container is available. If curl finishes with exitcode 0 the container app (python pika) will be started and publish a message to hello queue. Its now working (output).</p>
<p><strong>docker-compose (version 2.1):</strong></p>
<pre class=""lang-yaml prettyprint-override""><code>version: '2.1'

services:
  app:
    build: app/.
    depends_on:
      rabbit:
        condition: service_healthy
    links: 
        - rabbit

  rabbit:
    build: rabbitmq/.
    ports: 
        - &quot;15672:15672&quot;
        - &quot;5672:5672&quot;
    healthcheck:
        test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:15672&quot;]
        interval: 30s
        timeout: 10s
        retries: 5
</code></pre>
<p><strong>output:</strong></p>
<pre><code>rabbit_1  | =INFO REPORT==== 25-Jan-2017::14:44:21 ===
rabbit_1  | closing AMQP connection &lt;0.718.0&gt; (172.18.0.3:36590 -&gt; 172.18.0.2:5672)
app_1     |  [x] Sent 'Hello World!'
healthcheckcompose_app_1 exited with code 0
</code></pre>
<p><em><strong>Dockerfile (rabbitmq + curl):</strong></em></p>
<pre><code>FROM rabbitmq:3-management
RUN apt-get update
RUN apt-get install -y curl 
EXPOSE 4369 5671 5672 25672 15671 15672
</code></pre>
<p><strong>Version 3 no longer supports the condition form of <a href=""https://docs.docker.com/compose/compose-file/#depends_on"" rel=""noreferrer"">depends_on</a>.</strong>
So i moved from depends_on to restart on-failure. Now my app container will restart 2-3 times until it is working, but it is still a docker-compose feature without overwriting the entrypoint.</p>
<p><strong>docker-compose (version 3):</strong></p>
<pre class=""lang-yaml prettyprint-override""><code>version: &quot;3&quot;

services:

  rabbitmq: # login guest:guest
    image: rabbitmq:management
    ports:
    - &quot;4369:4369&quot;
    - &quot;5671:5671&quot;
    - &quot;5672:5672&quot;
    - &quot;25672:25672&quot;
    - &quot;15671:15671&quot;
    - &quot;15672:15672&quot;
    healthcheck:
        test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:15672&quot;]
        interval: 30s
        timeout: 10s
        retries: 5

  app:
    build: ./app/
    environment:
      - HOSTNAMERABBIT=rabbitmq
    restart: on-failure
    depends_on:
      - rabbitmq
    links: 
        - rabbitmq
</code></pre>
","1584115","","1402846","","2020-09-07 08:45:11","2020-09-07 08:45:11","","","","18","","","","CC BY-SA 4.0"
"21498832","1","23667302","","2014-02-01 13:49:08","","333","87617","<p>What's the difference between a container and an image in Docker? In the <a href=""https://docs.docker.com/engine/getstarted/"" rel=""noreferrer"">Get started with Docker tutorial</a> these terms are both used, but I do not understand the difference.</p>

<p>Can anybody please shed some light?</p>
","1333873","","42223","","2017-12-28 19:58:07","2019-03-07 05:40:04","In Docker, what's the difference between a container and an image?","<docker><terminology>","13","0","94","2019-05-06 18:23:29","","CC BY-SA 3.0","23667302","2","","21498832","2014-05-15 00:22:55","","374","","<p>Images are frozen immutable snapshots of live containers. Containers are running (or stopped) instances of some image.</p>

<p>Start with the base image called 'ubuntu'. Let's run bash interactively within the ubuntu image and create a file. We'll use the <code>-i</code> and <code>-t</code> flags to give us an interactive bash shell.</p>

<pre><code>$ docker run -i -t ubuntu  /bin/bash
root@48cff2e9be75:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
root@48cff2e9be75:/# cat &gt; foo
This is a really important file!!!!
root@48cff2e9be75:/# exit
</code></pre>

<p>Don't expect that file to stick around when you exit and restart the image. You're restarting from exactly the same defined state as you started in before, not where you left off.</p>

<pre><code>$ docker run -i -t ubuntu  /bin/bash
root@abf181be4379:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
root@abf181be4379:/# exit
</code></pre>

<p>But, the container, now no longer running, has state and can be saved (committed) to an image.</p>

<pre><code>$ docker ps -a
CONTAINER ID        IMAGE               COMMAND                CREATED              STATUS                          PORTS                      NAMES
abf181be4379        ubuntu:14.04        /bin/bash              17 seconds ago       Exited (0) 12 seconds ago                                  elegant_ardinghelli    
48cff2e9be75        ubuntu:14.04        /bin/bash              About a minute ago   Exited (0) 50 seconds ago                                  determined_pare        
...
</code></pre>

<p>Let's create an image from container ID 48cff2e9be75 where we created our file:</p>

<pre><code>$ docker commit 48cff2e9be75 ubuntu-foo
d0e4ae9a911d0243e95556e229c8e0873b623eeed4c7816268db090dfdd149c2
</code></pre>

<p>Now, we have a new image with our really important file:</p>

<pre><code>$ docker run ubuntu-foo /bin/cat foo
This is a really important file!!!!
</code></pre>

<p>Try the command <code>docker images</code>. You should see your new image <code>ubuntu-foo</code> listed along with the <code>ubuntu</code> standard image we started with.</p>
","199166","","199166","","2015-05-27 00:05:11","2015-05-27 00:05:11","","","","5","","","","CC BY-SA 3.0"
"30233105","1","30234588","","2015-05-14 08:52:54","","247","166595","<p>I have a <code>docker-compose.yml</code> which contain several containers.  Three of them are for my app (client, server and database) and the rest are for various dev tools (e.g. psql, npm, manage.py, etc).  When I do <code>docker-compose up</code> all of them are started, but I only want the three main ones to start.  Because of the links I've specified, I can start just those three with <code>docker-compose up client</code> but then the output is only from that one container. So, is there a way to do one of the following:</p>

<ol>
<li>Tell docker-compose which containers should by started by <code>docker-compose up</code></li>
<li>Get output from all linked containers from <code>docker-compose up client</code></li>
</ol>
","1235039","","","","","2021-01-27 14:44:17","docker-compose up for only certain containers","<docker><docker-compose>","8","1","33","","","CC BY-SA 3.0","30234588","2","","30233105","2015-05-14 10:08:25","","372","","<p>You can start containers by using:</p>

<pre><code>$ docker-compose up -d client
</code></pre>

<p>This will run containers in the background and output will be avaiable from</p>

<pre><code>$ docker-compose logs
</code></pre>

<p>and it will consist of all your started containers </p>
","3254377","","107049","","2015-05-14 20:38:55","2015-05-14 20:38:55","","","","4","","","","CC BY-SA 3.0"
"19335444","1","38783433","","2013-10-12 14:46:18","","555","561863","<p>I'm not sure if I've misunderstood something here, but it seems like it's only possible to set port mappings by creating a new container from an image. Is there a way to assign a port mapping to an existing Docker container?</p>
","455988","","63550","","2017-03-12 13:28:26","2021-06-17 00:14:38","How do I assign a port mapping to an existing Docker container?","<docker><port><lxc><linux-containers>","14","4","217","","","CC BY-SA 3.0","38783433","2","","19335444","2016-08-05 07:20:57","","369","","<p>You can change the port mapping by directly editing the <code>hostconfig.json</code> file at
<code>/var/lib/docker/containers/[hash_of_the_container]/hostconfig.json</code> or <code>/var/snap/docker/common/var-lib-docker/containers/[hash_of_the_container]/hostconfig.json</code>, I believe, if You installed Docker as a snap.</p>
<p>You can determine the [hash_of_the_container] via the <code>docker inspect &lt;container_name&gt;</code> command and the value of the &quot;Id&quot; field is the hash.</p>
<ol>
<li>Stop the container (<code>docker stop &lt;container_name&gt;</code>).</li>
<li>Stop docker service (per Tacsiazuma's comment)</li>
<li>Change the file.</li>
<li>Restart your docker engine (to flush/clear config caches).</li>
<li>Start the container (<code>docker start &lt;container_name&gt;</code>).</li>
</ol>
<p>So you don't need to create an image with this approach. You can also change the restart flag here.</p>
<p><em>P.S. You may visit <a href=""https://docs.docker.com/engine/admin/"" rel=""noreferrer"">https://docs.docker.com/engine/admin/</a> to learn how to correctly restart your docker engine as per your host machine. I used <code>sudo systemctl restart docker</code> to restart my docker engine that is running on Ubuntu 16.04</em>.</p>
","4142617","","1505369","","2020-10-07 12:24:23","2020-10-07 12:24:23","","","","16","","","","CC BY-SA 4.0"
"20635472","1","25086628","","2013-12-17 13:29:34","","332","273056","<p>I have a Dockerfile that I am putting together to install a vanilla python environment (into which I will be installing an app, but at a later date).</p>

<pre><code>FROM ubuntu:12.04

# required to build certain python libraries
RUN apt-get install python-dev -y

# install pip - canonical installation instructions from pip-installer.org
# http://www.pip-installer.org/en/latest/installing.html
ADD https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py /tmp/ez_setup.py
ADD https://raw.github.com/pypa/pip/master/contrib/get-pip.py /tmp/get-pip.py
RUN python /tmp/ez_setup.py
RUN python /tmp/get-pip.py
RUN pip install --upgrade pip 

# install and configure virtualenv
RUN pip install virtualenv 
RUN pip install virtualenvwrapper
ENV WORKON_HOME ~/.virtualenvs
RUN mkdir -p $WORKON_HOME
RUN source /usr/local/bin/virtualenvwrapper.sh
</code></pre>

<p>The build runs ok until the last line, where I get the following exception:</p>

<pre><code>[previous steps 1-9 removed for clarity]
...
Successfully installed virtualenvwrapper virtualenv-clone stevedore
Cleaning up...
 ---&gt; 1fc253a8f860
Step 10 : ENV WORKON_HOME ~/.virtualenvs
 ---&gt; Running in 8b0145d2c80d
 ---&gt; 0f91a5d96013
Step 11 : RUN mkdir -p $WORKON_HOME
 ---&gt; Running in 9d2552712ddf
 ---&gt; 3a87364c7b45
Step 12 : RUN source /usr/local/bin/virtualenvwrapper.sh
 ---&gt; Running in c13a187261ec
/bin/sh: 1: source: not found
</code></pre>

<p>If I <code>ls</code> into that directory (just to test that the previous steps were committed) I can see that the files exist as expected:</p>

<pre><code>$ docker run 3a87 ls /usr/local/bin
easy_install
easy_install-2.7
pip
pip-2.7
virtualenv
virtualenv-2.7
virtualenv-clone
virtualenvwrapper.sh
virtualenvwrapper_lazy.sh
</code></pre>

<p>If I try just running the <code>source</code> command I get the same 'not found' error as above. If I RUN an interactive shell session however, source does work:</p>

<pre><code>$ docker run 3a87 bash
source
bash: line 1: source: filename argument required
source: usage: source filename [arguments]
</code></pre>

<p>I can run the script from here, and then happily access <code>workon</code>, <code>mkvirtualenv</code> etc.</p>

<p>I've done some digging, and initially it looked as if the problem might lie in the difference between <strong>bash</strong> as the Ubuntu <em>login shell</em>, and <strong>dash</strong> as the Ubuntu <em>system shell</em>, <strong>dash</strong> not supporting the <code>source</code> command.</p>

<p>However, the answer to this appears to be to use <strong>'.'</strong> instead of <code>source</code>, but this just causes the Docker runtime to blow up with a go panic exception.</p>

<p>What is the best way to run a shell script from a Dockerfile RUN instruction to get around this (am running off the default base image for Ubuntu 12.04 LTS).</p>
","45698","","","","","2021-05-20 18:21:24","Using the RUN instruction in a Dockerfile with 'source' does not work","<bash><shell><docker>","18","5","76","","","CC BY-SA 3.0","25086628","2","","20635472","2014-08-01 18:39:52","","365","","<p>Edit: My answer is stale. I think that another answers is better.</p>
<p><s>RUN /bin/bash -c &quot;source /usr/local/bin/virtualenvwrapper.sh&quot;</s></p>
","1924796","","1924796","","2021-05-14 06:47:10","2021-05-14 06:47:10","","","","9","","","","CC BY-SA 4.0"
"19897743","1","19905563","","2013-11-11 02:00:56","","437","461060","<p>I'm trying to create a Docker container that acts like a full-on virtual machine. I know I can use the EXPOSE instruction inside a Dockerfile to expose a port, and I can use the <code>-p</code> flag with <code>docker run</code> to assign ports, but once a container is actually running, is there a command to open/map additional ports live?</p>

<p>For example, let's say I have a Docker container that is running sshd. Someone else using the container ssh's in and installs httpd. Is there a way to expose port 80 on the container and map it to port 8080 on the host, so that people can visit the web server running in the container, without restarting it?</p>
","2079798","","63550","","2017-03-12 13:26:36","2021-01-31 13:26:50","Exposing a port on a live Docker container","<docker>","16","1","181","","","CC BY-SA 3.0","19905563","2","","19897743","2013-11-11 11:47:07","","362","","<p>You cannot do this via Docker, but you can access the container's un-exposed port from the host machine.</p>
<p>If you have a container with something running on its port 8000, you can run</p>
<pre><code>wget http://container_ip:8000
</code></pre>
<p>To get the container's IP address, run the 2 commands:</p>
<pre><code>docker ps
docker inspect container_name | grep IPAddress
</code></pre>
<p>Internally, Docker shells out to call iptables when you run an image, so maybe some variation on this will work.</p>
<p>To expose the container's port 8000 on your localhost's port 8001:</p>
<pre><code>iptables -t nat -A  DOCKER -p tcp --dport 8001 -j DNAT --to-destination 172.17.0.19:8000
</code></pre>
<p>One way you can work this out is to setup another container with the port mapping you want, and compare the output of the <strong>iptables-save</strong> command (though, I had to remove some of the other options that force traffic to go via the docker proxy).</p>
<p><strong>NOTE: this is subverting docker, so should be done with the awareness that it may well create blue smoke.</strong></p>
<p>OR</p>
<p>Another alternative is to look at the (new? post 0.6.6?) -P option - which will use random host ports, and then wire those up.</p>
<p>OR</p>
<p>With 0.6.5, you could use the LINKs feature to bring up a new container that talks to the existing one, with some additional relaying to that container's -p flags? (I have not used LINKs yet.)</p>
<p>OR</p>
<p>With docker 0.11? you can use <code>docker run --net host ..</code> to attach your container directly to the host's network interfaces (i.e., net is not namespaced) and thus <strong>all</strong> ports you open in the container are exposed.</p>
","31088","","1402846","","2020-07-23 01:31:09","2020-07-23 01:31:09","","","","7","","","","CC BY-SA 4.0"
"26600769","1","26604307","","2014-10-28 04:10:49","","204","99039","<p>I have created a couple different directories on my host machine as I try to learn about Docker just to keep my dockerfiles organized.  My Dockerfile I just ran looks like this:</p>

<pre><code>FROM crystal/centos
MAINTAINER crystal

ADD ./rpms/test.rpm ./rpms/ 
RUN yum -y --nogpgcheck localinstall /rpms/test.rpm 
</code></pre>

<p>My actual rpm is only 1 GB.  But when I try to do <code>sudo docker build -t=""crystal/test"" .</code>, I get sending build context to Docker daemon 3.5 GB.  Is there something else that I'm unaware of as you continue to build Docker images? Is my memory accumulating as I build more images in my other directories on my host machine? </p>
","207524","","","","","2021-04-23 12:22:55","build context for docker image very large","<docker>","11","2","37","","","CC BY-SA 3.0","26604307","2","","26600769","2014-10-28 09:02:00","","358","","<p>The Docker client sends the entire &quot;build context&quot; to the Docker daemon. That build context (by default) is the entire directory the <code>Dockerfile</code> is in (so, the entire <code>rpms</code> tree).</p>
<p>You can setup a <a href=""https://docs.docker.com/engine/reference/builder/#dockerignore-file"" rel=""noreferrer""><code>.dockerignore</code></a> file to get Docker to ignore some files. You might want to experiment with it.</p>
<p>Alternatively, you can move your <code>rpms</code> folder one directory level above your <code>Dockerfile</code>, and only symlink <code>test.rpm</code> into the <code>Dockerfile</code>'s directory.</p>
<hr />
<p>You’ll often want to <strong>add the <code>.git</code> folder to the <code>.dockerignore</code></strong> which was the cause of a 150MB -&gt; 5GB difference for some users in the comments here.</p>
","873145","","873145","","2020-09-26 09:05:31","2020-09-26 09:05:31","","","","6","","","","CC BY-SA 4.0"
"22944631","1","24716645","","2014-04-08 17:53:32","","426","466974","<p>As the title says. I need to be able to retrieve the IP address the docker hosts and the portmaps from the host to the container, and doing that inside of the container. </p>
","335918","","1429387","","2018-03-13 07:47:12","2021-05-07 11:23:52","How to get the IP address of the docker host from inside a docker container","<docker><ip>","26","2","153","","","CC BY-SA 3.0","24716645","2","","22944631","2014-07-12 19:41:34","","356","","<pre><code>/sbin/ip route|awk '/default/ { print $3 }'
</code></pre>

<p>As @MichaelNeale noticed, there is no sense to use this method in <code>Dockerfile</code> (except when we need this IP during build time only), because this IP will be hardcoded during build time.</p>
","1556065","","1556065","","2015-08-10 16:01:39","2015-08-10 16:01:39","","","","10","","","","CC BY-SA 3.0"
"29663459","1","29745541","","2015-04-16 00:47:16","","208","97919","<p>I have a Python (2.7) app which is started in my dockerfile:</p>

<pre><code>CMD [""python"",""main.py""]
</code></pre>

<p><em>main.py</em> prints some strings when it is started and goes into a loop afterwards:</p>

<pre><code>print ""App started""
while True:
    time.sleep(1)
</code></pre>

<p>As long as I start the container with the -it flag, everything works as expected:</p>

<pre><code>$ docker run --name=myapp -it myappimage
&gt; App started
</code></pre>

<p>And I can see the same output via logs later:</p>

<pre><code>$ docker logs myapp
&gt; App started
</code></pre>

<p>If I try to run the same container with the -d flag, the container seems to start normally, but I can't see any output:</p>

<pre><code>$ docker run --name=myapp -d myappimage
&gt; b82db1120fee5f92c80000f30f6bdc84e068bafa32738ab7adb47e641b19b4d1
$ docker logs myapp
$ (empty)
</code></pre>

<p>But the container still seems to run;</p>

<pre><code>$ docker ps
Container Status ...
myapp     up 4 minutes ... 
</code></pre>

<p>Attach does not display anything either:</p>

<pre><code>$ docker attach --sig-proxy=false myapp
(working, no output)
</code></pre>

<p>Any ideas whats going wrong? Does ""print"" behave differently when ran in background?</p>

<p>Docker version:</p>

<pre><code>Client version: 1.5.0
Client API version: 1.17
Go version (client): go1.4.2
Git commit (client): a8a31ef
OS/Arch (client): linux/arm
Server version: 1.5.0
Server API version: 1.17
Go version (server): go1.4.2
Git commit (server): a8a31ef
</code></pre>
","1152166","","402884","","2015-10-11 12:59:39","2021-03-04 21:08:23","Python app does not print anything when running detached in docker","<python><docker><dockerfile>","13","0","41","","","CC BY-SA 3.0","29745541","2","","29663459","2015-04-20 10:37:19","","356","","<p>Finally I found a solution to see Python output when running daemonized in Docker, thanks to @ahmetalpbalkan over at <a href=""https://github.com/docker/docker/issues/12447#issuecomment-94417192"">GitHub</a>. Answering it here myself for further reference :</p>

<p>Using unbuffered output with</p>

<pre><code>CMD [""python"",""-u"",""main.py""]
</code></pre>

<p>instead of </p>

<pre><code>CMD [""python"",""main.py""]
</code></pre>

<p>solves the problem; you can see the output (both, stderr and stdout) via</p>

<pre><code>docker logs myapp
</code></pre>

<p>now!</p>
","1152166","","","","","2015-04-20 10:37:19","","","","7","","","","CC BY-SA 3.0"
"35689628","1","35689633","","2016-02-28 23:28:46","","208","197521","<p>To start an interactive shell for the Ubuntu image we can run:</p>

<pre><code>ole@T:~$ docker run -it --rm ubuntu
root@1a6721e1fb64:/# ls
bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
</code></pre>

<p>But when this is run for the <a href=""https://hub.docker.com/_/alpine/"" rel=""noreferrer"">Alpine Docker image</a>, the following results:</p>

<pre><code>ole@T:~$ docker run -it --rm alpine
Error response from daemon: No command specified
</code></pre>

<p>What is the command for starting an interactive shell in an Alpine base container?</p>
","1684269","","63550","","2018-08-07 12:29:06","2020-03-19 20:20:07","Starting a shell in the Docker Alpine container","<linux><docker><containers><alpine>","4","0","48","","","CC BY-SA 4.0","35689633","2","","35689628","2016-02-28 23:29:08","","347","","<pre><code>ole@T:~$ docker run -it --rm alpine /bin/ash
(inside container) / # 
</code></pre>

<p>Options used above:</p>

<ul>
<li><code>/bin/ash</code> is Ash (<a href=""http://www.in-ulm.de/~mascheck/various/ash/#busybox"" rel=""noreferrer"">Almquist Shell</a>) provided by BusyBox</li>
<li><code>--rm</code> Automatically remove the container when it exits (<code>docker run --help</code>)</li>
<li><code>-i</code> Interactive mode (Keep STDIN open even if not attached)</li>
<li><code>-t</code> Allocate a pseudo-TTY</li>
</ul>
","1684269","","117471","","2017-10-02 22:50:41","2017-10-02 22:50:41","","","","5","","","","CC BY-SA 3.0"
"41637505","1","41650891","","2017-01-13 15:02:12","","287","195576","<p>My docker compose file has three containers, web, nginx, and postgres. Postgres looks like this:</p>
<pre><code>postgres:
  container_name: postgres
  restart: always
  image: postgres:latest
  volumes:
    - ./database:/var/lib/postgresql
  ports:
    - 5432:5432
</code></pre>
<p>My goal is to mount a volume which corresponds to a local folder called <code>./database</code> inside the postgres container as <code>/var/lib/postgres</code>. When I start these containers and insert data into postgres, I verify that <code>/var/lib/postgres/data/base/</code> is full of the data I'm adding (in the postgres container), but in my local system, <code>./database</code> only gets a <code>data</code> folder in it, i.e. <code>./database/data</code> is created, but it's empty. Why?</p>
<p>Notes:</p>
<ul>
<li><a href=""https://github.com/docker/compose/issues/2971"" rel=""noreferrer"">This suggests my above file should work.</a></li>
<li><a href=""https://stackoverflow.com/questions/39175194/docker-compose-persistent-data-mysql"">This person is using docker services which is interesting</a></li>
</ul>
<h3>UPDATE 1</h3>
<p>Per Nick's suggestion, I did a <code>docker inspect</code> and found:</p>
<pre><code>    &quot;Mounts&quot;: [
        {
            &quot;Source&quot;: &quot;/Users/alex/Documents/MyApp/database&quot;,
            &quot;Destination&quot;: &quot;/var/lib/postgresql&quot;,
            &quot;Mode&quot;: &quot;rw&quot;,
            &quot;RW&quot;: true,
            &quot;Propagation&quot;: &quot;rprivate&quot;
        },
        {
            &quot;Name&quot;: &quot;e5bf22471215db058127109053e72e0a423d97b05a2afb4824b411322efd2c35&quot;,
            &quot;Source&quot;: &quot;/var/lib/docker/volumes/e5bf22471215db058127109053e72e0a423d97b05a2afb4824b411322efd2c35/_data&quot;,
            &quot;Destination&quot;: &quot;/var/lib/postgresql/data&quot;,
            &quot;Driver&quot;: &quot;local&quot;,
            &quot;Mode&quot;: &quot;&quot;,
            &quot;RW&quot;: true,
            &quot;Propagation&quot;: &quot;&quot;
        }
    ],
</code></pre>
<p>Which makes it seem like the data is being stolen by another volume I didn't code myself. Not sure why that is. Is the postgres image creating that volume for me? If so, is there some way to use <em>that volume</em> instead of the volume I'm mounting when I restart? Otherwise, is there a good way of disabling that other volume and using my own, <code>./database</code>?</p>
<h3>UPDATE 2</h3>
<p>I found the solution, thanks to Nick! (and another friend) Answer below.</p>
","2584721","","1840794","","2021-02-10 17:18:59","2021-02-10 17:18:59","How to persist data in a dockerized postgres database using volumes","<postgresql><docker><docker-compose><docker-volume>","4","6","62","","","CC BY-SA 4.0","41650891","2","","41637505","2017-01-14 14:10:23","","345","","<p>Strangely enough, the solution ended up being to change</p>

<pre><code>volumes:
  - ./postgres-data:/var/lib/postgresql
</code></pre>

<p>to </p>

<pre><code>volumes:
  - ./postgres-data:/var/lib/postgresql/data
</code></pre>
","2584721","","","","","2017-01-14 14:10:23","","","","8","","","","CC BY-SA 3.0"
"38986057","1","38986676","","2016-08-16 23:37:34","","398","385283","<p>You can set image name when building a custom image, like this:</p>

<pre><code>docker build -t dude/man:v2 . # Will be named dude/man:v2
</code></pre>

<p>Is there a way to define the name of the image in Dockerfile, so I don't have to mention it in the <code>docker build</code> command?</p>
","1542343","","821436","","2019-01-22 12:55:36","2021-04-30 10:12:27","How to set image name in Dockerfile?","<docker><tags><dockerfile>","4","1","56","","","CC BY-SA 3.0","38986676","2","","38986057","2016-08-17 01:08:09","","343","","<p>Tagging of the image isn't supported inside the Dockerfile. This needs to be done in your build command. As a workaround, you can do the build with a docker-compose.yml that identifies the target image name and then run a <code>docker-compose build</code>. A sample docker-compose.yml would look like</p>

<pre><code>version: '2'

services:
  man:
    build: .
    image: dude/man:v2
</code></pre>

<p>That said, there's a push against doing the build with compose since that doesn't work with swarm mode deploys. So you're back to running the command as you've given in your question:</p>

<pre><code>docker build -t dude/man:v2 .
</code></pre>

<p>Personally, I tend to build with a small shell script in my folder (build.sh) which passes any args and includes the name of the image there to save typing. And for production, the build is handled by a ci/cd server that has the image name inside the pipeline script.</p>
","596285","","596285","","2019-01-03 18:41:33","2019-01-03 18:41:33","","","","0","","","","CC BY-SA 4.0"
"36685980","1","36689427","","2016-04-18 05:22:17","","160","256905","<p>I have installed docker on centos 7. by running following commands, </p>

<pre><code>curl -sSL https://get.docker.com/ | sh
systemctl enable docker &amp;&amp; systemctl start docker
docker run hello-world
</code></pre>

<p><strong>NOTE: helloworld runs correctly and no issues.</strong></p>

<p>however when i trying to run docker-compose (docker-compose.yml exists and valid) it gives me the error on Centos only (Windows version works fine for the docker-compose file)</p>

<pre><code>/usr/local/bin/docker-compose: line 1: {error:Not Found}: command not found
</code></pre>
","1179459","","","","","2021-06-02 15:09:24","Docker is installed but Docker Compose is not ? why?","<docker><docker-compose><dockerfile>","14","5","39","","","CC BY-SA 3.0","36689427","2","","36685980","2016-04-18 08:54:26","","341","","<p>You also need to install Docker Compose. See the <a href=""https://docs.docker.com/compose/install/"" rel=""noreferrer"">manual</a>. Here are the commands you need to execute</p>
<pre><code>sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)&quot;  -o /usr/local/bin/docker-compose
sudo mv /usr/local/bin/docker-compose /usr/bin/docker-compose
sudo chmod +x /usr/bin/docker-compose
</code></pre>
","472150","","2921949","","2020-06-23 03:42:24","2020-06-23 03:42:24","","","","7","","","","CC BY-SA 4.0"
"21928691","1","21928864","","2014-02-21 08:05:16","","309","262376","<p>Consider:</p>

<pre><code>docker run -it centos /bin/bash
</code></pre>

<p>I pressed <kbd><strong>Ctrl</strong></kbd>+<kbd><strong>D</strong></kbd> to exit it.</p>

<p>I want to continue to run this container, but I found I can't.</p>

<p>The only method is</p>

<pre><code>docker commit `docker ps -q -l` my_image
docker run -it my_image /bin/bash
</code></pre>

<p>Am I right? Is there a better method? (I'm using docker 0.8.0.)</p>
","730346","","63550","","2018-07-23 19:15:56","2021-06-18 19:44:50","How to continue a Docker container which has exited","<docker>","13","5","106","","","CC BY-SA 4.0","21928864","2","","21928691","2014-02-21 08:14:54","","338","","<p>You can restart an existing container after it exited and your changes are still there.</p>

<pre><code>docker start  `docker ps -q -l` # restart it in the background
docker attach `docker ps -q -l` # reattach the terminal &amp; stdin
</code></pre>
","467255","","","","","2014-02-21 08:14:54","","","","5","","","","CC BY-SA 3.0"